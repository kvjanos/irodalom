A. Ghosh, L.C. Jain (Eds.) Evolutionary Computation in Data Mining

To our students
A. Ghosh L. C.Jain

Studies in Fuzziness and Soft Computing,Volume 163
Editor-in-chief Prof. Janusz Kacprzyk Systems Research Institute Polish Academy of Sciences ul. Newelska 6 01-447 Warsaw Poland E-mail: kacprzyk@ibspan.waw.pl
Further volumes of this series can be found on our homepage: springeronline.com
Vol. 147. K. Watanabe, M.M.A. Hashem New Algorithms and their Applications to Evolutionary Robots, 2004 ISBN 3-540-20901-8 Vol. 148. C. Martin-Vide, V. Mitrana, G. PSun (Eds.) Formal Languages and Applications, 2004 ISBN 3-540-20907-7 Vol. 149. J.J. Buckley Fuzzy Statistics, 2004 ISBN 3-540-21084-9 Vol. 150. L. Bull (Ed.) Applications of iear&ng Classifier Systems, 2004 ISBN 3-540-21109-8 Vol. 151. T. Kowalczyk, E. Pleszczynska, F. Ruland (Eds.) Grade Models and Methods for Data Analysis, 2004 ISBN 3-540-21120-9 Vol. 152. J. Rajapakse, L. Wang (Eds.) Neural Information Processing: Research and Development, 2004 ISBN 3-540-21123-3 Vol. 153. J. Fulcher, L.C. Jain (Eds.) Applied Intelligent Systems, 2004 ISBN 3-540-21153-5 Vol. 154. B. Liu Uncertainty Theory, 2004 ISBN 3-540-21333-3 Vol. 155. G. Resconi, J.L. Jain Intelligent Agents, 2004 ISBN 3-540-22003-8 Vol. 156. R. Tadeusiewicz, M.R. Ogiela Medical Image Understanding Technology, 2004 ISBN 3-540-21985-4 Vol. 157. R.A. Aliev, F. Fazlollahi, R.R. Aliev Soft Computing and its Applications in Business and Economics, 2004 ISBN 3-540-22138-7 Vol. 158. K.K. Dompere Cost-Benefit Analysis and the Theory of Fuzzy Decisions - Identification and Measurement Theory, 2004 ISBN 3-540-22154-9 Vol. 159. E. Damiani, L.C. Jain, M. Madravia Soft Computing in Software Engineering, 2004 ISBN 3-540-22030-5 Vol. 160. K.K. Dompere Cost-Benefit Analysis and the Theory of Fuzzy Decisions - Fuzzy Value Theory, 2004 ISBN 3-540-22161-1 Vol. 161. N. Nedjah, L. d e Macedo Mourelle (Eds.) Evolvable Machines, 2005 ISBN 3-540-22905-1 Vol. 162. N. Ichalkaranje, R. Khosla, L.C. Jain Design of Intelligent Multi-Agent Systems, 2005 ISBN 3-540-22913-2

Ashish Ghosh Lakhmi C. Jain (Eds.)

Evolutionary Computation in Data Mining

- Springer

Dr. Ashish Ghosh
Indian Statistical Institute Machine Intelligence Unit 203 Barrackpore Trunk Road Kolkata 700 108 India E-mail: ash@isical.ac.in

Prof. Lakhmi C. Jain
University of South Australia Knowledge-Based Intelligent Engineering Systems Centre Mawson Lakes 5095 Adelaide Australia E-mail: l.jain@unisa.edu.au

ISSN 1434-9922 ISBN 3-540-22370-3 Springer Berlin Heidelberg New York
Library of Congress Control Number: 2004111009 This work is subject to copyright. All rights are reserved, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitations, broadcasting, reproduction on microfilm or in any other way, and storage in data banks. Duplication of this publication or parts thereof is permitted only under the provisions of the German copyright Law of September 9, 1965, in its current version, and permission for use must always be obtained from Springer-Verlag. Violations are liable to prosecution under the German Copyright Law. Springer is a part of Springer Science+Business Media springeronline.com
O Springer-Verlag Berlin

Heidelberg 2005

Printed in Germany The use of general descriptive names, registered names trademarks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use. Typesetting: data delivered by editors Cover design: E. Kirchner, Springer-Verlag, Heidelberg Printed on acid free paper 62/3020/M - 5 4 3 2 1 0

Preface

Data mining (DM) consists of extracting interesting knowledge from realworld, large & complex data sets; and is the core step of a broader process, called the knowledge discovery from databases (KDD) process. In addition to the DM step, which actually extracts knowledge from data, the KDD process includes several preprocessing (or data preparation) and post-processing (or knowledge refinement) steps. The goal of data preprocessing methods is to transform the data t o facilitate the application of a (or several) given DM algorithm(s), whereas the goal of knowledge refinement methods is to validate and refine discovered knowledge. Ideally, discovered knowledge should be not only accurate, but also comprehensible and interesting to the user. The total process is highly computation intensive. The idea of automatically discovering knowledge from databases is a very attractive and challenging task, both for academia and for industry. Hence, there has been a growing interest in data mining in several AI-related areas, including evolutionary algorithms (EAs). The main motivation for applying EAs to KDD tasks is that they are robust and adaptive search methods, which perform a global search in the space of candidate solutions (for instance, rules or another form of knowledge representation). The evolutionary computing community has been publishing KDD-related articles in a relatively scattered manner in conference proceedings/journals dedicated to knowledge discovery and data mining or evolutionary computing. The objective of this volume is to assemble a set of high-quality original contributions that reflect and advance the state-of-the-art in the area of Data Mining and Knowledge Discovery with Evolutionary Algorithms. The book will also emphasize the utility of different evolutionary computing tools to various facets of KDD, ranging from theoretical analysis to real-life applications. This topic is quite new and there are only a few books in the literature. This book discusses advanced theories of evolutionary computing/data mining, and recent applications like web mining or bioinformatics. The book contains twelve chapters written by leading experts of the field demonstrating how different evolutionary computing tools can be used for solving real life problems in data mining, web mining, bioinformatics in addition to provide

VI

Preface

fundamentals of evolutionary computing and data mining. This provides a balance mixture of theory, algorithms and applications in cohesive manner. The book starts with an introductory chapter by one of the editors (Ashish Ghosh) where he discusses the use of evolutionary algorithms, particularly genetic algorithms and genetic programming, in data mining and knowledge discovery with some applications. Chapters 2-4 describe how to use EC for feature selection/preprocessing. In Chapter 2, Cano, Herrera and Lozano have carried out an empirical study using different size data sets to evaluate the scaling up problem. The results show that the stratified evolutionary instance selection algorithms consistently outperform the non-evolutionary ones. The main advantages that they found are: better instance reduction rates, higher classification accuracy and reduction in resources consumption. In the next chapter Smith and Bull have examined the use of Genetic Programming and a Genetic Algorithm to pre-process data before it is classified using the C4.5 and decision tree learning algorithms. Genetic Programming is used to construct new features from those available in the data, a potentially significant process for data mining since it gives consideration to hidden relationships between features. A Genetic Algorithm is used to determine which such features are the most predictive. Using ten well-known datasets they have shown that their approach, in comparison to C4.5 alone, provided marked improvement in a number of cases. In the fourth chapter Sikora presented a multi-agent based inductive learning algorithm for scaling up and improving the performance of traditional algorithms; the system used genetic algorithms as learning agents incorporating a self-adaptive feature selection method. Chapters 5-7 discuss the use of EC for rule generation. In Chapter 5 Fu and Wang proposed a decompositional rule extraction method based on radial basis function neural networks. In the proposed rule extraction method, rules are extracted from trained RBF networks with class-dependent features. Genetic Algorithm is used to determine the feature subsets corresponding to different classes. Rules are extracted from trained RBF networks by a gradient descent method. The chapter by Yu, Tan and Lee discusses a coevolutionbased classification technique, which they call CORE (COevolutionary Rule Extractor), that discovers cohesive classification rules. The proposed system coevolves rules and rule sets concurrently in two cooperative populations to confine the search space and to produce good rule sets that are cohesive and comprehensive. Comparison results show that the proposed CORE produces comprehensive and good classification rules for most datasets, obtained from UCI machine learning repository, which are competitive as compared with existing classifiers in literature. Nguyen, Abbass, and McKay showed in Chapter 7 that combining different neural networks can improve the generalization ability of learning machines for rule discovery. Diversity of the ensemble's members plays a key role in minimizing the combined bias and variance of the ensemble. In this chapter, we compare between different mech-

Preface

VII

anisms and methods for promoting diversity in an ensemble. In general, they found that it is important to design the diversity promoting mechanism very carefully for the ensemble's performance to be satisfactory. In Chapter 8 Nasraoi and Krishnapuram prsented a robust clustering algorithm, called the Unsupemrised Niche Clustering algorithm (UNC), that overcomes all the above difficulties. UNC can successfully find dense areas (clusters) in feature space and determines the number of clusters automatically. Robust cluster scale estimates were dynamically estimated using a hybrid learning scheme coupled with the genetic optimization of the cluster centers, to adapt to clusters of different sizes and noise contamination rates. Genetic Optimization enables this approach to handle data with both numeric and qualitative attributes, and general subjective, n o n metric, even non-differentiable dissimilarity measures. Next four chapters are on application of EC in several aspects of data mining. In Chapter 9 Abraham showed how EC can be used for intrusion detection in computer systems, as well as web usage mining to discover useful knowledge from the secondary data obtained from the interactions of the users with the web. He also compared the performance with other techniques to establish the superiority of EC based techniques. In Chapter 10 Langdon and Barrett used genetic programming (GP) to automatically create interpretable predictive models of oral bioavailability of a small number of complex biological interactions that are of great interest to medicinal and computational chemists who search for new drug treatments. The models can make i n silico predictions about "virtual" chemicals, e.g. to decide if they are to be synthesized. FOGEL, in Chapter 11, provided a recent state-of-the-art literature survey on the application of evolutionary algorithms in the area of microarray data establishing that simulated evolution provides better predictive models for the same. In Chapter 12 KOdiscussed a modularized financial distress forecasting mechanism based on evolutionary algorithm, which allows using any evolutionary algorithm, such as Particle Swarm Optimization, Genetic Algorithm and etc., to extract the essential financial patterns. One more evaluation function modules, such as Logistic Regression, Discriminant Analysis, Neural Network, are integrated to obtain better forecasting accuracy by assigning distinct weights, respectively. Specifically they applied evolutionary algorithm to select critical financial ratios and obtained better forecasting accuracy. This model when integrated by other classification models like logistic regression, neural networks etc. showed a much better performance. We are grateful to the contributors and the referees for their vision and efforts.

Kolkata, India, April 2004 Adelaide, Australia, April 2004

Ashish Ghosh Lakhmi C. Jain

Table of Contents

1 Evolutionary Algorithms for Data Mining and Knowledge

.

Discovery AshishGhosh

...............................................

1

1.1 Introduction ........................................... 1.2 Knowledge Discovery in Databases . . . . . . . . . . . . . . . . . . . . . . . . 1.2.1 Data Preprocessing ............................... 1.2.2 Data Mining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.2.3 Knowledge Interpretation or Postprocessing . . . . . . . . . . 1.2.4 Desirable Properties of Discovered Knowledge . . . . . . . . 1.2.5 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.3 Genetic Algorithms (GAS) for Rule Discovery . . . . . . . . . . . . . . 1.3.1 Association Rule Mining Algorithms: An Overview ... 1.3.2 Individual Representation . . . . . . . . . . . . . . . . . . . . . . . . . 1.3.3 Representing the Rule Antecedent (a Conjunction of Conditions) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.3.4 Representing the Rule Consequent (Predicted Class) . . 1.3.5 Genetic Operators for Rule Discovery . . . . . . . . . . . . . . . 1.3.6 Fitness Functions for Rule Discovery ................ 1.4 Multi-Objective Optimization and Rule Mining Problems . . . . 1.4.1 Model of Ghosh and Nath . . . . . . . . . . . . . . . . . . . . . . . . . 1.5 Discussion and Research Directions ....................... References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1 2 2 3 5 6 6 9 9 10
11 12 12 14 15 16 18 19

2 Strategies for Scaling Up Evolutionary Instance Reduction Algorithms for Data Mining Jose Ramon Cano. Francisco Herrera. and Manuel Lozano ......... 21

.

2.1 Introduction ........................................... 2.2 Instance Selection on Data Reduction . . . . . . . . . . . . . . . . . . . . . 2.2.1 Instance Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.2.2 Instance Selection for Prototype Selection ........... 2.2.3 Overview of Instance Selection Algorithms ........... 2.3 Evolutionary Instance Selection Algorithms ................ 2.3.1 Evolutionary Instance Selection: Key Points ......... 2.3.2 The CHC Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

21 23 23 23 24 25 26 26

X

Table of Contents 2.4 The Scaling up Problem . The Stratified Approach .......... 2.4.1 Scaling up and Stratification . . . . . . . . . . . . . . . . . . . . . . . 2.4.2 Evolutive Algorithms and Stratification Strategy . . . . . 2.5 Experimental Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.5.1 Data Sets and Parameters . . . . . . . . . . . . . . . . . . . . . . . . . 2.5.2 Partitions and Stratification: A Specific Model ....... 2.5.3 Table of Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.6 Experimental Study .................................... 2.6.1 Medium Size Data Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.6.2 Large Size Data Set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.7 Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . References .................................................

3 GAP: Constructing and Selecting Features with

.

Evolutionary Computing Matthew G . Smith and Larry Bull
3.1 3.2

............................. Introduction ........................................... The GAP Algorithm ....................................

3.2.1 Feature Creation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2.2 Feature Selection ................................. 3.3 Experimentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.3.1 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.3.2 Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.3.3 The Importance of Reordering the Dataset . . . . . . . . . . 3.3.4 Combining Creation and Selection in a Single Stage . . . 3.3.5 A Rough Comparison to Other Algorithms . . . . . . . . . . 3.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4 Multi-Agent Data Mining using Evolutionary Computing Riyaz Sikora ................................................

.

4.1 Introduction ........................................... 4.2 Relatedwork . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.2.1 Feature Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.2.2 Distributed Data Mining . . . . . . . . . . . . . . . . . . . . . . . . . . 4.3 Data Mining with GA ................................... 4.4 Feature Selection as Self-Adaptation . . . . . . . . . . . . . . . . . . . . . . 4.5 Multi-Agent Data Mining ............................... 4.6 Experimental Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.6.1 Experimental Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.6.2 Effectiveness of Feature Selection ................... 4.6.3 Effectiveness of DLS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.7 Conclusions and Future Work ............................ References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Table of Contents

XI

5 A Rule Extraction System with Class-Dependent Features Xiuju Fu and Lipo Wang . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
;

.

79

5.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 5.1.1 Rule Extraction Systems . . . . . . . . . . . . . . . . . . . . . . . . . . 79 5.1.2 Categories of Rule Extraction Systems . . . . . . . . . . . . . . 81 5.1.3 Data Dimensionality Reduction . . . . . . . . . . . . . . . . . . . . 82 5.2 Our Rule Extraction System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87 5.3 RBF Classifiers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88 5.3.1 A Conventional RBF Classifier . . . . . . . . . . . . . . . . . . . . . 88 5.3.2 A Novel RBF Classifier ........................... 89 5.3.3 Feature Masks Encoded by GA . . . . . . . . . . . . . . . . . . . . 91 5.4 Rule Extraction by the Gradient Descent Method . . . . . . . . . . 92 5.5 Experimental Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95 5.5.1 Thyroid Data Set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95 5.5.2 Wine Data Set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96 5.5.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
6 Knowledge Discovery in Data Mining via an Evolutionary Algorithm Qi Yu. Kay Chen Tan. and Tong Heng Lee ..............

.

6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101 6.2 Coevolutionary Rule Extractor . . . . . . . . . . . . . . . . . . . . . . . . . . . 103 6.2.1 Coevolutionary Algorithms . . . . . . . . . . . . . . . . . . . . . . . . 103 6.2.2 Overall Flowchart of CORE . . . . . . . . . . . . . . . . . . . . . . . 104 6.2.3 Population and Chromosome Structure . . . . . . . . . . . . . . 106 6.2.4 Genetic Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107 6.2.5 Fitness Evaluations ............................... 107 6.2.6 Token Competition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108 6.3 Case Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109 6.3.1 Experimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109 6.3.2 Simulation Results and Comparisons . . . . . . . . . . . . . . . . 109 6.3.3 Discussion and Summary . . . . . . . . . . . . . . . . . . . . . . . . . . 118 6.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121 References ................................................. 121
7 Diversity and Neuro-Ensemble Minh Ha Nguyen. Hussein Abbass. and Robert McKay

.

........... 125 7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125 7.2 Ensemble of Predictors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126

7.2.1 Forming and Selecting the Individual Networks ....... 126 7.2.2 Combining Neural Networks to form the Ensemble . . . 128 7.2.3 Review of Diversity Promotion Mechanisms . . . . . . . . . . 129

XI1

Table of Contents 7.2.4 Review of the use of Diversity in Selecting the Members for the Ensemble . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132 7.3 Comparisons of Different Ensemble Methods . . . . . . . . . . . . . . . 134 7.3.1 Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134 7.3.2 Evolutionary Multi Objective Optimization Application in Ensemble . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136 7.3.3 Experiment Set-up . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138 7.3.4 Results and Analysis .............................. 141 7.4 Conclusion ............................................ 150 References ................................................. 153

8 Unsupervised Niche Clustering:

.

Discovering an Unknown Number of Clusters in Noisy Data Sets Olfa Nasraoui. Elizabeth Leon. and Raghu Krishnapuram ........ 157

. 8.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .157 8.1.1 Unsupervised Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . 158 8.1.2 Motivations for Evolutionary Clustering . . . . . . . . . . . . . 158 8.1.3 Why Genetic Niching? . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159 8.2 Genetic Niching . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160 8.3 An Overview of Existing Evolutionary Clustering Techniques 161 8.4 New Approach to Unsupervised Robust Clustering using Genetic Niching .......................................... 163 8.4.1 Representation ................................... 163 8.4.2 Fitness Function ................................. 164 8.4.3 Analogy between Density and Scale in Artificial Niches and Fertility and Barrier Constraints in Natural Niches 166 8.4.4 A Baldwin Effect for Scale Estimation .............. 166 8.4.5 Mating Restriction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168 8.4.6 Scale Inheritance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169 8.4.7 Crossover and Mutation . . . . . . . . . . . . . . . . . . . . . . . . . . . 169 8.4.8 Incorporating Constraints Against Degenerate and Spurious Solutions ................................... 169 8.4.9 Selecting the Initial Population ..................... 171 8.4.10 Extracting Cluster Centers From the Final Population 171 8.4.11 Refinement of the Extracted Prototypes ............. 172 8.4.12 The Unsupervised Niche Clustering Algorithm (UNC) . 173 8.4.13 Computational Complexity . . . . . . . . . . . . . . . . . . . . . . . . 173 8.5 Simulation Results on Synthetic Examples ................. 174 8.5.1 Detailed Phases of Cluster Evolution . . . . . . . . . . . . . . . . 174 8.5.2 Sensitivity to GA Parameters, Noise, and Effect of Final Refinement ................................... 174

Table of Contents

XI11

8.5.3 Simulation Results for Data with Varying Number of Clusters. Cluster Sizes. Densities. and Noise Contamination Rates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8.6 Application to Image Segmentation . . . . . . . . . . . . . . . . . . . . . . . 8.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

178 179 185 186

9 Evolutionary Computation in Intelligent Network Management Ajith Abraham . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .189

.

9.1 Intrusion Detection Systems ............................. 189 9.1.1 Intrusion Detection .a Data Mining Approach . . . . . . . 191 9.1.2 Linear Genetic Programming (LGP) ................ 192 9.1.3 Decision Trees (DT) as Intrusion Detection Model . . . . 192 9.1.4 Support Vector Machines (SVM) . . . . . . . . . . . . . . . . . . .193 9.1.5 Intrusion Detection Data . . . . . . . . . . . . . . . . . . . . . . . . . . 193 9.1.6 Discussions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198 9.2 Web usage Mining using Intelligent Miner (i-Miner) . . . . . . . . . 198 9.2.1 Optimization of Fuzzy Clustering Algorithm . . . . . . . . . 199 9.2.2 Optimization of the Fuzzy Inference System . . . . . . . . . 200 9.2.3 Discussions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206 9.3 Conclusions ............................................ 206 References ................................................. 209
10 Genetic Programming in Data Mining for Drug

.

Discovery W . B . Langdon and S. J . Barrett

............................. 211 10.1 Computational Drug Discovery ........................... 213

10.2 Evolutionary Computing for Drug Discovery ............... 214 10.3 Oral Bioavailability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214 10.4 Genetic Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215 10.5 Receiver Operating Characteristics . . . . . . . . . . . . . . . . . . . . . . . 215 10.5.1 Simple use of ROC as the Objective to be Maximized . 216 10.6 The Bioavailability Data ................................ 221 10.7 Chemical Features ...................................... 221 10.8 Genetic Programming Configuration . . . . . . . . . . . . . . . . . . . . . . 223 10.8.1 Function set ..................................... 223 10.8.2 Terminal set ..................................... 223 10.8.3 GP Genetic Operations and other Parameters . . . . . . . . 223 10.8.4 GP Fitness Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225 10.9 Experiments ........................................... 225 10.9.1 Training on 321 Human Records . . . . . . . . . . . . . . . . . . . 226 10.9.2 Training on 1342 Rat Records . . . . . . . . . . . . . . . . . . . . . . 226 10.9.3 Simplification of Evolved Model of Rat Bioavailability. 228

XIV

Table of Contents 10.10Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231 10.11 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232

11. Microarray Data Mining with Evolutionary Computation GaryB.Foge1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237

11.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237 11.2 Microarrays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238 11.3 Supervised and Unsupervised Methods for Microarray Analysis239 11.3.1 Supervised Methods of Class Assignment . . . . . . . . . . . . 239 11.4 Evolutionary Computation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241 11.4.1 Evolutionary Computation in Bioinformatics . . . . . . . . . 242 11.5 Applications of Evolutionary Computation for Class Prediction and Expression Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . 242 11.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .245
12. An Evolutionary Modularized Data Mining

Mechanism for Financial Distress Forecasts Po-Chang (P.C.) KO and Ping-Chen (P.C.) Lin . . . . . . . . . . . . . . . . . 249
12.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .249 12.2 Evolutionary Modularized Mining Mechanism . . . . . . . . . . . . . . 250 12.2.1 Exploration Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .251 12.2.2 Transformation Process . . . . . . . . . . . . . . . . . . . . . . . . . . . 252 12.2.3 Mining Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252 12.3 Implementations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253 12.4 Performance Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256 12.4.1 Exploration Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256 12.4.2 Mining Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257 12.4.3 Simulation Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258 12.5 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261 . References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262

Subject Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .264

List of Contributors

A. A b r a h a m Natural Computation Lab Department of Computer Science Oklahoma State University,USA ajith. abraham@ieee.org

University of Huelva 21819, Huelva, Spain jose. cano@diesia.uhu. es

G. B. Fogel Natural Selection, Inc. 3333 N. Torrey Pines Ct., Suite 200 H. Abbass Artificial Life and Adaptive Robotics La Jolla, California 92037 USA (A.L.A.R.) Lab School of Information Technology gfogel@natural-selection. corn and Electrical Engineering X. J. Fu Australian Defence Force Academy Institute of High Performance ComUniversity of New South Wales, puting Canberra, ACT 2600, Australia Science Park 2, 117528 h.abbass@adfa.edu.au Singapore fuxj@ihpc. a-star. edu. sg S . J. B a r r e t t Data Exploration Sciences A. Ghosh GlaxoSmithKline Machine Intelligence Unit Research and Development Indian Statistical Institute Greenford, Middlesex 203 B. T. Road UK Kolkata 700 108, India ash@isical.ac.in L. Bull Faculty of Computing, Engineering F. H e r r e r a & Mathematical Sciences Dept. of Computer Science and ArtiUniversity of the West of England ficial Intelligence Bristol BS16 1QY University of Granada U.K. 18071, Granada, Spain Larry.Bull@uwe.ac.uk herrera@decsai.ugr. es J. R. C a n o P. C. KO Dept. of Electronic Engineering National Kaohsiung University of Computer Systems and Automatics Applied Sciences Escuela Superior de La Rabida

XVI

List of Contributors

Department of Information Manage- and Electrical Engineering Australian Defence Force Academy ment Kaohsiung Univessity of New South Wales, Taiwan 807, R.0.C Canberra, ACT 2600, Australia cobol@cc.kuas.edu. tw

W. B. Langdon
Data Exploration Sciences GlaxoSmithKline, Research and Development, Greenford, Middlesex, UK

Olfa Nasraoui Department of Electrical and Computer Engineering The University of Memphis 206 Engineering Science Bldg. Memphis, TN 38152-3180 onasraou@memphis.edu

T. H. Lee Department of Electrical and Computer Engineering National University of Singapore 4 Engineering Drive 3 Singapore 117576

Raghu Krishnapuram IBM India Research Lab Block 1, Indian Institute of Technology Hauz Khas, New Delhi 110016, India kraghura@in.ibm. com

Elizabeth Leon Department of Electrical and Com- M. H. Nguyen Artificial Life and Adaptive Robotics (A.L.A.R.) Lab puter Engineering School of Information Technology The University of Memphis, and Electrical Engineering 206 Engineering Science Bldg. Australian Defence Force Academy Memphis, TN 38152-3180 University of New South Wales, Canberra, ACT 2600, Australia P. C. Lin m.nguyen@adfa.edu. au Van Nung Institute of Technology Department of Information ManageR. Sikora ment Dept. of Information Systems & OM Jungli, Taiwan 320, R.0.C The University of Texas at Arlington lety@cc.vit.edu. tw P.O. Box 19437, Arlington, TX 76019 rsikora@uta.edu M. Lozano Dept. of Computer Science and ArtiM. G . Smith ficial Intelligence Faculty of Computing, Engineering University of Granada & Mathematical Sciences 18071, Granada, Spain University of the West of England lozano@decsai.ugr.es Bristol BS16 1QY U.K. R. McKay Artificial Life and Adaptive Robotics Matt-Smith@bigfoot.com (A.L.A.R.) Lab School of Information Technology

List of Contributors

XVII

K. C. Tan Department of Electrical and Computer Engineering National University of Singapore 4 Engineering Drive 3 Singapore 117576 eletankc@nus.edu.sg

Nanyang Technological University (NTU) Nanyang Avenue, Singapore 639798 elpwang@ntu. edu.sg

Q. Yu Department of Electrical and Computer Engineering National University of Singapore L. P. Wang School of Electrical and Electronic 4 Engineering Drive 3 Singapore 117576 Engineering

1. Evolutionary Algorithms for Data Mining and Knowledge Discovery
Ashish Ghosh
Machine Intelligence Unit Indian Statistical Institute 203 B. T. Road Kolkata 700 108, India ash@isical.ac.in

Abstract: This chapter discusses the use of evolutionary algorithms, particularly genetic algorithms, in data mining and knowledge discovery. We focus on the data mining task of rule generation. We show how the requirements of data mining and knowledge discovery influence the design of evolutionary algorithms. In particular, we discuss how individual representation, genetic operators and fitness functions have to be adapted for extracting rules from data. We also discussed an algorithm for using multi-objective evolutionary algorithms for rule mining.

1.1 Introduction
Since 1960, database technology and information technology have been evolving systematically from primitive file processing to sophisticated powerful database systems through the development of DBMS. But the explosive growth in the data collected from various application areas are continuously increasing in recent times. Intuitively, this large amount of stored data contains valuable hidden knowledge, which could be used to improve the decisionmaking process of an organization. For instance, data about previous sales might contain interesting relationships between products and customers. The discovery of such relationships can be very useful to increase the sale of a company. No human can use such a big volume of data in an efficient way. Thus, there is a clear need for semi-automatic methods for extracting knowledge from data. This need has led to the emergence of a field called data mining and knowledge discovery (KDD) [1.16, 1.5, 1.1, 1.271. This is an interdisciplinary field, using methods of several research areas (specially machine learning and statistics) to extract knowledge from real-world data sets. Data mining is the core step of a broader process, called knowledge discovery from databases. This whole process includes application of several preprocessing methods aimed at facilitating application of the data mining algorithms and postprocessing methods for refining and improving the discovered knowledge. This chapter discusses the use of evolutionary algorithms (EAs), particularly genetic algorithms (GAS) [1.15, 1.221 in KDD process. We mainly focus on rule mining. We show how the requirements of data mining and knowledge

2

Ghosh

discovery influence the design of GAS. In particular, we discuss how individual representation, genetic operators and fitness functions have to be adapted for extracting knowledge from data bases. We also discussed an algorithm for using multi-objective evolutionary algorithms for rule mining. This chapter is organized as follows. Section 2 presents an overview of data mining and knowledge discovery process. Section 3 discusses several aspects of the design of GAS for rule discovery. Section 4 discusses the use of multiobjective GAS for rule discovery. Finally, Section 5 presents a discussion that concludes the chapter.

1.2 Knowledge Discovery in Databases
Data collected from various application domains is becoming increasingly high in recent time. They are stored in various repositories like different databases (such as relational databases, transactional databases, objectrelational databases, object-oriented databases etc.), different data warehouses (repository of multiple heterogeneous data for long term and providing online analytical processing), and other repositories (such as WWW data, biological data, text data, image data, multimedia data etc.).
1.2.1 Data Preprocessing

During the recording or storing of data in the repositories, it is obvious that some error will be there. Such errors may be missing values, noise, inconsistency etc and the data may not be in suitable format for processing. So, before going to perform mining on the data some kind of preprocessing [1.16, 1.18, 1.241 is required. Preprocessing of data is done in the following major ways.

Data cleaning. To remove inconsistency, noise , to fill up missing values, to identify the outliers etc., data cleaning is performed. The missing values are filled up manually or using some global constants. Noises are smoothed using binning, regression analysis etc. Data integration. This is needed to combine data from multiple sources like databases, data cubes, flat files etc. The integration can be done in terms of metadata, correlation analysis, detecting data conflict, and resolving semantic heterogeneity. Correlation analysis measures how one attribute strongly implies the other based on available data. Data conflicts are detected by identifying the difference among the real world attribute values [say price can be expressed in Rs, $ etc.]. Finally, the semantic heterogeneities are removed.

1. EAs for KDD

3

Data transformation. The format of data in the repositories may not be suitable for processing. So, the format of the data should be transformed to a one suitable for a particular task. This is done for smoothing, aggregation, generalization, normalization, and attribute construction. Smoothing uses binning, clustering, regression analysis etc. Aggregation is done in terms of summarization [say daily sales may be summarized or aggregated to compute monthly, yearly e t ~ . ] Generalization is done using the concept of "hi. erarchies of data" where low-level data are replaced by high-level data [say, for age we can represent as young, old, senior, junior etc]. Normalization is done in terms of scaling the attribute data so as to fall within a small range [say, to have data values between the range 0.0 to 1.01. New attributes are constructed from the given data sets with desired format. Discretization. This step consists of transforming a continuous attribute into a categorical (or nominal) attribute, taking only a few discrete values e.g., the real-valued attribute. Salary can be discretized to take on only three values, say "low", "medium", and "high". This step is particularly required when the data mining algorithm cannot cope with continuous attributes. In addition, discretization often improves the comprehensibility of the discovered knowledge. Data reduction. To have reduced representation of data sets that is necessary for efficient mining this step is used. This data reduction is done in terms of dimensionality reduction, data cube aggregation, data compression, numerosity reduction etc. Dimensionality reduction is done removing some features from the data sets. Different data cubes are aggregated in order to have desired representation of data. Numerosity of the data is reduced using alternatives like sampling, histogram etc. Data selection. For the purpose of processing and analysis, relevant data are selected and retrieved in this step.
1.2.2 Data Mining

In order to extract or mine the knowledge or pattern of interest from the data that is ready after preprocessing task, intelligent mining tools are applied. These tools or methods are association analysis, clustering, classification and prediction, dependence analysis, and outlier analysis.

Association analysis:. Discovery of association relationship among large set of data items is useful in decision-making. This can be better understood with a typical example called market basket analysis, which studies customer buying habits by finding associations between the different items that customers place in their baskets. For instance, if customers are buying milk, how likely are they to buy bread on the same trip to the market? An association rule is thus a relationship of the form IF A THEN B, where A and B are sets of items and A n B = 8. Such a rule generation technique consists of finding

4

Ghosh

frequent item sets (set of items, such as A and B satisfying minimum support and minimum confidence) from which rules like A=>B are generated. The measures support is the percentage of transactions that contain both the item sets. Thus Support (A U B) = p(A U B) Confidence (A=>B) =*

Classification and prediction. Classification is a process of finding a set of models or functions that describes and distinguishes data classes, for the purpose of using it. This derived model is based on the analysis of a set of training data object (i.e. data objects whose class labels are known). Classification rules can be considered as a particular kind of prediction rules where the rule antecedent ("IF part") contains a combination - typically, a conjunction - of conditions on predicting attributes, and the rule consequent ("THEN part") contains a predicted value for the goal attribute. Examples of classification rules are: IF (UnpaidLoan? = "no") and (Current-account-balance > $ 3,000) THEN (Credit = "good") IF (UnpaidLoan = "yes") THEN (Credit = "bad"). Although both classification and association rules have an IF-THEN structure, there are major differences between them. Major differences are: association rules can have more than one item in the consequent part, whereas classification rules always have one attribute (the goal one) in the consequent. In other words, for classification rules , predicting attributes and the goal attribute. Predicting attributes can occur only in the rule antecedent, whereas the goal attribute occurs only in the rule consequent. Dependence modelling. This task can be regarded as a generalization of the classification task. In the former we want to predict the value of several attributes - rather than a single goal attribute, as in classification. In its most general form, any attribute can occur both in the antecedent of a rule and in the consequent of another rule - but not in both the antecedent and the consequent of the same rule. For instance, we might discover the following two rules: IF (Current-account-balance > $3,000) AND (Salary = "high") THEN (Credit = "good") IF (Credit = "good") AND (Age > 21) THEN (GrantLoan = "yes"). Clustering. In a huge data set objects can be identified to keep them in different groups. The process of grouping a set of data objects that are similar to one another within the same cluster and are dissimilar to objects in other cluster is called clustering. The similarity and dissimilarity are measured in terms of some distance measure. For classification the class label of a training example is given as input to the classification algorithm, characterizing a form of supervised learning. In contrast, the clustering task discover classes by itself, by partitioning the examples into clusters, which is a form of unsupervised learning [1.8]. Note that, once the clusters are found, each cluster can be considered as a "class",

1. EAs for KDD

5

and one can run a classification algorithm on the clustered data, by using the cluster name as a class label. So many clustering algorithms have been developed: and they can broadly be classified as partitioning method, hierarchical method, density-based method, grid based method, model based method. Outlier analysis:. In the whole data set, some data objects do not comply with the general behavior of the data. They are grossly different or inconsistent from the remaining set of data. These data objects are called outliers. For example, salary of the chief executive to other employees in a company can be considered as an outlier for the salary data set. This kind of outliers can be analyzed in terms of detection of these outlier data objects using various approaches including statistical, distance-based and deviation-based approaches are used.
1.2.3 Knowledge Interpretation o r Postprocessing

Knowledge interpretation is the last step in the KDD process. Extracted patterns are required to be interpreted properly, so that they can be used for decision making; i.e. to interpret the knowledge that the patterns are carrying. Patterns representing knowledge are evaluated i.e. identified properly by interestingness measures. A pattern will be interesting if
-

it is easily understood by humans (i.e. simplicity of the pattern) potentially useful validates a hypothesis that the user sought to confirm.

- valid on test data with some degree of certainty - novel,
Once the patterns are evaluated and discovered, they are presented to the users for interaction and to guide them for further discovery. This is done using visualization techniques, which includes tables, crosstabs (crosstabulations), pie charts, bar charts, decision trees, rules etc. It is often the case that the knowledge discovered by a data mining algorithm needs to undergo some kind of postprocessing. There are two main motivations for such postprocessing. First, when the discovered rule set is large, we often want to simplify it - i.e. to remove some rules and/or rule conditions - in order to improve knowledge comprehensibility for the user. Second, we often want to extract a subset of interesting rules, among the discovered ones. The reason is that although many data mining algorithms were designed to discover accurate, comprehensible rules, most of these algorithms were not designed to discover interesting rules, which is a rather more difficult and ambitious goal. Methods for selection of interesting rules can be roughly divided into subjective and objective methods. Subjective methods are user-driven and

6

Ghosh

domain-dependent. For instance, the user may specify rule templates, indicating which combination of attributes must occur in the rule for it to be considered interesting - this approach has been used mainly in the context of Another example of a subjective method, the user can association rules [1.11]. give the system a general, high-level description of his/her previous knowledge about the domain, so that the system can select only the discovered 1. rules which represent previously-unknown knowledge for the user [I.1 1 By contrast, objective methods are data-driven and domain-independent. Some of these methods are based on the idea of comparing a discovered rule against other rules, rather than against the user's beliefs. In this case the basic idea is that the interestingness of a rule depends not only on the quality of the rule itself, but also on its similarity to other rules. [1.11].
1.2.4 Desirable Properties of Discovered Knowledge

In essence, data mining consists of the semi-automatic extraction of knowledge from data. This statement raises the question of what kind of knowledge we should try to discover. Although this is a subjective issue, we can mention three general properties that the discovered knowledge should satisfy; namely, it should be accurate, comprehensible, and interesting. Let us briefly discuss each of these properties in turn. As will be seen in the next subsection, in data mining we are often interested in discovering knowledge which has a certain predictive power. The basic idea is to predict the value that some attribute(s) will take on in "future", based on previously observed data. In this context, we want the discovered knowledge to have a high predictive accuracy. We also want the discovered knowledge to be comprehensible for the user. This is necessary whenever the discovered knowledge is to be used for supporting a decision to be made by a human being. If the discovered "knowledge" is just a black box, which makes predictions without explaining them, the user may not trust it [1.16]. Knowledge comprehensibility can be achieved by using high-level knowledge representation. A popular one is a set of IF-THEN rules, where each rule is of the form: IF <some-conditions-aresatisfied> THEN <predictsome-valuefor-an-attribute>. The third property, knowledge interestingness, is the most difficult one to define and quantify, since it is, to a large extent, subjective. However, there are some aspects of knowledge interestingness that can be defined in objective terms.

1 2 5 Applications .. Spatial data mining. A spatial database stores a large amount of spacerelated data, such as maps, preprocessed remote sensing or medical imaging

1. EAs for KDD

7

data and VLSI chip layout data. They carry topological and/or distance information and usually organized by multidimensional structure using data cubes. Spatial data mining refers to the extraction of knowledge like spatial relationship or other interesting patterns from large geo-spatial databases.

Web mining. With the explosive growth of information sources available on the World Wide Web (WWW), it has become increasingly necessary for users to utilize automated tools in order to find, filter, and evaluate the desired information and resources [1.6, 1.231. Web mining can be broadly defined as the discovery and analysis of useful information from the WWW. In order to mine the web basically two ideas are used. Web content mining: here the idea is automatic search and retrieval of the information. Web usage mining: the basic idea here is to automatic discovery and analysis of user access patterns from one or more web servers. Text mining. In recent days we can have databases, which contain large collection of documents from various sources such as news articles, research papers, books, digital libraries, e-mail messages, and various web pages which are called text databases or document databases. These text databases are rapidly growing due to the increasing amount of information available in electronic forms, such as electronic publications, e-mails, CD-ROMs etc. Data stored in most text databases are semi-structured data, in that they are neither completely unstructured nor completely structured. For example, a document may contain a few structured fields, such as title, authors, publication date, category and so on, but also contain some largely unstructured text component such as abstract and contents. This type of text data has challenges to the traditional retrieval techniques. As a result, text-mining concepts are increasingly coming into light. Text mining goes one step beyond the traditional approach and discovers knowledge from semi-structured text data also. Image mining. Actually image mining i.e. mining the image databases falls under the multimedia database mining, which also contains audio data, video data along with image data. Basically images are stored with some description against a particular image. Again images are nothing but some intensity values, which figure the image in terms of color, shape, texture etc. The mining task is based on using such information contained in the images. Based on this image mining techniques can be categorized in two places:
-

description based retrieval, and

- content based retrieval
Biological data mining. Biological researches are dealing greatly in development of new pharmaceutical, various therapies, medicines and human genome by discovering large-scale sequencing patterns and gene functions. In the process of gene technology the DNA data analysis becomes significantly focused with data mining applications, since the discovery of genetic causes

8

Ghosh

for many diseases and disabilities and to discover new medicines as well as disease diagnosis, prevention, and treatment DNA analysis is a must. The DNA sequences form the foundation of the genetic code of all living organisms. All DNA sequences comprised four basic nucleotides [i.e. Adenine (A), Cytosine (C), Guanine (G), Thiamine (T)]. These four nucleotides are combined in different orders to form long sequences or chains in the structure of DNA. There are almost an unlimited number of ways that the nucleotides can be ordered and sequenced which play important role in various diseases. It is a challenging task to identify such a particular sequence from among the unlimited sequences, which are actually responsible for various diseases. Now people are trying to use data mining techniques to search and analyze these sequence patterns. In addition to DNA sequencing, linkage analysis, and association analysis (where the structure, function, next generation genes, co-occurring genes etc) are also studied. For all these machine learning, association analysis, pattern matching, sequence alignments, Bayesian learning etc techniques are being used in bioinformatics recently I1.17, 1.261. A recent technology called Microarry, is being used in bio-informatics, which provides the experimental approach to measure levels of gene expression, subject to growth, stress and some other conditions. Levels are determined by some ratio of signal expression with the help of laser scanner. Then the intensity values are used to create an image file, from where image-mining techniques are invoked

Scientific data mining. Computational simulations and data acquisition in a variety of scientific and engineering domains have made tremendous progress over the past few decades [1.25]. Coupled with the availability of massive storage systems and fast networking technology to manage and assimilate data, these have given a significant impetus to data mining in scientific domains. In other sense, we can say that data mining has become a key computational technology applying in various domains such as geological and geophysical applications, astrophysics, bio-informatics, chemical sciences etc. Distributed Data Mining. The evolution of KDD system from being centralized and stand alone along the dimension of data distribution signifies the emergence of distributed data mining (DDM). More precisely in that, when data mining is undertaken in an environment, where users, data, hardware, and the mining software are geographically dispersed, will be called DDM. Typically such environments are also characterized by the heterogeneity of data, multiple users, and large data volumes. In the following sections, we describe the utility of GAS for a specific problem of data mining, namely rule mining.

1. EAs for KDD

9

1.3 Genetic Algorithms (GAS) for Rule Discovery
1.3.1 Association Rule Mining Algorithms: An Overview

Existing algorithms for mining association rules are mainly based on the approach suggested by Agrawal et al. [1.2]. Apriori [1.2], SETM [1.9], AIS [1.2], Pincer search [1.10], DIC [1.4] etc. are some of the popular algorithms based on this approach. These algorithms work on a binary database, termed as market basket database. On preparing the market basket database, every record of the original database is represented as a binary record where the fields are defined by a unique value of each attribute in the original database. The fields of this binary database are often termed as an item. For a database having a huge number of attributes and each attribute containing a lot of distinct values, the total number of items will be huge. Storing of this binary database, to be used by the rule mining algorithms, is one of the limitations of the existing algorithms. Another aspect of these algorithms is that they work in two phases. The first phase is for frequent item-set generation. Frequent item-sets are detected from all-possible item-sets by using a measure called support count (SUP) and a user-defined parameter called minimum support. Support count of an item set is defined by the number of records in the database that contains all the items of that set. If the value of minimum support is too high, number of frequent item sets generated will be less, and thereby resulting in generation of few rules. Again, if the value is too small, then almost all possible item sets will become frequent and thus a huge number of rules may be generated. Selecting better rules from them may be another problem. After detecting the frequent item-sets in the first phase, the second phase generates the rules using another user-defined parameter called minimum confidence (which again affects the generation of rules). Confidence factor or predictive accuracy of a rule is defined as Confidence = S U P (AUC)/SUP ( A ) for a rule A + C. Another limitation of these algorithms is the encoding scheme where separate symbols are used for each possible value of an attribute. This encoding scheme may be suitable for encoding the categorical valued attributes, but not for encoding the numerical valued attributes as they may have different values in every record. To avoid this situation, some ranges of values may be defined. For each range of values an item is defined. This approach is also not suitable for all situations. Defining the ranges will create yet another problem, as the range of different attributes may be different. GA based approach is free from this limitations. Existing algorithms, try to measure the quality of generated rules by considering only one evaluation criterion, i.e., confidence factor or predictive accuracy. This criterion evaluates the rule depending on the number of occurrence of the rule in the entire database. More the number of occurrences better is the rule. The generated rule may have a large number of attributes

10

Ghosh

involved in the rule thereby making it difficult to understand [1.11].If the generated rules are not understandable to the user, the user will never use them. Again, since more importance is given to those rules, satisfying number of records, these algorithms may extract some rules from the data that can be easily predicted by the user. It would have been better for the user, if the algorithms can generate some of those rules that are actually hidden inside the data. These algorithms do not give any importance towards the rare events, i.e., interesting rules [1.11]. In the present work we used the comprehensibility and the interestingness measure of the rules in addition to predictive accuracy. In the next section, we will discuss about them in detail. Using these three measures - comprehensibility, interestingness and the predictive accuracy, some previously unknown, easily understandable rules can be generated. Hence, the rule-mining problem is not a single objective problem; rather we visualize them as a multi-objective problem. In general the main motivation for using GAS in the discovery of highlevel prediction rules is that they perform a global search and cope better with attribute interaction than the greedy rule induction algorithms often used in data mining.

1 3 2 Individual Representation ..
GAS for rule discovery can be divided into two broad approaches, based on how rules are encoded in the population of individuals ("chromosomes"). In the Michigan approach each individual encodes a single prediction rule, whereas in the Pittsburgh approach each individual encodes a set of prediction rules. The choice between these two approaches strongly depends on which kind of rule we want to discover. This is related to which kind of data mining task we are addressing. Suppose the task is classification. Then we usually evaluate the quality of the rule set as a whole, rather than the quality of a single rule. In other words, the interaction among the rules is important. In this case, the Pittsburgh approach seems more natural. On the other hand, the Michigan approach might be more natural in other kinds of data mining tasks. An example is a task where the goal is to find a small set of high-quality prediction rules, and each rule is often evaluated independently of other rules. The Pittsburgh approach directly takes into account rule interaction when computing the fitness function of an individual. However, this approach leads to syntactically-longer individuals, which tends to make fitness computation more computationally expensive. In addition, it may require some modifications to standard genetic operators to cope with relatively complex individuals. By contrast, in the Michigan approach the individuals are simpler and syntactically shorter. This tends to reduce the time taken to compute the

fitness function and to simplify the design of genetic operators. However, this advantage comes with a cost. First of all, since the fitness function evaluates the quality of each rule separately, now it is not easy to compute the quality of the rule set as a whole - i.e. taking rule interactions into account. Another problem is that, since we want to discover a set of rules, rather than a single rule, we cannot allow the GA population to converge to a single individual - which is what usually happens in standard GAS. This introduces the need for some kind of niching method [1.21], which obviously is not necessary in the case of the Pittsburgh approach. We can avoid the need for niching in the Michigan approach by running the GA several times, each time discovering a different rule. The drawback of this approach is that it tends to be computationally expensive.
1.3.3 Representing the Rule Antecedent (a Conjunction of

Conditions)
A simple approach to encode rule conditions into an individual is to use a binary encoding. Suppose that a given attribute can take on k discrete values. Then we can encode a condition on the value of this attribute by using k bits. k) The i-th value (i=l, ..., of the attribute domain is part of the rule condition if and only if the i-th bit is "on" [1.11]. For instance, suppose that a given individual represents a rule antecedent with a single attribute-value condition, where the attribute is MaritalStatus and its values can be "single", "married", "divorced" and "widow". Then a condition involving this attribute would be encoded in the genome by four bits. If these bits take on, say, the values "0 1 1 O" then they would be representing the following rule antecedent: IF (Marital-Status = "married" OR "divorced" ) . Hence, this encoding scheme allows the representation of conditions with internal disjunctions, i.e. with the logical OR operator within a condition. Obviously, this encoding scheme can be easily extended to represent rule antecedents with several conditions (linked by a logical AND) by including in the genome an appropriate number of bits to represent each attribute-value condition. Note that if all the k bits of a given rule condition are "on", this means that the corresponding attribute is effectively being ignored by the rule antecedent, since any value of the attribute satisfies the corresponding rule condition. In practice, it is desirable to favor rules where some conditions are "turned off" - i.e. have all their bits set to "1" - in order to reduce the size of the rule antecedent. (Recall that we want comprehensible rules and, in general, the shorter the rule is the more comprehensible it is.) To achieve this, one can automatically set all bits of a condition to "1" whenever more than half of those bits are currently set to "1". The above discussion assumed that the attributes were categorical, also called nominal or discrete. In the case of continuous attributes the binary

12

Ghosh

encoding mechanism gets slightly more complex. A common approach is to use bits to represent the value of a continuous attribute in binary notation. For instance, the binary string "0 0 0 0 1 1 0 1" represents the value 13 of a given integer-valued attribute. Instead of using a binary representation for the genome of an individual, this genome can be expressed in a higher-level representation which directly encodes the rule conditions. One of the advantages of this representation is that it leads to a more uniform treatment of categorical and continuous attributes, in comparison with the binary representation. In any case, in rule discovery we usually need to use variable-length individuals, since, in principle, we do not know a priori how many conditions will be necessary to produce a good rule. Therefore, we might have to modify crossover to be able to cope with variable-length individuals in such a way that only valid individuals are produced by this operator.
1.3.4 Representing t h e Rule Consequent (Predicted Class)

Broadly speaking, there are three ways of representing the predicted class (the "THEN" part of the rule) in an evolutionary algorithm. The first possibility is to encode it in the genome of an individual - possibly making it subject to evolution. The second possibility is to associate all individuals of the population with the same predicted class, which is never modified during the running of the algorithm. Hence, if we want to discover a set of classification rules predicting k different classes, we would need to run the evolutionary algorithm at least k times, so that in the i-th run, i=l,..,k, the algorithm discovers only rules predicting the i-th class [1.19]. The third possibility is to choose the predicted class most suitable for a rule, in a kind of deterministic way, as soon as the corresponding rule antecedent is formed. The chosen predicted class can be the class that has more representatives in the set of examples satisfying the rule antecedent [1.13] or the class that maximizes the individual's fitness [1.11]. The first and third possibilities have the advantage of allowing different individuals of the population to represent rules predicting different classes. This avoids the need to perform multiple runs of the evolutionary algorithm to discover rules predicting different classes, which is the case in the second possibility. Overall, the third possibility seems more sound.
1.3.5 Genetic Operators for Rule Discovery

There has been several proposals of genetic operators designed particularly for rule discovery. We review some of these operators in the following subsections.

1. EAs for KDD

13

Selection. REGAL [1.14] follows the Michigan approach, where each individual represents a single rule. Since the goal of the algorithm is to discover a set of (rather than just one) classification rules, it is necessary to avoid the convergence of the population to a single individual (rule). REGAL does that by using a selection procedure called universal suffrage. In essence, individuals to be mated are "elected" by training examples. An example "votes" for one of rules that cover it, in a probabilistic way. More precisely, the probability of voting for a given rule (individual) is proportional to the fitness of that rule. Only rules covering the same examples compete with each other. Hence, this procedure effectively implements a form of niching, encouraging the evolution of several different rules, each of them covering a different part of the data space.

Generalizing/specializing crossover. The basic idea of this special kind of crossover is to generalize or specialize a given rule, depending on whether it is currently overfitting or underfitting the data [1.11]. To simplify our discussion, assume that the evolutionary algorithm follows the Michigan approach - where each individual represents a single rule - using a binary encoding. Then the generalizing / specializing crossover operators can be implemented as the logical OR and the logical AND, respectively. This is illustrated below, where the above-mentioned bitwise logical functions are used to compute the values of the bits between the two crossover points denoted by the "I" symbol.

Parents
00 1 1100 1 1 10 1 1010 1 0

Children generated by generalized crossover
0011101 1011100

Children generated by specialized crossover
0010001 1010000

Example of generalizing / specializing crossover

Generalizing/specializing-condition operator. In the previous subsection we saw how the crossover operator can be modified to generalize/ specialize a rule. However, the generalization/specialization of a rule can also be done in a way independent of crossover. Suppose, e.g., that a given individual represents a rule antecedent with two attribute-value conditions, as follows again, there is an implicit logical AND connecting the two conditions as: (Age > 25) (Marital-Status = "single")........... ( 4 We can generalize, say, the first condition of (1) by using a kind of mutation operator that subtracts a small, randomly-generated value from 25. This might transform the rule antecedent of (a) into, say, the following one: (Age > 21) (Marital-Status = "single") ........... (b) Rule antecedent (b) tends to cover more examples than (a), which is a kind of result that we wish in the case of a generalization operator. Another way to generalize rule antecedent (a) is simply to delete one of its conditions.

14

Ghosh

Conversely, we could specialize the first condition of rule antecedent (a) by using a kind of mutation operator that adds a small, randomly-generated value to 25. Another way to specialize (a) is, of course, to add another condition to that rule antecedent.
1.3.6 Fitness Functions for Rule Discovery

As discussed earlier, ideally the discovered rules should: (a) have a high predictive accuracy (b) be comprehensible and (c) be interesting. In this subsection we discuss how these rule quality criteria can be incorporated in a fitness function. To simplify our discussion, throughout this subsection we will again assume that the GA follows the Michigan approach - i.e. an individual represents a single rule. However, the basic ideas discussed below can be easily adapted to GAS following the Pittsburgh approach, where an individual represents a rule set. Let a rule be of the form: IF A THEN C, where A is the antecedent (a conjunction of conditions) and C is the consequent (predicted class), as discussed earlier. A very simple way to measure the predictive accuracy of a rule is to compute the so-called confidence factor (CF) of the rule, defined as: A CF = I U CI / (Al, where IAl is the number of examples satisfying all the conditions in the antecedent A and JA U CI is the number of examples that both satisfy the antecedent A and have the class predicted by the consequent C. For instance, if a rule covers 10 examples (i.e. IAI = lo), out of which 8 have the class predicted by the rule (i.e. IA&CJ= 8) then the CF of the rule is CF = 80%. Unfortunately, such a simple predictive accuracy measure favors rules overfitting the data. For instance, if IAl = IA & CI = 1 then the CF of the rule is 100%. However, such a rule is most likely representing an idiosyncrasy of a particular training example, and probably will have a poor predictive accuracy on the test set. A solution for this problem is described next. The predictive performance of a rule can be summarized by a 2 x 2 matrix, sometimes called a confusion matrix. To interpret this, recall that A denotes a rule antecedent and C denotes the class predicted by the rule. The class predicted for an example is C if and only if the example satisfies the rule antecedent. The labels in each quadrant of the matrix have the following meaning: T P = True Positives = Number of examples satisfying A and C F P = False Positives = Number of examples satisfying A but not C FN = False Negatives = Number of examples not satisfying A but satisfying C TN = True Negatives = Number of examples not satisfying A nor C Clearly, the higher the values of T P and TN, and the lower the values of F P and FN, the better the rule.

1. EAs for RDD

15

1.4 Multi-Objective Optimization and Rule Mining Problems
It is always difficult to find out a single solution for a multi-objective problem. So it is natural to find out a set of solutions depending on non-dominance criterion [1.7]. At the time of taking a decision, the solution that seems to fit better depending on the circumstances can be chosen from the set of these candidate solutions. A solution, say a, is said to be dominated by another solution, say b, if and only if the solution b is better or equal with respect to all the corresponding objectives of the solution a, and b is strictly better in at least one objective. Here the solution b is called a non-dominated solution. So it will be helpful for the decision-maker, if we can find a set of such nondominated solutions. Vilfredo Pareto suggested this approach of solving the multi objective problem. Optimization techniques based on this approach are termed as Pareto optimization techniques. Based on this idea, several genetic algorithms were designed to solve multiobjective problems [1.7]. Multiple-Objective Genetic Algorithm (MOGA) [1.7] is one of them. Here the chromosomes are selected (using standard selection scheme, e.g. roulette wheel selection) using the fitness value. Fitness value is calculated using their ranks, which are calculated from the nondominance property of the chromosomes. The ranking step tries to find the non-dominated solutions, and those solutions are ranked as one. Among the rest of the chromosomes, if pi individuals dominate a chromosome then its rank is assigned as l+pi. This process continues till all the chromosomes are ranked. Then fitness is assigned to the chromosomes such that the chromosomes having the smallest rank gets the highest fitness and the chromosomes having the same rank gets the same fitness. After assigning the fitness to the chromosomes, selection, replacement, crossover and mutation operators are applied to get a new set of chromosomes, as in standard GAS. As mentioned earlier, in the present work we used the comprehensibility and the interestingness measure of rules in addition to predictive accuracy (which is already discussed in the previous section) as objectives of multiobjective GAS. Let us discuss them here. It is very difficult to quantify understandability or comprehensibility. A careful study of an association rule will infer that if the number of conditions involved in the antecedent part is less, the rule is more comprehensible. To reflect this behavior, an expression was derived as comp = N-(number of conditions in the antecedent part) [1.11].This expression serves well for the classification rule generation where the number of attributes in the consequent part is always one. Since, in the association rules, the consequent part may contain more than one attribute, this expression is not suitable for the association rule mining. We require an expression where the number of attributes involved in both the parts of the rule has some effect. The following expression can be used to quantify the comprehensibility of an association rule,

16

Ghosh

Comprehensibility = log(l+lCI)

/

log(l+lA U CI).

Here, ICI and [AU CI are the number of attributes involved in the consequent part and the total rule, respectively. Since association rule mining is a part of data mining process that extracts some hidden information, it should extract only those rules that have a comparatively less occurrence in the entire database. Such a surprising rule may be more interesting to the users; which again is difficult to quantify. For classification rules it can be defined by information gain theoretic measures [1.11].This way of measuring interestingness for the association rules will become computationally inefficient. For finding interestingness the data set is to be divided based on each attribute present in the consequent part. Since a number of attributes can appear in the consequent part and they are not predefined, this approach may not be feasible for association rule mining. So a new expression is defined which uses only the support count of the antecedent and the consequent parts of the rules, and is defined as Interestingness = [SUP(A U C)/SUP(A)] x [SUP(A U C)/SUP(C)] x P-(SUP(A U C)lIDI)l. Here [Dl is the total number of records in the database. This expression contains three parts. The first part, [SUP(AuC)/SUP(A)], gives the probability of generating the rule depending on the antecedent part, the second part, [SUP(A U C)/SUP(C)], gives the probability of generating the rule depending on the consequent part, and (SUP(A U C)/IDI) gives the probability of generating the rule depending on the whole data-set. So complement of this probability will be the probability of not generating the rule. Thus, a rule having a very high support count will be measured as less interesting.
1.4.1 Model of Ghosh and Nath

In this work [1.12] we tried to solve the association rule-mining problem with a Pareto based genetic algorithm. The first task for this is to represent the possible rules as chromosomes, for which a suitable encoding/decoding scheme is required. For this, two approaches can be adopted. In the Pittsburgh approach each chromosome represents a set of rules, and this approach is more suitable for classification rule mining; as we do not have to decode the consequent part and the length of the chromosome limits the number of rules generated. The other approach is called the Michigan approach where each chromosome represents a separate rule. In the original Michigan approach we have to encode the antecedent and consequent parts separately; and thus this maybe an efficient way from the point of space utilization since we have to store the empty conditions as we do not known a priori which attributes will appear in which part. So we followed a new approach that is better than this approach from the point of storage requirement. With each attribute

1. EAs for KDD

17

we associate two extra tag bits. If these two bits are 00 then the attribute next to these two bits appears in the antecedent part and if it is 11 then the attribute appears in the consequent part. And the other two combinations, 01 and 10 will indicate the absence of the attribute in either of these parts. O O So the above rule will look like O A 11B O C 01D 11E OOF. In this way we can handle variable length rules with more storage efficiency, adding only an overhead of 2k bits, where k is the number of attributes in the database. The next step is to find a suitable scheme for encoding/decoding the rules to/from binary chromosomes. Since the positions of attributes are fixed, we need not store the name of the attributes. We have to encode the values of different attribute in the chromosome only. For encoding a categorical valued attribute, the market basket encoding scheme is used. As discussed earlier this scheme is not suitable for numeric valued attributes. For a real valued attribute their binary representation can be used as the encoded value. The range of value of that attribute will control the number of bits used for it. Decoding will be simply the reverse of it. The length of the string will depend on the required accuracy of the value to be encoded. Decoding can be performed as: Value = Minimum value (maximum value -minimum value) x ((C(2i-1 x ith bit ~alue))/(2~-1)) Where 1 i l n and n is the number of bits used for encoding; and mini5 mum & maximum are minimum and maximum values of the attribute. Using these encoding schemes, values of different attributes can be encoded into the chromosomes. Since in the association rules an attribute may it be involved with different relational operators [1.11], is better to encode them also within the rule itself. For example, in one rule a numeric attribute A may be involved as A 2 valuel, but in another rule it may be involved as A 5 valuez. Similarly, a categorical attribute may be involved with either equal to (=) or not equal to (#). To handle this situation we used another bit to indicate the operators involved with the attribute. Equality and not equality are not considered with the numerical attribute. In this way the whole rule can be represented as a binary string, and this binary string will represent one chromosome or a possible rule. After getting the chromosomes, various genetic operators can be applied on it. Presence of large number of attributes in the records will results in large chromosomes, thereby needing multi-point crossover. There are some difficulties to use the standard multi-objective GAS for association rule mining problems. In case of rule mining problems, we need to store a set of better rules found from the database. If we follow the standard genetic operations only, then the final population may not contain some rules that are better and were generated at some intermediate generations. It is better to keep these rules. For this task, a separate population is used [1.1]. In this population no genetic operation is performed. It will simply contain

+

18

Ghosh

only the non-dominated chromosomes of the previous generation. The user can fix the size of this population. At the end of first generation, it will contain the non-dominated chromosomes of the first generation. After the next generation, it will contain those chromosomes, which are non-dominated among the current population as well as among the non-dominated solutions till the previous generation. The approach will work as follows: 1. 2. 3. 4. 5. 6. 7. 8. Load a sample of records from the database that fits in the memory. Generate N chromosomes randomly. Decode them to get the values of the different attributes. Scan the loaded sample to find the support of antecedent part, consequent part and the rule. Find the confidence, comprehensibility and interestingness values. Rank the chromosomes depending on the non-dominance property. Assign fitness to the chromosomes using the ranks, as mentioned earlier. Bring a copy of the chromosomes ranked as 1 into a separate population, and store them if they are non-dominated in this population also. If some of the existing chromosomes of this population become dominated, due to this insertion, then remove the dominated chromosomes from this population. Select the chromosomes, for next generation, by roulette wheel selection scheme using the fitness calculated in Step 7. Replace all chromosomes of the old population by the chromosomes selected in Step 9. Perform multi-point crossover and mutation on these new individuals. If the desired number of generations is not completed, then go to Step 3. Decode the chromosomes in the final stored population, and get the generated rules.

9.
10. 11. 12. 13.

1.5 Discussion and Research Directions
We have begun our discussion of data mining and knowledge discovery by identifying three desirable properties of discovered knowledge. These properties are predictive accuracy, comprehensibility and interestingness. We believe a promising research direction is to design evolutionary algorithms which aim at discovering truly interesting rules. Clearly, this is much easier said than done. The major problem is that rule interestingness is a complex concept, involving both objective and subjective aspects. Almost all the fitness functions currently used in evolutionary algorithms for data mining focus on the objective aspect of rule quality, and in most cases only predictive accuracy and rule comprehensibility are taken into account. However, these two factors alone

References

19

do not guarantee rule interestingness, since a highly-accurate, comprehensible rule can still be uninteresting, if it corresponds to a piece of knowledge previously known by the user. Concerning data mining tasks, which correspond t o kinds of problems to be solved by data mining algorithms, in this chapter we have focused on the rule mining task only, due t o space limitations. However, many of the ideas and concepts discussed here are relevant t o other data mining tasks involving prediction, such as the dependence modelling task. We have discussed several approaches to encode prediction (IF-THEN) rules into the genome of individuals, as well as several genetic operators designed specifically for data mining purposes. A typical example is the use of generalizing/specializing crossover. We believe that the development of new data mining-oriented operators is important t o improve the performance of evolutionary algorithms in data mining and knowledge discovery. Using this kind of operator makes evolutionary algorithms endowed with some "knowledge" about what kind of genome-modification operation makes sense in data mining problems. The same argument holds for other ways of tailoring evolutionary algorithms for data mining, such as developing data mining-oriented individual representations. We have also discussed the use of multi-objective evolutionary algorithms for rule mining. Use of other multi-objective EAs for rule mining needs to be investigated.

References
1.1 Adamo, J. M. (2001): Data mining for association rules and sequential patterns. Springer-Verlag, USA 1.2 Agrawal, R., Imielinski, T., Swami, A. (1993): Mining association rules between sets of items in large databases. Proc. 1993 Int. Conf. Management of Data (SIGMOD-93), 207-216 1.3 Anglano, C., Giordana, A., Lo Bello, G., Saitta, L. (1998): Coevolutionary, distributed search for inducing concept descriptions. Lecture Notes in Artificial Intelligence 1398. ECML-98: Proc. 10th Europ. Conf. Machine Learning, 422333. Springer-Verlag 1.4 Banzhaf, W., Nordin, P., Keller, R. E., Francone, F. D. (1998): Genetic programming an introduction: on the automatic evolution of computer programs and its applications. Morgan Kaufmann 1.5 Cios, K., Pedrycz, W., Swiniarski, R. (2000): Data mining methods for knowledge discovery. Kluwer Academic Publishers 1.6 Cooley, R., Mobasher, B., Srivastava, J. (1997): Web mining: information and pattern discovery on the world wide web. Proc. Of the gth IEEE International Conference on Tools with Artificial Intelligence 1.7 Deb, K. (2001): Multi-objective optimization using evolutionary algorithms. John Wiley & Sons 1.8 Duda, R. G., Hart, P. E., Stork, D. G. (2001): "Pattern classification". John Wiles & Sons

-

20

References

1.9 Fayyad, U. M., Piatetsky-Shapiro, G., Smyth. P. (1996): From data mining to knowledge discovery: an overview. In: Fayyad UM, Piatetsky-Shapiro G, Smyth P and Uthurusamy R. Advances in Knowledge Discovery & Data Mining, 1-34. AAAIIMIT 1.10 Flockhart, I. W., Radcliffe, N. J. (1995): GA-MINER: parallel data mining with hierarchical genetic algorithms - final report. EPCC-AIKMS-GA-MINERReport 1.0. University of Edinburgh, UK 1.11 Freitas, A. A. (2002): Data mining and knowledge discovery with evolutionary algorithms. Springer-Verlag 1.12 Ghosh, A., Nath, B. (2004): "Multi-objective rule mining using genetic algorithms". Information Sciences (in press). 1.13 Giordana, A. Neri, F. (1995): Search-intensive concept induction. Evolutionary Computation 3, 375-416 1.14 Giordana, A., Saitta, L., Zini, F. (1994): Learning disjunctive concepts by means of genetic algorithms. Proc. 10th Int. Conf. Machine Learning (ML-94), 96-104. Morgan Kaufmann 1.15 Goldberg, D. E. (1989): Genetic algorithms in search, optimization and machine learning. Addison-Wesley 1.16 Han, J., Kamber, M. (2001): Data mining: concept and techniques. Morgan Kauffman Publisher 1.17 Han, J., Jamil, H., Lu, Y., Chan, L., Liao, Y., Pei, J.: DNA-Miner: a system prototype for mining DNA sequences, Electronic Edition, ACM, School of Computing Science, Simon Fraser University, Canada; Dept. of Computer Science, Mississipi State University, USA 1.18 Jain, A., Zongker, D. (1997): Feature selection: evaluation, application, and small sample performance. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 19, 153-158 1.19 Janikow C. Z. (1993): A knowledge-intensive genetic algorithm for supervised learning. Machine Learning 13, 189-228 1.20 Koza, J. R. (1992): Genetic programming: on the programming of computers by means of natural selection. MIT Press 1.21 Mahfoud, S. W. (1995): Niching methods for genetic algorithms. Ph.D. Thesis. Univ. of Illinois at Urbana-Champaign. IlliGAL Report No. 95001 1.22 Michalewicz, Z. (1996): Genetic algorithms data structures = evolution programs. 3rd Ed. Springer-Verlag 1.23 Mobasher, B., Jain, N., Han, E., Srivastava, J. (1996): Web mining: pattern discovery from world wide web transactions, Technical Report TR-96050, Dept. of Computer Science, University of Minnesota, Minneapolis 1.24 Pyle, D. (1999): Data preparation for data mining. Morgan Kaufmann 1.25 Ramakrishnan, N., Grama, A. Y. (2001): Mining scientific data, advances in computers, 55, 119-169 1.26 Su, S., Cook, D. J., Holder, L. B. (1999): Application of knowledge discovery in molecular biology: identifying structural regularities in proteins. Proc. Of Pacific Symposium of Biocomputing, 190--201. 1.27 Weiss, S. M., Indurkhya, N. (1998): Predictive data mining: a practical guide. Morgan Kaufmann

+

2. Strategies for Scaling Up Evolutionary Instance Reduction Algorithms for Data Mining
Jose Ramon Canol, Fi-ancisco Herrera2, and Manuel ~ o z a n o ~ Dept. of Electronic Engineering, Computer Systems and Automatics, Escuela Superior de La Rabida, University of Huelva, 21819, Huelva, Spain jose.cano@diesia.uhu.es Dept. of Computer Science and Artificial Intelligence, University of Granada, 18071, Granada, Spain herrera@decsai.ugr.es,lozano@decsai.ugr.es

Abstract: Evolutionary algorithms are adaptive methods based on natural evolution that may be used for search and optimization. As instance selection can be viewed as a search problem, it could be solved using evolutionary algorithms. In this chapter, we have carried out an empirical study of the performance of CHC as representative evolutionary algorithm model. This study includes a comparison between this algorithm and other non-evolutionary instance selection algorithms applied in different size data sets to evaluate the scaling up problem. The results show that the stratified evolutionary instance selection algorithms consistently outperform the non-evolutionary ones. The main advantages are: better instance reduction rates, higher classification accuracy and reduction in resources consumption.

2.1 Introduction
Advances in digital and computer technology that have led to the huge expansion of the Internet means that massive amounts of information and collection of data have to be processed. Due to the enormous amounts of data, much of the current research is based on scaling up [2.5] Data Mining (DM) ([2.1, 2.20, 2.221) algorithms. Other research has also tackled scaling down data. The main problem of scaling down data is how to select the relevant data. This task is carried out in the data preprocessing phase in a Knowledge Discovery in Databases (KDD) process. Our attention is focused on Data Reduction (DR) [2.16] as preprocessing task, which can be achieved in many ways: by selecting features [2.15], by making the feature-values discrete [2.8], and by selecting instances([2.13]).We led our study to Instance Selection (IS) as DR mechanism ([2.3, 2.17, 2.18]), where we reduce the number of rows in a data set (each row represents and instance). IS can follow different strategies (see Fig. 2.1): sampling, boosting, prototype selection (PS), and active learning. We are going to study the IS from the PS perspective.

22

Cano, Herrera and Lozano

F&m
Selcchon

Instance

Selectton

Featwe DisWon

Fig. 2.1. Data reduction strategies

IS mechanisms have been proposed to choose the most suitable points in the data set to become instances for the training data set used by a learning algorithm. IS has been studied previously in the literature using different approaches, in particular by means of Genetic Algorithms (GA) ([2.11]) as PS approach. For example, in [2.14], a GA is used for carry out a k-nearest neighbor edition. Evolutionary Algorithms (EAs) ([2.2]) are general-purpose search alge rithms that use principles inspired by natural genetic populations to evolve solutions to problems. The basic idea is to maintain a population of chromosomes, which represent plausible solutions to the problem, which evolves over time through a process of competition and controlled variation. EAs in general and GAS in particular have been used to solve the IS problem, with promising results ([2.14]). The issue of scalability and the effect of increasing the size of data sets are always present in the algorithm behavior. This scaling up drawback appears in EAs due to the increasing of the chromosome's size, which reduces the EAs convergence capabilities. To avoid this drawback we offer a combination of EAs and a stratified strategy. In large size we can't evaluate the algorithms over the complete data set so the stratification is a way to carry out the executions. Combining the subsets selected from the strata we can obtain the subset selected for the whole initial data set. The stratification reduces the data set size, while EAs select the most representative prototype per stratus. The aim of this chapter is to study the application of a representative and efficient E model for data reduction, the CHC algorithm in IS ([2.6, 2.4]), and A to compare it with non-evolutionary instance selection algorithms (hereafter referred to as classical ones) following a stratified strategy. To address this, we have carried out a number of experiments increasing the complexity and the data set size.

2. Scaling Up Evolutionary Instance Reduction in Data Mining

23

In order to do that, this chapter is set up as follows. In Section 2.2, we introduce the main ideas about IS, describing the processes which IS algorithms take part, and we also summarize the classical IS algorithms used in this study. In Section 2.3, we introduce the foundations of EAs and summarize the main features of them, giving details of how EAs can be applied to the IS problem in large size data sets. Section 2.4 is dedicated to the Scaling Up problem and we present our proposal solution. In Section 2.5, we explain the methodology used in the experiments. Section 2.6 deals with the results and the analysis of medium and large size data sets. Finally, in Section 2.7, we point out our conclusion.

2.2 Instance Selection on Data Reduction
In this section we describe the strategy which IS takes part in, as a DR mechanism, as well as a summary of classical IS algorithms.
2.2.1 Instance Selection

In IS we want to isolate the smallest set of instances which enable us to predict the class of a query instance with the same (or higher) accuracy as the original set [2.16]. By reducing the "useful" data set size, which can reduce both space and time complexities of subsequent processing phases. One can also hope to reduce the size of formulas obtained by a subsequent induction algorithm on the reduced and less noise data sets. This may facilitate interpretation tasks. IS raises the problem of defining relevance for a prototype subset. From the statistical viewpoint, relevance can be partly understood as the contribution to the overall accuracy, that would be e.g. obtained by a subsequent induction. We emphasize that removing instances does not necessarily lead to a degradation of the results: we have observed experimentally that a little number of instances can have performances comparable to those of the whole sample, and sometimes higher. Two reasons come to mind to explain such an observation:
First, some noises or repetitions in data could be deleted by removing instances. - Second, each instance can be viewed as a supplementary degree of freedom. If we reduce the number of instances, we can sometimes avoid over-fitting situations.
-

2.2.2 Instance Selection for Prototype Selection

There may be situations in which there is too much data and this data in most cases is not equally useful in the training phase of a learning algorithm.

24

Cano, Herrera and Lozano

Instance selection mechanisms have been proposed to choose the most suitable points in the data set to become instances for the training data set used by a learning algorithm. Fig. 2.2 shows a general framework for the application of an IS algorithm for PS. Starting from the data set, D, the PS algorithm finds a suitable set, Prototype Subset Selected (PSS), then a learning or DM algorithm is applied to evaluate each subset selected (1-nearest neighbor in our case) to test the quality of the subset selected. This model is assessed using the test data set, TS.

I

Data Set (0)

I

Trarning set (TR) PrototEpe Selection

1-1
1 - e r s Naghbour Naet

Prototype Subset Selected ( P S j

Fig. 2.2. Prototype selection strategy

2.2.3 Overview of Instance Selection Algorithms

Historically, IS has been mainly aimed at improving the efficiency of the Nearest Neighbor (NN) classifier. The NN algorithm is one of the most venerable algorithms in machine learning. This algorithm calculates the Euclidean distance (possibly weighted) between an instance to be classified and each training-neighboring instance. The new instance obtained is assigned to the class of the nearest neighboring one. More generally, the k-nearest neighbors (k-NN) are computed, and the new instance is assigned to the most frequent class among these k neighbors. The k-NN classifier was also widely used and encouraged by early theoretical results related to its Bayes error generalization. However, from a practical point of view, the k-NN algorithm is not suitable for dealing with very large sets of data due to the storage requirements it demands and the computational costs involved. In fact, this approach requires the storage of all the instances in memory. Early research in instance selection firstly tried to reduce storage size. Taking as reference our study in [2.4] we select the most effective classic algorithms to evaluate them. The algorithms used in this study will be:

2. Scaling Up Evolutionary Instance Reduction in Data Mining

25

Methods based on nearest neighbor rules.
Cnn [2.12] - It tries to find a consistent subset, which correctly classifies all of the remaining points in the sample set. However, this algorithm will not find a minimal consistent subset. - Ib2 [2.13] - It is similar to Cnn but using a different selection strategy. - Ib3 [2.13]- It outperforms Ib2 introducing the acceptable instance concept to carry out the selection.
-

Methods based on ordered removal.
[2.21] - Essentially, this rule tests to see if removing an instance would degrade leave-one-out cross-validation generalization accuracy, which is an estimate of the true generalization ability of the resulting classifier. - Drop2 [2.21] - Drop2 changes the order of removal of instances. It initially sorts the instances in TR by the distance to their nearest enemy (nearest instance belonging to another class). Instances are then checked for removal beginning at the instance furthest from its nearest enemy. This tends to remove instances furthest from the decision boundary first, which in turn increases the chance of retaining border points. - Drop3 [2.21] - Drop3 uses a noise filtering pass before sorting the instances in TR. This is done using the rule: Any instance not classified by its knearest neighbors is removed.
- Drop1

2.3 Evolutionary Instance Selection Algorithms
EAs ([2.2]) are stochastic search methods that mimic the metaphor of natural biological evolution. All EAs rely on the concept of a population of individuals (representing search points in the space of potential solutions to a given problem), which undergo probabilistic operators such as mutation, selection, and (sometimes) recombination to evolve towards increasingly better fitness values of the individuals. Most of the success of EAs is due to their ability to exploit the information accumulated about an initially unknown search space. This is their key feature, particularly in large, complex, and poorly understood search spaces, where classical search tools (enumerative, heuristic, etc.) are inappropriate. In such cases they offer a valid approach to problems requiring efficient and effective search techniques. Recently EAs have been widely applied to KDD and DM ([2.9, 2.101). In this section we firstly present the key-points of their application to our problem as well as the representation and the fitness function, and then describe the EA (CHC [2.6]) used in this study, according to the best results obtained by CHC in the study presented in [2.4]. In the Section 2.3.2 we describe the model of EA that will be used in this chapter as evolutionary instance selection algorithm. CHC is a classical model

26

Cano, Herrera and Lozano

that introduces different features to obtain a trade-off between exploration and exploitation.
2.3.1 Evolutionary Instance Selection: Key Points

EAs may be applied to the IS problem, because it can be considered as a search problem. The application of EAs to IS is accomplished by tackling two important issues: the specification of the representation of the solutions and the definition of the fitness function. Representation. Let's assume a data set denoted T with n instances. The R search space associated with the instance selection is constituted by all the subsets of TR. Then, the chromosomes should represent subsets of TR. This is accomplished by using a binary representation. A chromosome consists of n genes (one for each instance in TR) with two possible states: 0 and 1. If R the gene is 1, then its associated instance is included in the subset of T represented by the chromosome. If it is 0, then this does not occur. Fitness function. Let PSS be a subset of instances of T to evaluate and R be coded by a chromosome. We define a fitness function that combines two values: the classification performance (clas-per) associated with PSS and the percentage of reduction (perc-red) of instances of PSS with regards to TR: Fitness(PSS) = a - clas-rat

+ (1- a ) .perc-red.

(2-1)

The 1-NN classifier (Section 2.2.3) is used for measuring the classification rate, clas-rat, associated with PSS. It denotes the percentage of correctly classified objects from T using only PSS to find the nearest neighbor. For R each object y in TR, the nearest neighbor is searched for amongst those in the set PSS \ {y). Whereas, perc-red is defined as: perc-red = 100. (ITRI - IPSSI)/ITRI. (2.2)

The objective of the EAs is to maximize the fitness function defined, i.e., maximize the classification performance and minimize the number of instances obtained. In the experiments presented in this chapter, we have considered the value a = 0.5 in the fitness function, as per a previous experiment in which we found the best trade-off between precision and reduction with this value.
2.3.2 The CHC Algorithm

During each generation the CHC develops the following steps:

2. Scaling Up Evolutionary Instance Reduction in Data Mining

27

1. It uses a parent population of size n to generate an intermediate population of n individuals, which are randomly paired and used to generate n potential offspring. 2. Then, a survival competition is held where the best n chromosomes from the parent and offspring populations are selected to form the next generation.
CHC also implements a form of heterogeneous recombination using HUX, a special recombination operator. HUX exchanges half of the bits that differ between parents, where the bit position to be exchanged is randomly determined. CHC also employs a method of incest prevention. Before applying HUX to two parents, the Hamming distance between them is measured. Only those parents who differ from each other by some number of bits (mating threshold) are mated. The initial threshold is set at L/4, where L is the length of the chromosomes. If no offspring are inserted into the new population then the threshold is reduced by 1. No mutation is applied during the recombination phase. Instead, when the population converges or the search stops making progress (i.e., the difference threshold has dropped to zero and no new offspring are being generated which are better than any members of the parent population) the population is re-initialized to introduce new diversity to the search. The chromosome representing the best solution found over the course of the search is used as a template to re-seed the population. Re-seeding of the population is accomplished by randomly changing 35% of the bits in the template chromosome to form each of the other n-1 new chromosomes in the population. The search is then resumed.

2.4 The Scaling up Problem. The Stratified Approach
In this section we point our attention in the Scaling Up problem and finally we describe our proposal, the combination of the stratified strategy with the evolutionary instance selection.
2.4.1 Scaling up and Stratification

The algorithms we have studied, both classical and evolutionary, are affected when the size of the data set increases. The main difficulties they have to face are as follows:
-

Efficiency. The efficiency "of I S algorithms is at least O(n2),where n is the size of the data set. Most of them present an efficiency order greater than O(n2). When the size increases, the time needed by each algorithm also increases.

28

Cano, Herrera and Lozano

- Resources. Most of the algorithms assessed need to have the complete data
set stored in memory to carry out their execution. If the size of the problem is too big, the computer would need to use the disk as swap memory. This loss of resources has an adverse effect on efficiency due to the increased access to the disk. - Representation. EAs are also affected by representation, due to the size of their chromosomes. When the size of these chromosomes is too big, then it increases the algorithm convergence difficulties. To avoid these drawback we led our experiments towards a stratified strategy. This strategy divides the initial data set in strata. The strata are disjoints sets with equal class distribution. We evaluate the algorithm over each stratus to carry out the data selection and finally we reunite the partial subsets to conform the final one. In the following section (Fig. 2.3) we describe the use of the stratified strategy combined with EA.
2.4.2 Evolutive Algorithms and Stratification Strategy

Following the stratified strategy, initial data set D is divided into t disjoint sets D j , strata of equal size, Dl, D2,..., and Dt. We maintain class distribution within each set in the partitioning process. Prototype selection algorithms (classical or evolutionary) are applied to each D j obtaining a subset selected DSj, as we can see in Fig. 2.3.

I

Data Set (Dl

1

PSA:Pmtotype SelectianAlgcoitlun

Fig. 2.3. Combination of prototype selection algorithms and stratified strategy

In Fig. 2.2, the PSS is obtained by the PS algorithm, applied on TR. In the stratified strategy, the PS algorithm is applied in each D j to obtain its DSj associated. PSS in stratified strategy is obtained using the DSj (see Eq. (2.3)) and it is called Stratified Prototype Subset Selected (SPSS).

2. Scaling Up Evolutionary Instance Reduction in Data Mining

29

The test set TS will be the TR complementary one in D.

TS=D\TR
Our specific model will be described in Section 2.5.2.

2.5 Experimental Methodology
We have carried out our study of I S problem using two size problems: medium and large. We intend to study the behavior of the algorithms when the size of the problem increases. Section 2.5.1 describes the data sets used and introduces the parameters associated with the algorithms, Section 2.5.2 introduces the stratification and partition of the data sets that were considered for applying the algorithms, and finally, in Section 2.5.3 we describe the table contents that show the results.
2.5.1 Data Sets and Parameters

The data sets used are shown in Table 2.1 and 2.2. They can be found in the UCI Repository (http://kdd.ics.uci.edu/).
Table 2.1. Medium size data sets
Data Set Pen-Based Recognition Satimage Thyroid Num. Instances 10992 6435 7200 Num. Features 16 36 21 Num. Classes 10 6 3

Table 2.2. Large size data set
Data Set Adult Num. Instances 30132 Num. Features 14 Num. Classes 2

The parameters used are shown in Table 2.3.

30

Cano. Herrera and Lozano

Table 2.3. Parameters
Algorithm
Ib3

Parameters Acept. Level=0.9, Drop Level=O.7 Population=50, Evaluations=10000

CHC

2.5.2 Partitions and Stratification: A Specific Model

We have evaluated each algorithm in a ten fold cross validation process. In the validation process TRi, i=l, ..., 10 is a 90% of D and TSi its complementary 10% of D. In our experiments we have evaluated the PS algorithms following two perspectives for the ten fold cross validation process. In the first one, we have executed the PS algorithms as we can see in Fig. 2.4. We call it Ten fold cross validation classic (Tf cv c l a s s i c ) . The idea is use this result as baseline versus the stratification ones.

Data Sa (D)

1

Prototype Subset Selected (Pa)

Fig. 2.4. Prototype selection strategy in Tfcv classic

In Tfcv c l a s s i c the subsets T R i and TSi, i=l, ..., 10 are obtained as the Eqs. (2.6) and (2.7) indicate:

where t is the number of strata, and b is the number of strata grouped
(b = t/10).

Each PSSi is obtained by the PS algorithm applied to TRi subset.

2. Scaling Up Evolutionary Instance Reduction in Data Mining

31

The second way is to execute the PS algorithms in a stratified process as the Fig. 2.5 shows. We call it Ten fold cross validation strat (Tfcv s t r a t ) .

I

Data Set (D)

1

PSA Prototype Selection Algorithm

Fig. 2.5. Prototype selection strategy in Tfcv strat

In Tf cv strat each T R , is defined as we can see in Eq. (2.6), by means of the union of Dj subsets (see Fig. 2.5). In Tf cv s t r a t (see Fig. 2.5) SPSSi is generated using the DSj (see Eq. (2.8)).

SPSSi =

UD
j J

S J~=

{jll5 j 5 b.(i-1)

and ( i . b ) + l 5 j 5 t)(2.8)

SPSSi contains the instances selected by PS algorithms in T R i following the stratified strategy. The subset TSi is defined by means the Eq. (2.7). Both, T R , and TSi are generated in the same way in Tf cv c l a s s i c and Tf cv s t r a t . For each data set we have employed the following partitions and number of strata:
Table 2.4. Stratification in medium size data sets

Pen-Based Recognition
10 Strata 30 Strata

Satimage
10 Strata 30 Strata

Thyroid
10 Strata 30 Strata

32

Cano, Herrera and Lozano

Table 2.5. Stratification in large size data set

Adult 10 Strata 50 Strata 100 Strata

2.5.3 Table of Results

In the following section we will present the structure of tables where we present the results. Our table shows the results obtained by the classical and evolutionary instance selection algorithms, respectively. In order to observe the level of robustness achieved by all algorithms, the table presents the average in the ten fold cross validation process of the results offered by each algorithm in the data sets evaluated. Each column shows:
-

The first column shows the name of the algorithm. In this column the name is followed by the sort of validation process (Tf cv s t r a t and the number of strata, or Tf cv c l a s s i c meaning ten fold cross-validation process classic). - The second column contains the average execution time associated to each algorithm. The algorithms have been run in a Pentium 4, 2.4 Ghz, 256 RAM, 40 Gb HD. - The third column shows the average reduction percentage from the initial training sets. - The fourth column contains the training accuracy associated to the prototype subset selected. - The fifth column contains the test accuracy of the PS algorithms selection.

2.6 Experimental Study
In this section we present the results obtained in the evaluation of medium and large data sets and their analysis.
2.6.1 Medium Size Data Sets

The following conclusions about the IS algorithms for PS can be made studying Table 2.6: In Table 2.6 we can see that the stratification strategy reduces significantly the execution time. - Stratified strategy affects in different manner to the accuracy rates associated to the classic algorithms. Some of them, like Ib2, Ib3 or Cnn,increase their accuracy, but other group (Dropl, Drop2 and Drop) reduces it.
-

2. Scaling Up Evolutionary Instance Reduction in Data Mining

33

Table 2.6. Prototype selection for pen-based recognition data set
Exec. Time(sec) 1-NN 66 Cnn Tfcv classic 4 Cnn Tfcv strat 10 Cnn Tfcv strat 30 Dropl Tfcv classic Dropl Tfcv strat 10 Dropl Tfcv strat 30 Drop2 Tfcv classic Drop2 Tfcv strat 10 Drop2 Tfcv strat 30 Drop3 Tfcv classic Drop3 Tfcv strat 10 Drop3 Tfcv strat 30 Ib2 Tfcv classic Ib2 Tfcv strat 10 Ib2 Tfcv strat 30 Ib3 Tfcv classic Ib3 Tfcv strat 10 Ib3 Tfcv strat 30 CHC Tfcv classic CHC Tfcv strat 10 CHC Tfcv strat 30

% Reduction

1-NN

1-NN

%Ac.Trn 98.04% 99.36% 84.85%

%Ac.Test 99.39% 85.69%

34
- CHC

Cano, Herrera and Lozano

and its stratified version have not been improved in their test accuracy by classic methods which offer small reduction rates. They offer the best balance between reduction and accuracy rates. - The Stratified CHC is the one which presents the best behavior among time and resources consumption, and reduction and accuracy rates. The classic algorithm which can face to Stratified CHC is Ib3 following a Tf cv classic, which can be hard to use when the size of the problem is huge due to its resources necessities.
Table 2.7. Prototype selection for Satimage data set
Exec. Time(sec)

% Reduction

1-NN %Ac.Trn

1-NN %Ac.Test

1-NN Cnn Tfcv classic Cnn Tfcv strat 10 Cnn Tfcv strat 30 Dropl Tfcv classic Dropl Tfcv strat 10 Dropl Tfcv strat 30 Drop2 Tfcv classic Drop2 Tfcv strat 10 Drop2 Tfcv strat 30 Drop3 Tfcv classic Drop3 Tfcv strat 10 Drop3 Tfcv strat 30 Ib2 Tfcv classic Ib2 Tfcv strat 10 Ib2 Tfcv strat 30 Ib3 Tfcv classic Ib3 Tfcv strat 10 Ib3 Tfcv strat 30 CHC Tfcv classic CHC Tfcv strat 10 CHC Tfcv strat 30

The following conclusions can be made studying Table 2.7: Execution time is decreased by the stratified strategy in the same way that we saw it in Table 2.6. We can see that the stratification strategy reduces significantly the execution time. - Stratified strategy affects in different manner to the accuracy rates associated to the classic algorithms. We can see the group conformed by the Drop family algorithms and other group with the rest of classic algorithms. The first group reduces its accuracy associated when they are evaluated following a stratification strategy while the second group increase it.
-

2. Scaling Up Evolutionary Instance Reduction in Data Mining

35

- In Satimage, CHC and its stratified version offer the best balance between

reduction and accuracy rates. They have not been improved in their test accuracy by classic methods which offer small reduction rates. - Like in Pen-Based Recognition data set, the Stratified CHC presents the best behavior among time and resources consumption, and reduction and accuracy rates.

Table 2.8. Prototype selection for thyroid data set

Exec. Time(sec) 1-NN Cnn Tfcv classic Cnn Tfcv strat 10 Cnn Tfcv strat 30 Dropl Tfcv classic Dropl Tfcv strat 10 Dropl Tfcv strat 30 Drop2 Tfcv classic Drop2 Tfcv strat 10 Drop2 Tfcv strat 30 Drop3 Tfcv classic Drop3 Tfcv strat 10 Drop3 Tfcv strat 30 Ib2 Tfcv classic Ib2 Tfcv strat 10 Ib2 Tfcv strat 30 Ib3 Tfcv classic Ib3 Tfcv strat 10 Ib3 Tfcv strat 30 CHC Tfcv classic CHC Tfcv strat 10 CHC Tfcv strat 30

% Reduction

1N -N %Ac.Trn

1-NN

%Ac.Test

The following conclusions can be made studying Table 2.8:
- Execution time is reduced by the stratified strategy as in the Tables 2.6

and 2.7.
- In Thyroid data set, CHC and its stratified version have not been improved

in their test accuracy by classic methods which offer small reduction rates. They offer the best balance between reduction and accuracy rates. - The Stratified CHC is the one which present the best behavior among time and resources consumption, and reduction and accuracy rates. The main conclusion that can be drawn when using medium size data sets is that Stratified CHC is the best algorithm for data reduction having

36

Cano, Herrera and Lozano

both high reduction rates and accuracy, and decreasing execution time and resources consumption.

2.6.2 Large Size Data Set

Table 2.9. Prototype selection for adult data set

Exec. Time(sec)
1-NN 24 4 1 0.20 0.02 44 1.2 0.15 48 0.7 0.13 41 0.8 0.11 2 1 0.1 0.03 210 3 0.4 0.05 20172 48 14

% Reduction

1-NN

1-NN

%Ac.Tm Cnn Tfcv classic Cnn Tfcv strat 10 Cnn Tfcv strat 50 Cnn Tfcv strat 100 Dropl Tfcv strat 10 Dropl Tfcv strat 50 Dropl Tfcv strat 100 Drop2 Tfcv strat 10 Drop2 Tfcv strat 50 Drop2 Tfcv strat 100 Drop3 Tfcv strat 10 Drop3 Tfcv strat 50 Drop3 Tfcv strat 100 Ib2 Tfcv classic Ib2 Tfcv strat 10 Ib2 Tfcv strat 50 Ib2 Tfcv strat 100 Ib3 Tfcv classic Ib3 Tfcv strat 10 Ib3 Tfcv strat 50 Ib3 Tfcv strat 100 CHC Tfcv strat 10 CHC Tfcv strat 50 CHC Tfcv strat 100
99.21% 97.34% 93.69% 90.09% 95.09% 94.59% 94.49% 70.33% 68.03% 66.96% 95.57% 95.34% 93.71% 99.94% 99.57% 98.66% 94.33% 79.42% 76.69% 73.48% 71.21% 99.38% 98.34% 97.03% 79.34% 26.40% 35.37% 66.51% 64.42% 100.00% 100.00% 100.00% 27.71% 56.90% 59.31% 48.98% 64.83% 65.82% 25.20% 52.33% 74.72% 67.66% 72.61% 33.98% 63.93% 68.12% 97.02% 93.66% 94.28%

%Ac.Test
79.24% 26.56% 32.02% 57.42% 58.27% 25.64% 24.96% 24.83% 61.30% 70.27% 71.85% 63.46% 71.19% 70.19% 25.14% 26.89% 45.68% 54.30% 74.09% 70.96% 74.36% 71.52% 81.92% 80.17% 77.81%

We point out the following conclusions:

- If we pay attention to Table 2.9 we can see that only Cnn, Ib2 and Ib3
have been evaluated in a Tf cv classic validation. This is due to the size of the data set makes too hard to evaluate the rest of algorithms. This is one of the reason to advice the use of a stratified strategy like the one proposed by us. - There is an important reduction in execution time due to the stratified strategy. In Stratified CHC we have reduced its execution time associated from 40.391 seconds using 3 strata to 14 seconds using 100 strata.

2. Scaling Up Evolutionary Instance Reduction in Data Mining
-

37

Stratified CHC offers the best behavior. It presents the best reduction rates and accuracy rates, combined with a lower execution time. The fifth column in Table 2.9 shows that stratified CHC is the best algorithm offering the highest accuracy and reduction rates. - The classical algorithms which present higher accuracy rate, offer smaller reduction rates. Those which present higher reduction rates, show minimal accuracy rates. Clearly, when we manage large size data sets, the stratified CHC algorithm improves the behavior of the classic ones, giving the best results for scaling down data. If we take note of Table 2.9, the initial data set which needs 24 seconds to be evaluated using 1-NN, is reduced (in 14 seconds) in 97.03% by the stratified CHC, losing less than 1.5% in accuracy rate. This situation shows that our proposal is an effective data reduction alternative t o be applied in large size data sets. Taking Table 2.9 as reference, and more concretely the Stratified CHC as the best algorithm evaluated, we can study the effect of the number of strata over the algorithm's behavior.

I
I
10
50

,,,,ccuracy Rate
ReductionRate

rm

Number of Stratus

Fig. 2.6. Stratus effect on accuracy and reduction rates in Adult data set

As we can see in Fig. 2.6, when the number of strata increases, both the accuracy and reduction rate decrease. This situation is due to the selection carried out in each stratus. When the number of strata increases, the number of equivalent selected instances in different subsets also increases. This situation produces that the size of the final subset selected is bigger.

38

References

2.7 Concluding Remarks
This chapter addressed the analysis of the evolutionary instance selection by means of CHC and their use in data reduction for large data sets in KDD. We have studied the effect of the stratified strategy in the scaling up of the algorithms. The main conclusions reached are the following: The Stratified Strategy reduces significantly the execution time and the resources consumed by classic and CHC algorithm. This situation offers two principal advantages: First, the evaluation of large data sets which needs too much resources is feasible, and second, the reduction in time associated to its execution. - Stratified CHC outperform the classical algorithms, simultaneously offering two main advantages: better data reduction percentages and higher classification accuracy. - In medium and large size data sets, classical algorithms do not present balanced behavior. If the algorithm reduces the size then its accuracy rate is poor. When accuracy increases there is no reduction. - The increase in the number of strata can produce a small degradation in the algorithm behavior as we indicated in Fig. 2.6. The adequate number of them has to be chosen to produce a balance between time and resources consumption in one side, and reduction and accuracy rates by the other side.
-

Therefore, as a final concluding remark, we consider the stratified strategy combined with CHC to be a good mechanism for data reduction, facing to the problem of Scaling Up. It has become a powerful tool to obtain small selected training sets and therefore scaling down data. CHC can select the most representative instances, satisfying both the objectives of high accuracy and reduction rates. Stratified strategy permits a reduction of the search space so we can carry out the evaluation of the algorithms with acceptable execution time, and decreasing the resources necessities. Finally, we point out that future research could be directed towards the study of hybrid strategies between classical and evolutionary instance selection algorithms.

References
2.1 Adriaans, P., Zantinge, D. (1996): Data mining. Addison-Wesley

2.2 Back, T., Fogel, D., Michalewicz, Z. (1997): Handbook of evolutionary computation. Oxford University Press 2.3 Brighton, H., Mellish, C. (2002): Advances in instance selection for instancebased learning algorithms. Data Mining and Knowledge Discovery 6, 153-172

References

39

2.4 Cano, J.R., Herrera, F., Lozano, M. (2003): Using evolutionary algorithms as instance selection for data reduction in KDD: An experimental study. IEEE Transaction on Evolutionary Computation (In press) 2.5 Domingo, C., Gavalda, R., Watanabe, 0. (2002): Adaptative sampling methods for scaling up knowledge discovery algorithms. Data Mining and Knowledge Discovery 6, 131-152 2.6 Eshelman, L. J. (1991): The CHC adaptive search algorithm: how to have safe search when engaging in nontraditional genetic recombination. (Foundations of Genetic Algorithms-1) , Rawlins, G. J .E. (Eds.), Morgan Kauffman, 265-283 2.7 Esposito, F., Malerba, D., Semeraro, G. (1997): A comparative analysis of methods for pruning decision trees. IEEE Transactions on Pattern Analysis and Machine Intelligence, 19, 476-491 2.8 Frank, E., Witten, I. H. (1999): Making better use of global discretization. (Proc. Sixteenth International Conference on Machine Learning), Bratko, I., Dzeroski, S. (Eds.), Morgan Kaufmann, 115-123 2.9 Freitas, A. A. (2002): Data mining and knowledge discovery with evolutionary algorithms. Springer-Verlag 2.10 Freitas, A.A. (2002): A survey of evolutionary algorithms for data mining and knowledge discovery. (Advances in evolutionary computation), Ghosh, A., Tsutsui, S. (Eds.), Springer-Verlag, 819-845 2.11 Goldberg, D. E. (1989): Genetic algorithms in search, optimization, and machine learning. Addison-Wesley 2.12 Hart, P. E. (1968): The condensed nearest neighbour rule. IEEE Transaction on Information Theory, 18, 431-433 2.13 Kibbler, D., Aha, D. W. (1987): Learning representative exemplars of concepts: An initial case of study. Proc. of the (Fourth International Workshop on Machine Learning) , Morgan Kaufmann, 24-30 2.14 Kuncheva, L. (1995): Editing for the k-nearest neighbors rule by a genetic algorithm. Pattern Recognition Letters, 16, 809-814 2.15 Liu, H., Motoda, H. (1998): Feature selection for knowledge discovery and data mining. Kluwer Academic Publishers 2.16 Liu, H., Motoda, H. (2001): Data reduction via instance selection. (Instance Selection and Construction for Data Mining), Liu, H., Motoda, H. (Eds.) , Kluwer Academic Publishers, 3-20 2.17 Liu, H., Motoda, H. (2002): On issues of instance selection. Data Mining and Knowledge Discovery, 6, 115-130 2.18 Reinartz, T. (2002): A unifying view on instance selection. Data mining and Knowledge Discovery, 6, 191-210 2.19 Safavian, S. R., Landgrebe, D. (1991): A survey of decision tree classifier methodology. IEEE Transaction on Systems, Man. and Cybernetics, 21, 660674 2.20 Shanahan, J. G. (2000): Soft computing for knowledge discovery. Kluwer Academic Publishers 2.21 Wilson, D. R., Martinez, T. R. (1997): Instance pruning techniques. (Proceedings of the International Conference), Morgan Kaufmann, 403-411 2.22 Witten, I. H., Frank, E. (2000): Data mining: practical machine learning tools and techniques with Java implementations. Morgan Kaufmann

3. GAP: Constructing and Selecting Features with Evolutionary Computing
Matthew G. Smith and Larry Bull Faculty of Computing, Engineering and Mathematical Sciences, University of the West of England, Bristol BS16 lQY, U.K. Matt-SmithObigfoot.com, Larry.Bull@uwe.ac.uk Abstract: The use of machine learning techniques to automatically analyze data for information is becoming increasingly widespread. In this chapter we examine the use of Genetic Programming and a Genetic Algorithm to pre-process data before it is classified using the C4.5 decision tree learning algorithm. Genetic Programming is used to construct new features from those available in the data, a potentially significant process for data mining since it gives consideration to hidden relationships between features. A Genetic Algorithm is used to determine which set of features is the most predictive. Using ten well-known data sets we show that our approach, in comparison to C4.5 alone, provides marked improvement in a number of cases.

3.1 Introduction
Classification is one of the major tasks in data mining, involving the prediction of class value based on information about some other attributes. The process is a form of inductive learning whereby a set of pre-classified training examples are presented to an algorithm which must then generalize from the training set to correctly categorize unseen examples. One of the most commonly used forms of classification technique is the decision tree learning algorithm C4.5 [3.11]. In this chapter we examine the use of Genetic Programming (GP) [3.7] and a Genetic Algorithm (GA) [3.4] to improve the performance of C4.5 through feature construction and feature selection. Feature construction is a process that aims to discover hidden relationships between features, inferring new composite features. In contrast, feature selection is a process that aims to refine the list of features used thereby removing potential sources of noise and ambiguity. We use GP individuals consisting of a number of separate trees/automatically defined functions (ADFs) [3.7] to construct features for C4.5. A GA is then used to select over the combined set of original and constructed features for a final hybrid C4.5 classifier system. Results show that the system is able to outperform standard C4.5 on a number of data sets held at the UCI repository (http://www.ics.uci.edu/~mlearn/MLRepository.html). Raymer et al. [3.12] have used ADFs for feature extraction in conjunction with the k-nearest-neighbor algorithm. Feature extraction replaces an original feature with the result from passing it through a functional mapping.

42

Smith and Bull

In Raymer et al.'s approach each feature is altered by an ADF, evolved for that feature only, with the aim of increasing the separation of pattern classes in the feature space; for problems with n features, individuals consist of n ADFs. Ahluwalia and Bull [3.1] extended Raymer et al.'s approach by coevolving the ADFs for each feature and adding an extra coevolving GA population of feature selectors; extraction and selection occurred simultaneously in n + l populations. For other (early) examples of evolutionary computation approaches to data mining see [3.13] for a GA-based feature selection approach using k-nearest-neighbor and [3.5] for a similar GA-based approach also using k-nearest-neighbor. Since undertaking the work presented here we have become aware of Vafaie and DeJong's [3.14] combination of GP and a GA for use with C4.5. They used the GA to perform feature selection for a face recognition data set where feature subsets were evaluated through their use by C4.5. GP individuals were then evolved which contained a variable number of ADFs to construct new features from the selected subset, again using C4.5. Our approach is very similar to Vafaie and DeJong's but the feature operations are reversed such that feature construction occurs before selection. We find that our approach performs as well or better than Vafaie and DeJong's. More recent work using GP to construct features for use by C4.5 includes that of Otero et al. [3.10]. Otero et al. use a population of GP trees to evolve a single new feature using information gain as the fitness measure (this is the criteria used by C4.5 to select attributes to test at each node of the decision tree). This produces a single feature that attempts to cover as many instances as possible - a feature that aims to be generally useful and which is appended to the set of original features for use by C4.5. E k k t and MBrkus [3.3] use GP to evolve new features that are useful at specific points in the decision tree by working interactively with C4.5. They do this by invoking a GP algorithm when constructing a new node in the decision tree - e.g. when a leaf node incorrectly classifies some instances. Information gain is again used as the fitness criterion but the GP is trained only on those instances relevant at that node of the tree. Krawiec [3.8] also uses GP to construct new features for use by C4.5 but instead of using information gain as the fitness criterion uses, like the technique presented here, the 'so-called wrapper approach [3.6] where the evaluation consists of multiple train-and-test experiments carried out [with] the same inducer that is used to create the final classifier'[3.8]. Krawiec justifies the additional computational expense involved by reporting Kohavi and Johns [3.6] findings that 'although computationally demanding.. . [the wrapper approach] seems to out-perform other methods on most tasks'. Krawiec's algorithm creates a fixed number of new features (4 in the experiments shown) which replace the original set of features without any subsequent selection. Krawiec also extends the algorithm with the concept of features that are hidden from the evolutionary process to preserve them from destruction. These

3. Feature Selection with EC

43

features (2 in the experiments shown) are selected according to the number of times they appear in the decision trees constructed during fitness evaluation. While Krawiec's approach bears some similarity with the algorithm presented here, there are a number of differences: the fixed number of new features introduces a parameter that must be altered for each new problem; it does not involve any subset selection (other than the implicit selection of original features by their presence in the ADFs); nor does it appear to allow for the inclusion of any original features found to be useful. This contribution is arranged as follows: the next section describes the initial approach. Section 3.3 presents results from its use on a number of well-known data sets and discusses the results. This is followed by some amendments to the algorithm and further results. Finally Section 3.4 presents some conclusions and future directions.

3.2 The GAP Algorithm
In this work we have used the WEKA [3.15] implementation of C4.5, known as 548, to examine the performance of our Genetic Algorithm and Programming (GAP) approach. This is a wrapper approach, in which the fitness of individuals is evaluated by performing 10-fold cross validation using the same inducer as used to create the final classifier: C4.5 (J48). The approach consists of two phases:
3.2.1 Feature Creation

A population of 101 genotypes is created at random. Each genotype consists of n trees, where n is the number of numeric valued features in the data set, subject to a minimum of 7. This minimum is chosen to ensure that, for data sets with a small number of numeric features, the initial population contains a significant number of compound features. A tree can be either an original feature or an ADF. That is, a genotype consists of n GP trees, each of which may contain 1 or more nodes. The chance of a node being a leaf node (a primitive attribute) is determined by: 1 8 e a f = 1(depth 1) where depth is the depth of the tree at the current node. Hence a root node will have a depth of 1, and therefore a probability of 0.5 of being a leaf node. Nodes at depth 2 will have a 0.67 probability of being a leaf node, and so on. If a node is a leaf node, it takes the value of one of the original features chosen at random. Otherwise, a function is randomly chosen from the set {*, /, +, -, %) and two child nodes are generated. In this manner there is no absolute limit placed on the depth any one tree may reach but the average depth is limited. During the initial creation no two trees in a single

+

44

Smith and Bull

genotype are allowed to be alike, though this restriction is not enforced in later stages. Additionally, nodes with '-', '%' or '1' for functions cannot have child nodes that are equal to each other. In order to enforce this child nodes within a function '*' or '+' are ordered alphabetically to enable comparison (e.g. [width length] will become [length width]).

+

+

Fig. 3.1. Sample genotype (genotypes have a minimum of 7 trees, but only 4 are shown in the sample genotype due to space constraints. The sample genotype has been constructed using a very simple data set with 3 attributes - area (a), length (1) and width (w))

An individual is evaluated by constructing a new data set with one feature for each tree in the genotype. This data set is then passed to a C4.5 (J48) classifier (using default parameters), whose performance on the data set is evaluated using 10-fold cross validation. The percentage correct is then assigned to the individual and used as the fitness score. Once the initial population has been evaluated, several generations of selection, crossover, mutation and evaluation are performed. After each evaluation, if the fittest individual in the current generation is fitter than the fittest so far, a copy of it is set aside and the generation noted. The evolutionary process continues until the following conditions are met: at least 10 generations have passed, and the fittest individual so far is at least 6 generations old. There is no maximum generation, but in practice very rarely have more than 50 generations been necessary, and often fewer than 30 are required. This is still a lengthy process, as performing 10-fold cross validation for each member of the population is very processor intensive. The extra time required can justified by the improvement in the results over using, e.g., a single train and test set (results not shown). Information Gain, the fitness criterion employed by both Otero and EkArt, is much faster but is only applicable to a single feature - it cannot provide the fitness criterion for a set of features. We use tournament selection to select the parents of the next generation, with tournament size 8 and a 0.3 probability of the fittest individual winning (otherwise a 'winner' is selected at random from the tournament group).

3. Feature Selection with EC

45

There is a 0.6 probability of two-point crossover occurring between the ADFs of the two selected parents (whole trees are exchanged between genotypes):

Fig. 3.2. GA crossover

There is an additional 0.6 probability that crossover will occur between two ADFs at a randomly chosen locus (sub-trees are exchanged between trees): Mutation is used with probability 0.008 per node, whereby a randomly created subtree replaces the subtree under the selected node: We also use a form of inversion with probability 0.2 whereby the order of the trees between two randomly chosen loci is reversed: Experimentation on varying these parameters has found the algorithm to be fairly robust to their setting (not shown). Once the termination criteria have been met the fittest individual is used to seed the feature selection stage.
3.2.2 Feature Selection

The fittest individual from the feature creation stage (ties broken randomly) is analyzed to see if any of the original features do not appear to be used. If there are any missing, sufficient trees are added to ensure that every original feature in the data set appears at least once (the new trees are not randomly generated as in the feature creation stage, but have single nodes containing the required attribute). This extended genotype (up to twice as long as the fittest individual of the feature creation stage) replaces the initial individual and is used as the basis of the second stage.

46

Smith and Bull

Fig. 3.3. GP crossover

Fig. 3.4. Mutation

orrsprino 1

Fig. 3.5. Inversion

3. Feature Selection with EC

47

A new data set is constructed with one attribute for every tree in the extended genotype. In an attempt to reduce over-fitting of the data, the order of the data set is randomly reordered at this point. This has the effect of providing a different split of the data for 10-fold cross validation during the selection stage, giving the algorithm a chance of recognizing trees that performed well only due to the particular data partition in the creation stage. As a result of the reordering, it is usually the case that the fitness score of individuals in the selection stage is less than that of individuals in the creation stage, but solutions should be more robust. For the GA a population of 101 bit strings is randomly created. The strings have the same number of bits as the genotype has trees - there is one bit for every attribute (some composite, some primitive attributes). The last member of the population, the 10ISt bit string, is not randomly created but is initialized to all ones. This ensures that there are no missing alleles at the start of the selection. Once the entire population has been created, each genotype is evaluated and assigned a fitness score that is used in selecting the parents of the next generation. A GA bit string is evaluated by taking a copy of the parent data set and removing every attribute that has a '0' in the corresponding position in the bit string. As in the feature creation stage, this data set is then passed to a C4.5 (548) classifier whose performance on the data set is evaluated using 10-fold cross validation. The percentage correct is then assigned to the bit string and used as the fitness score. If the fittest individual in the current generation has a higher fitness score than the fittest so far (from the selection stage, ignoring genotypes from the feature creation stage), or it has the same fitness score and fewer 'l's, a copy of it is set aside and the generation noted. As in the feature creation stage the cycles of selection, crossover, mutation, and evaluation continue until the following conditions are met: at least 10 generations have passed, and the fittest individual so far is at least 6 generations old. The selection scheme is the same as for the creation stage. There is a 0.6 probability of two-point crossover and a 0.005 per bit probability of mutation.

3.3 Experimentation
We have used ten well-known data sets from the UCI repository to examine the performance of the GAP algorithm. The UCI data sets were chosen because they consisted entirely of numeric attributes (though the algorithm can handle some nominal attributes, as long as there are two or more numeric attributes present) and had no missing values (missing values could be handled with only a minor modification to the code). Table 3.1 shows the details of the ten data sets used here. For performance comparisons the tests were performed using ten-fold cross-validation (in which 90% of the data was used for training and 10%

48

Smith and Bull

Table 3.1. UCI data set information Data set Numeric features BUPA Liver Disorder (Liver) 6 Glass Identification (Glass) 9 Ionosphere (Iono.) 34 New Thyroid (NT) 5 Pima Indians Diabetes 8

Nominal features 0 0 0 0 0
0 0 0 0 0

Classes Instances
2 6 2 3 2 2 4 3 2 2

345 214 351 215 768
208 846 178 569 699

(Diab.) Sonar Vehicle Wine Recognition (Wine) Wisconsin Breast Cancer New (WBC New) Wisconsin Breast Cancer Original (WBC Orig.)

60 18 13 30 9

for testing). An additional set of ten runs using ten-fold cross validation were made (a total of twenty runs - two sets of ten-fold cross-validation) to allow a paired t-test to establish the significance of any improvement over C4.5 (548).

3 3 1 Results ..
The highest classification score for each data set is shown in Table 3.2 in bold underline. The first two columns show the performance of the GAP algorithm on the training data and the last column shows the results of the paired t-test. Results that are significant at the 95% confidence level are shown in bold. The GAP algorithm out-performs C4.5 (J48) on eight out of ten data sets, and provides a significant improvement on three (Glass Identification, New Thyroid, and Wisconsin Breast Cancer Original) - two of which are significant at the 99% confidence level. There are no data sets on which the GAP algorithm performs significantly worse than C4.5(548) alone. The standard deviation of the GAP algorithm's results do not seem to differ greatly from that of C4.5 (J48); there are five data sets where the GAP algorithms' standard deviation is greater and five where it is smaller. This is perhaps the most surprising aspect of the results, given that the GAP algorithm is unlikely to produce the same result twice when presented with exactly the same data, whereas C4.5 (J48) will always give the same result if presented with the same data. As noted in the introduction, Vafaie and DeJong [3.14] have used a very similar approach to improve the performance of C4.5. They use feature selection (GA) followed by feature construction (GP). We have examined the performance of our algorithm as described above with the two processes occurring in the opposite order. Results indicate that GAP gives either equivalent (e.g. Wisconsin Breast Cancer) or better performance (e.g. New Thyroid)

3. Feature Selection with EC

49

Table 3 2 Comparative performance of GAP algorithm and C4.5 (548) .. Data set GAP Train 75.04 78.17 95.99 98.22 78.15 92.33 78.82 98.47 97.86 97.65 89.07 S.D.
2.37 1.95 0.87 0.68 0.96 1.27 1.21 0.80 0.47 0.38

Liver Glass Iono. NT Diab. Sonar Vehicle Wine WBC New WBC Orig. Overall Average

GAP Test 65.97 73.74 89.38 96.27

S.D.

C4.5

S.D.

73.50
73.98 72.46 94.68 95.62 95.63
83.12

Paired t-test -0.22 33 .9 -0.34 3.02 0.19 0.05 0.20 0.85 1.87 21 .1 2.91

(Table 3.3). We suggest this is due to GAP'S potential to construct new features in a less restricted way, i.e. its ability to use all the original features during the create stage. For instance, on the New Thyroid data set the select stage will always remove either feature a or feature b thus preventing the create stage from being able to construct the apparently useful feature "b/a" (see Section 3.3.2). That is, on a number of data sets there is a significant difference (at the 95% confidence level) in the results brought about by changing the order of the stages.
Table 3.3. Comparison of ordering of create and select stages

Dataset Liver Glass Iono. NT Diab. Sonar Vehicle Wine WBC New WBC Orig. Overall Average

Create then Select Test S.D. 65.97 11.27 73.74 9.86 89.38 4.76 96.27 4.17 73.50 4.23 73.98 11.29 72.46 4.72 94.68 5.66 95.62 2.89 95.63 1.58 83.12

Select then Create Test S.D. 67.42 8.23 68.75 6.36 89.02 4.62 93.67 5.82 74.09 4.46 73.16 9.05 72.46 3.01 94.69 3.80 95.88 3.15 95.13 2.16 82.43

3 3 2 Analysis ..
We were interested in whether the improvement over C4.5 (548) is simply the result of the selection stage choosing an improved subset of features and discarding the new constructed features. An analysis of the attributes output

50

Smith and Bull

by the GAP classifier algorithm, and the use made of them in C4.5'~ decision trees, shows this is not the case. As noted above, the results in Table 3.2 were obtained from twenty runs on each of ten UCI data sets, i.e. a total of two hundred individual solutions. In those two hundred individuals there are a total of 2,425 trees: 982 ADFs and 1,443 original features - a ratio of roughly two constructed features to three original features. All but two of the two hundred individuals contained at least one constructed feature. Table 3.4 gives details of the average number of ADFs per individual for each data set (the number of original features used is not shown).
Table 3.4. Analysis of the constructed features for each data set Name Data set Features
6 9 34 5 8 60 18 13 30 9

Liver Glass Iono. NT Diab. Sonar Vehicle Wine WBC New WBC Orig.

Average Features 4.9 7.1 19.7 3.2 6.4 38.0 16.3 5.2 15.7 5.0

Results Average ADFs 2.6 3.1 7.6 2.3 2.7 13.6 5.5 2.1 7.0 2.9

Minimum ADFs 1 1 4 1 1 5 2 0 4 1

Knowing that the feature selection stage continues as long as there is a reduction in the number of attributes without reducing the fitness score, we can assume that C4.5 (J48) is making good use of all the attributes in most if not all of the winning individuals. This can be demonstrated by looking in detail at the attributes in a single winner, and the decision tree created by C4.5(J48). One of the best performers on the New Thyroid data set had three trees, two of them ADFs and hence constructed features. The original data set contains five features and the class: Tbresin uptake test. (A percentage) Total Serum thyroxin as measured by the isotopic displacement method. Total serum triiodothyronine as measured by radioimmuno assay. Basal thyroid-stimulating hormone (TSH) as measured by radioimmuno assay. 5. Maximal absolute difference of TSH value after injection of 200 micro grams of thyrotropin-releasing hormone as compared to the basal value.
1. 2. 3. 4.

Class attribute. (1 = normal, 2 = hyper, 3 = hypo) In the chosen example the newly constructed features were:

3. Feature Selection with EC
-

51

"e" becomes FeatO "((a/d)*b)" becomes Feat1 "(b/a)" becomes Feat2

The decision tree created by C4.5 (the numbers after the class prediction indicate the count of train instances correctly / incorrectly classified) was:

Fig. 3.6. New thyroid decision tree

It is apparent that C4.5 (548) is using the constructed features to classify a large majority of the instances, and only referring to one of the original features (FeatO, or the original feature "e") in 29 of 150 cases.
3.3.3 The Importance of Reordering the Dataset

In section two it was mentioned that the data set was randomly reordered before the second stage commenced, providing a different view of the data for 10-fold cross validation during fitness evaluation and, it was hoped, this would reduce over fitting and improve the performance on the test data. Is this what actually happens? In order to test this hypothesis we turned off the randomization and retested the algorithm. The first impression is that there is no important difference between the two sets of results - there are 5 data sets where not reordering gives a better result and 5 where it is worse. However, there are now only two (rather than three) data sets on which the algorithm provides a significant improvement over C4.5 (548) (New Thyroid and Wisconsin Breast Cancer); and most importantly the t-test performed over the 200 runs from all data sets no longer shows a significant improvement. The results were as follows (the column for paired t-test shows the results for testing the algorithm without reordering against C4.5(548)):

52

Smith and Bull

Table 3.5. Comparative performance of GAP algorithm with and without reordering) and C4.5 (548) Data set GAP reorder
65.97
73.74

S.D.
11.27 9.86 4.76 4.17 4.23 11.29 4.72 5.66 2.89 1.58

GAP
no

S.D.
7.84 9.79 4.24 3.78 4.34 8.32 4.43 5.09 2.58 1.59

C4.5 (548)

S.D.
8.86 8.86 4.79 4.14 5.25 10.92 3.33 5.70 4.22 3.05

Paired t-test
0.17 0.61 -0.04
3.99

reorder

Liver Glass Iono.
NT

66.65

89.38 96.27
73.50

69.74 89.77
97.22

66.37 68.28

89.82
92.31 73.32 73.86 72.22 93.27 93.88 94.42 81.77

Diab. Sonar Vehicle Wine WBC New WBC Orig. Overall Average

71.74
75.22

72.46
94.68 95.62

73.98

71.94 94.08 94.56
95.71

-1.37 0.50 -0.28 0.55 0.71
2.03

95.63 83.12

82.66

1.82

3.3.4 Combining Creation and Selection in a Single Stage

Having successfully tested the algorithm with two separate stages, we r e designed it to move feature selection into the construction stage. Feature construction occurs as before but each tree now has a bit flag associated with it, to determine whether the tree is passed to C4.5(548) for evaluation. During crossover each tree retains its associated bit flag, which is subject to the same chance of mutation as during the second stage (0.005). Testing the amended algorithm with the same parameter values as before gives a much shorter run time (not surprisingly, roughly half the time of the two stage algorithm) but with poorer results - an overall average of 82.20%' (though this is still an improvement over unaided C4.5 (J48)). There are three primary differences between the two versions of the algorithm that may account for this drop in performance: With a single stage we are asking the algorithm to do the same amount of work in half the time. There is no longer an opportunity to randomly reorder the data set between stages. There is no longer an opportunity to reintroduce any original attributes that have been dropped during the first stage. There seems no reasonable way to address the third of these differences with a single stage approach, but the other two can be compensated for. Firstly we It should be noted that the results for some of the data sets have a fairly high standard deviation, and so can show some variation in the results from run to run. For this reason we have taken to using the average result over all 10 data sets as a useful (and briefer!) indicator of the performance of the algorithm.

3. Feature Selection with EC

53

can change the termination criteria - by doubling both the minimum number of generations to 20 and the age of the fittest individual to 12 generations. Doing this does improve the result (to an overall average result of 82.88%) but not sufficiently to bring it into line with a two stage process. Additionally we can randomly reorder the data set. We considered two approaches to this. The first was to have two versions of the data set from the start, with the same data but in a different order, and simply alternate between data sets when evaluating each generation (i.e. the first data set was used to evaluate even numbered generations, the second to evaluate odd numbered) - this approach did not seem to improve the results (slightly worse than having no reordering at 82.24%).The second, more successful, approach was to reorder the data set once the termination criteria had been reached. That is, run as before but when the fittest individual reaches 12 generations old reorder the data set, re-evaluate the current generation and reset the fittest individual, then continue until the termination criteria are met again. The results obtained with a longer run time and randomly reordering the data set part-way through are shown in the table below (Table 3.6) (the column for paired t-test shows the results for testing the single stage algorithm against C4.5 (J48)).
Table 3 6 Comparative performance single stage and C4.5 (548) .. Data set
2 stage

S.D.
11.27

1 stage

S.D.
8.10 10.26 4.66 3.98 5.11 9.00 4.60 4.08 4.39 2.52

S.D.
8.86 8.86 4.79 4.14 5.25 10.92 3.33 5.70 4.22 3.05

Liver Glass Iono.
NT

65.97

Diab. Sonar Vehicle Wine WBC New WBC Orig. Overall Average

66.55 71.84 90.69 96.49 73.64 75.89 72.11 96.10 95.71 95.56

Paired t-test 0.11 1.78 0.96 36 .9 0.24 0.80 -0.09 1.76 1.71 1.62

83.12

Although the single stage algorithm out-performs C4.5 (548)) on only one data set at the 95% confidence level (a t-test of 1.96 or higher), as compared to three data sets for the two stage algorithm, it outperforms C4.5(J48) on everything but the Vehicle data set (and then loses by a very small margin). It also improves on the performance of the two stage version on seven out of ten data sets, resulting in an increase of the (already high) overall confidence of improvement over C4.5 (J48).

54

Smith and Bull

3.3.5 A Rough Comparison to Other Algorithms

Table 3.7 presents a number of published results we have found regarding the same ten UCI data sets using other machine learning algorithms. It should be noted that in the table the results for C4.5 were not obtained using J48. The GAP column presents results for the single stage version of the algorithm. Cells in the table are left blank where algorithms were not tested on the data set in question. The highest classification score for each data set is shown in bold underline.
Table 3.7. Performance of GAP and other algorithms on the UCI data sets Data set
Liver Glass Iono.

GAP
66.55 71.84 90.69 96.49 73.64 75.89 72.11 96.10 95.71 95.56

NT
Diab. Sonar Vehicle Wine WBC New WBC Orig.

C4.5 (548) 66.37 68.28 89.82 92.31 73.32 73.86 72.22 93.27 93.88 94.42

C4.5 HIDER XCS 65.27 64.29 67.27 70.59 67.94 74.1 69.69 56.93 93.29 96.05 93.72 95.71 67.85 72.53 68.62 53.41 92.74 96.27

0. A. F.
57.01 69.56 69.8 79.96 98.27 94.39

LVSM 68.68 87.75 78.12

The results for C4.5, HIDER and XCS were obtained from [3.2],those for O.F.A. ('Ordered Fuzzy ARTMAP', a neural network algorithm) from [3.1] and LVSM (Lagrangian Support Vector Machines) from [3.9]. The differences between the reported results for C4.5 and those for C4.5 as used in this paper (548, the WEKA implementation of C4.5) are likely to arise from different data partitions used for the tests (the most notable being the 5.38% difference in results for Pima Indians Diabetes). This discrepancy highlights the dangers inherent in comparing results with published data - the comparison should be seen as purely informal. The only comparisons that can be relied upon are those between the GAP classifier and C4.5 (548) as these have been performed using exactly the same procedure and data partitions. The results are by no means an exhaustive list of current machine learning algorithms, nor are they guaranteed to be the best performing algorithms available, but they give some indication of the relative performance of our approach - which appears to be very good.

3.4 Conclusion
In this chapter we have presented an approach to improve the classification performance of the well-known induction algorithm C4.5. We have shown that

References

55

GP individuals consisting of multiple trees/ADFs can be used for effective feature creation and t h a t solutions, combined with feature selection via a GA in either a separate or t h e same stage, can give significant improvements to the classification accuracy of C4.5. We have also indicated t h a t randomly reordering t h e data set part-way through the process may help t o reduce the problem of overfitting. Future work will apply our approach t o other d a t a sets and d a t a mining algorithms.

References
3.1 Ahluwalia, M., Bull, L. (1999): Co-evolving functions in genetic programming: classification using k-nearest neighbour. In Banzhaf, W., Daida, J., Eiben, G., Garzon, M. H., Honavar, J., Jakeila, K., Smith, R. (eds) GECCO-99: Proceedings of the Genetic and Evolutionary Computation Conference. Morgan Kaufmann, 947-952 3.2 Dixon, P. W., Corne, D. W., Oates, M. J. (2001): A preliminary investigation of modified XCS as a generic data mining tool. In Lanzi, P. L., Stolzmann, W., Wilson, S. (eds) Advances in Learning Classifier Systems. Springer, pp.133-151 3.3 EkBrt, A., Mkkus, A. (2003): Using genetic programming and decision trees for generating structural descriptions of four bar mechanisms. To appear in Artificial Intelligence for Engineering Design, Analysis and Manufacturing 3.4 Holland, J.H. (1975): Adaptation in natural and artificial systems. Univ. Michigan 3.5 Kelly, J.D., Davis, L. (1991): Hybridizing the genetic algorithm and the k nearest neighbors classification algorithm. In R. Belew, L. Booker (eds ) Proceedings of the Fourth International Conference on Genetic Algorithms. Morgan Kaufmann, pp377-383 3.6 Kohavi, R., John, G. H. (1997): Wrappers for feature subset selection. Artificial Intelligence Journal 1,2, 273-324 3.7 Koza, J.R. (1992): Genetic programming. MIT Press 3.8 Krawiec, Krzysztof (2002): Genetic programming-based construction of features for machine learning and knowledge discovery tasks. Genetic Programming and Evolvable Machines 3, 329-343 3.9 Mangasarian, 0. L., Musicant, D. R. (2001): Lagrangian support vector machines. Journal of Machine Learning Research, 1, 161-177 3.10 Otero, F. E. B., Silva, M. M. S., Freitas, A. A., Nievola, J. C. (2003): Genetic programming for attribute construction in data mining. In Ryan, C., Soule, T., Keijzer, M., Tsang, E., Poli, R., Costa, E. (Eds.) Genetic Programming: 6th European Conference, EuroGP 2003, Essex, UK, Proceedings. Springer, 384-393 3.11 Quinlan, J.R. (1993): C4.5: Programs for machine learning. Morgan Kaufmann 3.12 Raymer, M.L., Punch, W., Goodman, E.D., Kuhn, L. (1996): Genetic programming for improved data mining - application to the biochemistry of protein interactions. In Koza, J. R., Deb, K., Dorigo, M., Fogel, D. B., Garzon, M., Iba, H., Riolo, R. (eds) Proceedings of the Second Annual Conference on Genetic Programming, Morgan Kaufmann, 375-380 3.13 Siedlecki, W., Sklansky, J. (1988): On automatic feature selection. International Journal of Pattern Recognition and Artificial Intelligence 2, 197-220

56

References

3.14 Vafaie, H., De Jong, K. (1995): Genetic algorithms as a tool for restructuring feature space representations. In Proceedings of the International Conference on Tools with A.I. IEEE Computer Society Press 3.15 Witten, I.H., Frank, E. (2000): Data mining: practical machine learning tools and techniques with Java implementations. Morgan Kaufmann

4. Multi-Agent Data Mining using Evolutionary Computing
Riyaz Sikora Dept. of Information Systems & OM The University of Texas at Arlington P.O. Box 19437, Arlington, TX 76019
rsQora@uta.edu

Abstract :In this chapter we present a multi-agent based data mining algorithm for scaling up and improving the performance of traditional inductive learning algorithms that build feature-vector-based classifiers in the form of rule sets. With the tremendous explosion in the amount of data being amassed by organizations of today, it is critically important that data mining techniques are able to process such data efficiently. We present the Distributed Learning System, a multi-agent based data mining system that uses genetic algorithms as learning agents and incorporates a self-adaptive feature selection method.

4.1 Introduction
The amount of customer, financial, marketing, operations, and other sorts of data being amassed by organizations has increased by manifold in recent times. The ability to produce and store such voluminous data has far outpaced the ability to analyze and interpret this data, and derive useful knowledge from it. Large databases these days have millions of records and each record may have hundreds or even thousands of fields. For example, in the business world, one of the largest databases was created by Wal-Mart, which handles over 20 million transactions a day [4.3]. Similar instances can be found in databases created by health care companies, oil exploration firms, database marketing, and scientific research consortiums, just to name a few. Such volumes of data clearly overwhelm more traditional data analysis methods. A new generation of tools and techniques are needed to find interesting patterns in the data and discover useful knowledge. Successful development of effective and efficient data mining algorithms can also provide enormous benefits to an organization from the business standpoint. Benefits include reduced costs due to more accurate control, more accurate future predictions, more effective fault detection and prediction, fraud detection and control, and automation of repetitive human tasks. Although there are several algorithms available for discerning patterns from data in the machine learning, statistics, and classification literature, they generally break down in data mining applications because of the size of the data set. In a typical application involving data mining there are

58

Sikora

hundreds, possibly thousands of fields per record, majority of which are either unimportant or not directly relevant to the problem. The traditional machine learning algorithms end up wasting a lot of computational effort processing unimportant information. In this chapter we present the concepts of distributed learning and simultaneous feature selection in designing more effective and efficient genetic algorithm (GA) based data mining algorithms. The distributed learning concept uses the divide-and-conquer strategy in which the data set is divided into multiple sub-sets. Multiple copies of the algorithm then work on the sub-sets in parallel and their results are synthesized. This concept is especially suitable for evolutionary computation methods, as they are population based. The results of the sub-sets can be used as members of the population in the synthesis step. Because of the parallelism involved in distributed learning, the developed algorithm can also be executed more efficiently on a parallel machine.

4.2 Related Work
There are many data mining algorithms currently in use. Most of them can be classified in one of the following categories: Decision trees and rules [4.10, 4.371, nonlinear regression and classification methods [4.19, 4.161, example-based methods [4.13,4.23], probabilistic graphical dependency models [4.32, 4.471, and relational learning models [4.14]. Over the years genetic algorithms have been successfully applied in learning tasks in different domains, like chemical process control [4.40],financial classification [4.41],manufacturing scheduling [4.28], robot control [4.42], etc. There has also been some work done related to developing hybrid learning systems involving genetic algorithms [4.5, 4.461. One of the biggest problems in using some of the traditional machine learning methods for data mining is the problem of scaling up the methods to handle the huge size of the data sets and their high-dimensionality. Provost and Kolluri [4.35] provide a survey of techniques for scaling up machine learning algorithms. In this chapter we look at two approaches, feature selection and distributed learning, that can be used for making learning algorithms more efficient and scalable.
4.2.1 Feature Selection

Feature selection can be defined as selecting the smallest subset of the original set of features that are necessary and sufficient for describing the target concept [4.24]. The marginal benefit resulting from the presence of a feature in a given set plays an important role. A given feature might provide more information when present with certain other feature(s) than when considered

by itself. Cover [4.12], Elashoff et. al. [4.15], and Toussaint [4.44], among others, have shown the importance of selecting features as a set, rather than selecting the best features to form the (supposedly) best set. They have shown that the best individual features do not necessarily constitute the best set of features. There have been many approaches to feature selection based on a variety of techniques, such as statistical [4.25], geometrical [4.17], informationtheoretic measures [4.7],mathematical programming [4.9],among others. Several researchers have also used evolutionary algorithms for feature selection by using a classifier as a fitness function [4.36, 4.6, 4.46, 4.451. GAS have also been used in feature selection for creation of ensemble classifiers [4.20, 4.311. Feature selection has been traditionally used in data mining applications as part of the data cleaning and/or pre-processing step where the actual extraction and learning of knowledge or patterns is done after a suitable set of features is extracted. If the feature selection is independent of the learning algorithm it is said to use a filter approach. Lanzi [4.27] presents one such filter approach to feature selection using genetic algorithms. If the feature selection method works in conjunction with the learning algorithm it is using a wrapper approach [4.22, 4.481. The problem with the filter approach is that the optimal set of features may not be independent of the learning algorithm or classifier. The wrapper approach, on the other hand, is computationally expensive as each candidate feature subset has to be evaluated by executing a learning algorithm on that subset. When used with GAS, the wrapper approaches become even more prohibitively expensive [4.27]. Raymer et. al. [4.38] presents an approach of simultaneously doing feature selection and optimizing feature weights using a GA. In this chapter we present a new approach to feature selection using genetic algorithms that is based on the concept of self-adaptation where the learning and feature selection are done simultaneously. Feature selection concept presented in this chapter is related to two aspects of work done earlier: self-adaptation and use of non-coding material in the chromosome structure (called introns) motivated by the existence of non-encoding DNA in biological systems. In biological systems an intron is a portion of the DNA that is not transcribed into proteins. Introns can become an important part of the evolution process by providing a buffer against the destructive effects of the genetic algorithm. At the same time introns have been shown to be useful as a source of symbols that can be effectively used to evolve new behaviors through subsequent evolution [4.29, 4.301. Self-adaptation [4.1] refers to the technique of allowing characteristics of the search to evolve during the search rather than be specified by the user. Most of the work done on self-adaptation has focused on choices related to search operators. Aspects of these choices are encoded along with each member of the population and they are allowed to vary and adapt on an individual basis. One of the most common traits to be self-adapted has been

60

Sikora

the mutation rate [4.39, 4.18, 4.41). Others have included crossover [4.2] and inversion operators [4.11]. In all applications involving the use of evolutionary computation methods in machine learning, feature selection is either done implicitly or a wrapper approach is used for discerning important set of features. The learning algorithm is then applied for learning rules or patterns based on the features selected. In this chapter we present a GA for doing both of these tasks simultaneously by evolving a binary code for feature selection along side the chromosome structure used for evolving the rules.

4.2.2 Distributed Data Mining
Another approach for improving the efficiency of data mining algorithms is by using distributed learning. Even if all the data is centrally located in a single database, distributed data mining can be used effectively in scaling up by using the divide-and-conquer strategy. Moreover, there are many data mining problems that are inherently distributed. For example, the point-ofsale information for any big retailer (like Wal-Mart) is distributed across its various locations. In many instances it is not feasible to create and maintain a monolithic database by combining these distributed sources into a centralized database. In other scenarios security concerns do not allow the coalescing of separate data sources into one database. In such cases distributed data mining is the only feasible alternative, whereby the local databases are mined independently by the data mining algorithms and the results are then combined. Provost [4.34] provides a comprehensive summary of the different factors that motivate the development of distributed data mining. Prodomidis [4.33] present an approach for distributed data mining by using Java agents in which the distributed databases are mined independently by separate learning agents and their results are combined by using a meta-learning strategy. In this chapter we present a multi-agent system for distributed data mining that uses GA-based learning algorithm as individual agents and show that it can significantly improve the scale-up properties of the learning agent.

4.3 Data Mining with GA
In this section we present the design of a genetic algorithm for rule learning in a data mining application. Assume that the data mining problem has k attributes and we have a set of training examples I, ={(Et,c) 1 t = l , ..., T} I where T is the total number of examples, each example Et is a vector of k attribute values Et = [etl, et2, . . - , etrcl

and c is its classification value (usually a binary value indicating whether the example is a positive or a negative). The goal of data mining is to learn concepts that can explain or cover all of the positive examples without covering the negative examples. The representation of a concept or a classifier used by the GA is that of a disjunctive normal form. A concept is represented as

where each disjunct di (also referred to as a rule) is a conjunction of conditions on the k attributes, The above concept R is said to have a size of p (which we refer to as the rule size). In order to handle continuous attributes each condition &,i is in the form of a closed interval [aj, bj]. We say that a disjunct di covers an example Et if

Each member of the population in the GA is a single disjunct and the GA tries to find the best possible disjunct. At each generation it retains the best disjunct and replaces the rest through the application of the genetic operators. After the genetic algorithm converges, the best disjunct found is retained and the positive examples it covers are removed. The process is repeated until all the positive instances are covered. The final rule or concept is then the disjunct of all the disjuncts found. This procedure for searching the instance space (I-space) is called q l a n a t i o n based filtering, and is summarized in Fig. 4.1. The fitness function looks at the number of positive and negative examples covered by the rule but it also assigns partial credit for the number of attribute intervals on that rule that match the corresponding attribute values on a positive training example. Specifically, the fitness function is given by F = a Ck(p-n), where a is the total number of partial matches, C is a constant, k is the number of attributes, p is the number of positive examples covered by the rule, and n is the number of negative examples covered by the rule. Note that the partial credit portion of the fitness functions plays an important role in the initial generations in guiding the concepts that are being developed towards covering positive examples. As the concepts start covering more and more positive examples, the second term in the fitness function becomes correspondingly more dominant. The fitness function thus behaves like an adaptive function. In the next section we present a technique for performing simultaneous feature selection using the GA.

+

62

Sikora

/ k t : set of training examples y
initialize concept descriptionR = 0
while (there are still positive examples in

v

)

I
I
I

{

initialize the GA with random disjuncts (6i
repeat

I

i

= 1

... N)

where N is

the population size;

compute F(6i), the fitness function value for each disjunct 6i; reproduce a new population by applying the genetic operators;
until
(

the stopping criteria for the GA is met

);

Q=Qv&

(add the best disjunct to the concept);

remove all the positive examples from yt that are covered by

I

Output: concept description R learned by the GA

Fig. 4.1. Procedure GA

4.4 Feature Selection as Self-Adaptation
The GA presented above is modified as follows to incorporate the selfadaptive feature selection method. Each population member contains, in addition to the disjunct, a binary vector for feature selection that also evolves alongside the disjunct. A feature is selected if the corresponding bit in the selection code is 1. For example, if we have five attributes in the original feature set a typical rule represented in the new approach would look like the following:

Since only X2, Xq, and X5 have a corresponding 1on the selection vector, the rule becomes:

IF (0.12 5 X2 5 0.24) AND (0.4 5 X4 5 0.7) AND (0.2 5 X.5 5 0.87)
The uniform crossover operator is applied to the trio of values (the interval limits and the selection bit) for each attribute instead of the pair of values as in the last section. The mutation operator flips the binary digits on the selection vector in addition to changing the pair of numbers for each

attribute as in the last section. The initial population is created as before with the interval pairs for each attribute on a member created with uniform distribution and the binary selection vector randomly generated with a probability of Fselect for selecting a particular feature (i.e., a 1 appearing on the selection vector corresponding to that feature). The fitness function remains the same as before except that the selection vector is also used in deciding which attributes are considered for fitness evaluation. Since the fitness evaluation now also depends on the feature subset selected we can hypothesize that this would start evolutionary pressures for good features to be selected. Note that an attribute's interval limits on a rule can change due to crossover or mutation even when that feature is not selected in the rule. This is similar to the concept of introns mentioned earlier where non-coding genes are allowed to propagate and evolve in the hope that in a later generation they might be found to be useful. The interval limits of the attributes not selected in a rule can be thought of as introns. Since these are not used in the fitness evaluation they do not affect the computation time. The only additional resource they consume is the memory storage. However, since the GA used is a fixed length GA the use of introns in this case does not lead to the problems of bloat so often associated with the use of introns in the genetic programming community.

4.5 Multi-Agent Data Mining
The task of data mining is concerned with deriving rules or patterns that can best explain a set of data points or examples. In the traditional approach to data mining, a single learning program is used that generates a set of rules or patterns and successively refines it to explain all the examples. Since the process involves generating and evaluating hypotheses at each stage, it can be more effective and efficient to use a multi-agent approach where the examples are distributed to different learning agents and their partial results are synthesized into the final hypothesis. Such a multi-agent problem-solving approach is implemented in the Distributed Learning System (DLS). Since a learning agent is now working on only a fraction of the original data set and the different agents can work asynchronously, this method of distributing the amount of resources (data) can make the process parallel. At the same time, by using multiple agents that provide several different hypotheses of the solution, the approach can potentially provide better performance. The Multi-Agent Systems (MAS) solving paradigm has been extensively studied in the Distributed Artificial Intelligence (DAI) 14.21, 4.81 community. We designed the DLS using the four basic steps of distributed problem solving (Smith and Davis, 1981): (1)problem decomposition, (2) sub problem allocation, (3) sub problem solution, and (4) solution synthesis. Fig. 4.2 illustrates the conceptual model of DLS. At first, the data set P is decomposed into

64

Sikora

different subsets PI, P2...P,, which are then allocated to different learning agents. Each agent solves its sub problem independently of the other agents. The individual solutions are then synthesized into a final solution.

(subproblems)

(leamingagents)
INDUCTIVE LEARNING

(group adapation)
b

data set)

SOLUTION SYNTHESIS

+a
(learned concep

I

PROBLEM DECOMPOSITION

I

ASSIGNMENT TAs I :

I zgE I
LOCAL

I

Fig. 4.2. The distributed learning system

The above is only a conceptual model of the DLS and it can be implemented in many different ways. There could be several ways of performing the problem decomposition. For example, in record-based decomposition the data set is decomposed along the records. Each learning agent gets a fraction of the records (or examples) from the data set. This models real world situations where the records are distributed. For example, a chain store collecting point-of-sale information at its various locations that are geographically dispersed. A second method of decomposing the data set is the attribute-based decomposition where the data set is distributed among the agents along the attributes, with each agent getting the data corresponding to a subset of the attributes. This models the real world situations in which the data is spatially distributed (for e.g., air traffic control). The above mentioned distributed approach of data mining can be very efficient in these cases as the data can be analyzed at its point of origin and the individual results can then be synthesized. The two types of decomposition strategies can also be combined together. The task assignment and local problem-solving phase of the DLS can also be implemented in several different ways. For example, one can either use the

same learning agent on the different subsets or use different types of learning agents. By using different learning agents it is possible to build a hybrid data mining system that can use one learning agent's strengths to mask the problems of others and at the same time provide a diversity of learning biases that are inherent in any learning agent. A genetic algorithm becomes the natural choice for the synthesis phase of the DLS because of several reasons. First, since it is a population based method it can be seeded with the results of different learning agents. Second, since the GA works by combining two or more solutions to produce better ones it is a perfect choice for synthesizing and improving multiple solutions. Lastly, since its fitness function can be user defined it is ideal for managing trade-offs such as rule size vs. accuracy. Note that for handling complex representation languages one can also use a Genetic Programming 14.261 based synthesizing agent in the DLS that would treat the output of the learning agents as programs. Also, in our version of the DLS the agents do not cooperate explicitly with each other. We use the GA to simulate the cooperative group-problem solving behavior of agents where the group iteratively goes through modifying their individual solutions until they reach some kind of a group solution. In the DLS system, the data set is distributed over the learning agents. In our implementation all the learning agents use the GA procedure described in Fig. 4.1. Rules learned by the individual agents are then synthesized by another GA to produce the final concept. The DLS procedure is summarized in Fig. 4.3.

h t : a set of training examples yr,

a group of n data mining agents, q,i = 1
Begin:

... n; .- yrn, where
yr = yr, u yr2

decompose yr into n subsets, y, yr2, r, for each agent ni, i = 1

...

yrn;

... n,

execute the procedure GA(yri) to get
Qi ;

create a population

r

by using the individual disjuncts from all
=

the concepts Ri, i

1

.. n, .

as follows:

r={Si/ 6 , 1 ~ ~ ~ ~ i = l . . . n ~ j = l .where, }Ri =6, ~ ~ V . . . V ~ ~ , ; I ..p , V
execute the procedure GA(yr) by using

r

as the initial population;

Outuut: concept description R learned by the group;

Fig. 4.3. Procedure DLS

66

Sikora

4.6 Experimental Results
4.6.1 Experimental Design

The following parameter values for the GA were selected after fine-tuning the GA over several runs. The GA implemented in DLS uses uniform crossover operator with a probability of 0.7. The interval range for each attribute on the rule is considered as a single entity for the purpose of crossover. The mutation operator used can be thought of as a specialization/generalization operator, which either increases or decreases (with equal probability) the interval range of an attribute by either increasing or decreasing the upper or lower interval limit with equal probability of 0.1. The reproduction operator uses a tournament selection with a size of 2. The initial population is created by generating random disjuncts. A population size of 100 is used and the terminating criterion for the GA is the non-improvement in the fitness value of the best individual in 10 generations. All the algorithms used in this chapter were implemented in C++ on a Sun workstation running SunOS 5.7. The systems were tested on a real world chemical process control plant data. The data had 30 process variables, of which only 9 were controllable, and one boolean classification variable. All variables had continuous values from the domain [0.0 0.991. The data set had 5720 instances, of which 3550 were positive examples and 2170 were negative examples. It was randomly broken up into 10 pairs of a training set of 3440 examples and a testing set of 2280 examples. Four different problem variations were created from the above data set. In the first case only the 9 controllable variables were used. In the second case all the 30 variables were used, and for the last two cases 20 variables were constructed by randomly combining the existing variables to create a data set with 50 and 70 variables. Having these four different sizes of essentially the same problem allows us to test the performance of the system as the size of the problem domain increases and study its scale-up properties, something very crucial for data mining applications. The last two problem variations also allow us to test the effectiveness with which the data mining system can detect the irrelevant attributes. Typical data mining applications involve a lot of irrelevant attributes and it is widely recognized that around 80% of the resources in such applications are spent on cleaning and preprocessing the data.
4.6.2 Effectiveness of Feature Selection

We carried out several experiments to first test the effectiveness of using the binary selection vector for performing feature selection. Since we are using a population-based method (GA), one of the best ways to study the effectiveness of such a technique is to study the evolution of population proportions having different features. We can conclude that the feature selection technique is effective if the proportion of individuals having features that are important

4. Multi-agent DM by EA

67

or relevant keeps growing and the proportion of individuals having features that are not relevant keeps dwindling. In other words, the proportion of good features in a population should grow and that of irrelevant features should decline with generations. We can also be sure of the robustness of this method if the proportion of different features in the population converges to similar levels irrespective of the initial proportion of those features in the population.

Feature Proportions

Fig. 4.4. Evolution of feature proportions with Fselect=O.l

Several runs of the GA, without feature selection, produced concepts that always included attribute Xs with a very high discriminating interval indicating that X8was an extremely important attribute. To test the feature selection method outlined above we carried out experiments on the 9-attribute problem mentioned earlier. The proportion of each feature (attribute) selected in a population was tracked and three experiments were carried out with the initial proportion of each feature in the population set at 0.1, 0.5, and 0.9 (i.e., the parameter Fselect was set at 0.1, 0.5, 0.9 respectively). Figs. 4.4, 4.5 and 4.6 show the convergence of the proportions for the 9 features. Irrespective of the initial feature proportions it can be seen from the three figures that features X8, X5, and X3 quickly take over indicating that they might be very important, and feature X7 dies out of the population indicating that it might not be relevant. In fact, the proportion of individuals having a feature can also indicate the relative importance of that feature. For e.g., from the figures we can see that X8 is consistently present in the maximum proportion of individuals in the population followed by X5 and X3. The other features tend to be present in only about half the population indicating that they are not very important and might be used only in refining the rules. Their actual importance would be reflected by the corresponding intervals in the

68

Sikora

Feature Proportions

Fig. 4.5. Evolution of feature proportions with Fselect=0.5

Feature Proportions

Fig. 4.6. Evolution of feature proportions with Fselect=O.9

rules that the GA is evolving simultaneously. For e.g., in one trial the best rule given by the GA was as follows:

The above rule covered 1130 positive examples and 330 negative examples out of the 2280 examples of the testing set. Note that although the selection vector selected the features X3, X4,X5, X6, and X8, we can see that the feature X4 is not very important for the rule as its interval range of (0.003, 0.99) almost covers its entire domain of (0.00, 0.99). This experiment shows that the feature selection method presented above is effective in learning the important and the irrelevant features. Similar results have been observed for the above problem domain with 30, 50, and 70 features. In the next section we present detailed experimental results evaluating the performance of DLS.
4.6.3 Effectiveness of DLS

In the next set of experiments the DLS system was tested in which GAS are used as the learning agents so that the feature selection technique embedded within the GA can be used at the front end of the system. Attribute-based decomposition is used in these experiments as we want to study the scale-up properties of the system when the problem size is increased. For comparison purposes a single agent version of the system is also tested where the GA is used as the sole learning agent. To delineate the effect of using feature selection with that of using distributed learning on the performance of the system, a single agent version of the system with feature selection is also tested. The same parameter values are used for the GAS as described in section 6.1. As before 10 different pairs of data sets are used and for each data set pair the system is run 5 times with different random number seeds. The performance of the system is measured in terms of the prediction accuracy (%), computation time (sec.), and the rule size. The detailed results for the 9 variable, 30 variable, 50 variable, and the 70 variable problems are presented below in Tables 4.1-4.4. Note that each cell is an average of 5 trials. The single agent version of the system without feature selection is used as a benchmark and the one-tailed Student-t test for paired results is performed to test the statistical significance of the results. The average and standard deviation values are provided together with the t-values of the test wherever the differences are significant at 0.05 level of significance. The average results from the four problem sizes are summarized in Table 4.5 to provide a clearer picture about the scale-up properties of the methods. Some of the major findings can be summarized as follows:

70

Sikora

Table 4.1. Results for 9 variable problem

Table 4.2. Results for 30 variable problem

72

Sikora

Table 4.3. Results for 50 variable problem

Data Set

Simple GA wlo Feature Selection

GA with Simultaneous FS

DLS (No. of Agents = 5)

Table 4.4. Results for 70 variable problem

74

Sikora

Table 4.5. Summary of results

Performance of the simple GA quickly deteriorates as the problem size increases. Its prediction accuracy plummets at the same time its computational time and the complexity of the concept increase substantially. - When self-adaptive feature selection is added to the simple GA (GAFS), the performance in terms of computation time and the prediction accuracy of the concept does improve significantly without significant change in the complexity of the concepts learned. However, the general performance trend as the problem size increases remains the same, with a degradation in performance as the problem size increases from 30 variables to 70 variables. As hypothesized earlier, the main advantage of the self-adaptive feature selection method is to improve the computational time required, but it is interesting that in doing so it also improves the prediction accuracy of the concepts learned. For example, for the 70 variable problem the GAFS method improves the prediction accuracy by statistically significant 4% and reduces the computational time by about 26%. - The DLS method, in general, improves the overall performance. However, it can be seen that the benefit of distributed learning is realized and becomes more pronounced as the problem size is increased. Because of the overhead costs of data distribution, communication, and synthesis involved in distributed learning, it is not beneficial to use DLS for smaller problems. However, these costs become insignificant in comparison to the actual cost of data mining as the problem size increases. For example, for the 70 variable problem, the DLS improves the prediction accuracy by a statistically significant lo%, reduces the computational time by about 32%, and reduces the rule size by about 15% compared to the GA.
-

4.7 Conclusions and Future Work
In this chapter we presented a genetic algorithm based multi-agent data mining system called Distributed Learning System (DLS) and evaluated its performance on four different sizes of a real world problem. We introduced a novel technique of feature selection that can be embedded in a GA that simultaneously does rule learning. We clearly demonstrated the potential of the DLS in providing good scale-up property and improved performance as measured by the prediction accuracy of its classifiers. Currently work is under way in extending the system on several fronts. In the problem decomposition phase of the system a mix of the attributebased and record-based decomposition is being investigated. In the local problem-solving phase we are working on incorporating different data mining algorithms. In the synthesis phase, we are investigating the use of genetic programming (GP), instead of a simple GA, that will help in extending the representation language of the classifiers beyond the disjunctive normal form. Also, one of the advantages of using probabilistic population based methods like GA/GP is that sampling of the training data set can be introduced

76

References

in t h e function evaluation component improving t h e efficiency of the system without adversely deteriorating its performance. We are currently investigating t h e use of sampling. Preliminary results with t h e same problem domain showed t h a t t h e efficiency of t h e DLS can b e improved by as much as 13% with 75% sampling without significantly degrading the prediction accuracy of the learned classifiers.

References
4.1 Angeline, P. J. (1995): Adaptive and self-adaptive evolutionary computations, in: Palaniswami, M., Attikiouzel, Y., Marks, R., Fogel, D., Fukuda, T., Eds., Computational Intelligence: A Dynamic Systems Perspectives, 152-163. (IEEE Press. Piscataway, NJ) 4.2 Angeline, P. J. (1996): Two self-adaptive crossover operations for genetic programming, in: Angeline, p., Kinnear, K., Eds., Advances in Genetic Programming 11, 152-163 (MIT Press. Cambridge, MA) 4.3 Babcock, C. (1994): Parallel processing mines retail data, Computer World, 6 4.4 Back, T. (1992): Self-adaptation in genetic algorithms, in: Varela, F. J., Bourgine, P., Eds, Towards a Practice of Autonomous Systems: Proceedings of the First European Conference on Artificial Life, 263-271. (MIT Press, Cambridge, MA) 4.5 Bala, J., De Jong, K., Huang, J., Vafaei, H., Wechsler, H. (1992): Hybrid learning using genetic algorithms and decision trees for pattern classification, ProIntl. ceedings of 1 4 ~ ~ Joint Conf. on Artificial Intelligence 4.6 Bala, J., De Jong, K., Pachowicz, P. (1994): Multistrategy learning from engineering data by integrating inductive generalization and genetic algorithms, in: Michalski, R., Tecuci, G., Eds., Machine Learning: A Multistrategy Approach Volume IV (Morgan Kaufmann, San Francisco) 4.7 Battiti, R. (1994): Using mutual information for selecting features in supervised neural net learning, IEEE Transactions on Neural Networks. 5, 537-550 4.8 Bond, A., Gasser, L. (1988):Readings in distributed artificial intelligence, (Morgan Kaufmann) 4.9 Bradley, P. S., Mangasarian, 0. L., Street, W. N. (1998): Feature selection in mathematical programming. INFORMS Journal on Computing. 10 4.10 Breiman, L., Friedman, J., Olshen, R., Stone, C. (1994): Classification and regression trees. (Wadsworth, Belmont, California) 4.11 Chellapilla, K., Fogel, D. B. (1997): Exploring self-adaptive methods to improve the efficiency of generating approximate solutions to travelling salesman problems using evolutionary programming, in: Angeline, P. J., Reynolds, R. G., McDonnell, J. R., Eberhart, R., Eds., Evolutionary Programming VI, (Springer) 4.12 Cover, T . M. (1974): The best two independent measurements are not the two best, IEEE Transactions on Systems, Man, and Cybernetics, 4, 116-117 4.13 Dasarathy, B. (1991): Nearest neighbor (NN) norms: NN pattern classification techniques. IEEE Computer Society Press (Los Alamitos, CA) 4.14 Dzeroski, S. (1996): Inductive logic programming and knowledge discovery in databases, Advances in Knowledge Discovery and Data Mining, 117-152, (AAAI Press, Menlo Park, CA) 4.15 Elashoff, J. D., Elashoff, R. M., Goldman, G. E. (1967): On the choice of variables in classification problems with dichotomous variables, Biometrika, 54, 668-670

References

77

4.16 Elder, J., Pregibon, D. (1996):A statistical perspective on knowledge discovery in databases, Advances in Knowledge Discovery and Data Mining, 83-113, (AAAI Press, Menlo Park, CA) 4.17 Elomaa, T., Ukkonen, E. (1994): A geometric approach to feature selection, Proceedings of the European Conference on Machine Learning, 351-354 4.18 Fogel, D. B., Fogel, L. J., Atmar, J. W. (1991): Meta-evolutionary programming, in: Chen, R. R., Ed., Proceedings of 2sth Asilomar Conference on Signals, Systems, and Computers 540-545, Pacific Grove, CA 4.19 Friedman, J. (1989): Multivariate adaptive regression splines, Annals of Statistics, 19, 1-141 4.20 Guerra-Salcedo, C., Whitley, D. (1999): Genetic approach to feature selection for ensemble creation, in Proc. of the Genetic and Evolutionary Computation Conference, 236-243 4.21 Huhns, M. N. (1987): Distributed artificial intelligence, Pitman, London 4.22 John, G., Kohavi, R., Pfleger, K. (1994): Irrelevant features and the subset selection problem, Proceedings of the llthInternational Conference on Machine Learning. 121-129. Morgan Kaufmann, San Francisco 4.23 Kolodner, J. (1993): Case-based reasoning, Morgan Kaufmann, San F'rancisco 4.24 Kira, K., Rendell, L. A. (1992): A practical approach to feature selection, Proceedings of the gth International Conference on Machine Learning. 249256. Morgan Kaufmann, San Francisco 4.25 Kittler, J. (1975): Mathematical methods of feature selection in pattern recognition, International Journal of Man-Machine Studies. 7, 609-637 4.26 Koza, J. R. (1994): Genetic programming I1 MIT Press, Cambridge, MA 4.27 Lanzi, P. (1997): Fast feature selection with genetic algorithms: a filter approach, in Proc. of IEEE Intl. Conf. on Evolutionary Computation, 537-540 4.28 Lee, I., Sikora, R., Shaw, M. (1995): A genetic algorithm based approach to flexible flow-line scheduling with variable lot sizes, IEEE Transactions on Systems, Man, and Cybernetics, 27B, 36-54 4.29 Levenick, J. (1991): Inserting introns improves genetic algorithm success rate: taking a cue from biology, in: Belew, R., Booker, L., Eds., Proc. of the Fourth Intl. Conf. on Genetic Algorithms, 123-127 (Morgan Kaufmann, San Mateo, CA 4.30 Nordin, P., Francone, F., Banzhaf, W. (1996): Explicitly defined introns and destructive crossover in genetic programming, in: P. Angeline and K. Kinnear, Eds., Advances in Genetic Programming: Volume 2, 111-134, MIT Press, Cambridge, MA 4.31 Opitz, D. (1999): An evolutionary approach to feature set selection, in Proc. of the Genetic and Evolutionary Computation Conference, 803 4.32 Pearl, J. (1988): Probabilistic reasoning in intelligent systems, Morgan Kaufmann, San Francisco 4.33 Prodomidis, A. L., Chan, P. K., Stolfo, S. J. (2000): Meta-learning in distributed data mining systems: issues and approaches, in Advances in Distributed and Parallel Knowledge Discovery, Kargupta, H., Chan, P. (Eds), AAAI Press, 81-113 4.34 Provost, F. (2000): Distributed data mining: scaling up and beyond, in Advances in Distributed and Parallel Knowledge Discovery, Kargupta, H. and Chan, P. (Eds), AAAI Press, 3-27 4.35 Provost, F., Kolluri, V. (1999): A survey of methods for scaling up inductive algorithms, Data Mining and Knowledge Discovery, 2, 131-169 4.36 Punch, W., Goodman, E., Pei, M., Chia-Shun, L., Hovland, P., Enbody, R. (1993): Further research on feature selection and classification using genetic algorithms, in: S. Forrest, Ed., Proceedings of the 5th International Conference on Genetic Algorithms, 557-564, Morgan Kaufmann

78

References

4.37 Quinlan, J. (1992): C4.5: Programs for machine learning, Morgan Kaufmann, San Francisco 4.38 Raymer, M., Punch, W., Goodman, E., Sanschagrin, Kuhn, L. (1997): Simultaneous feature scaling and selection using a genetic algorithm, in Proc. of the 7th Intl. Conf. On Genetic Algorithms, 561-567 4.39 Schwefel, H. P. (1981): Numerical optimization of computer models, Wiley, Chichester 4.40 Sikora, R. (1992): Learning control strategies for a chemical process: a distributed approach, IEEE Expert, 35-43 4.41 Sikora R., Shaw, M. (1994):. A double-layered learning approach to acquiring rules for classification: integrating genetic algorithms with similarity-based learning, ORSA Journal on Computing, 6, 174187 4.42 Sikora, R., Piramuthu, S. (1996): An intelligent fault diagnosis system for robotic machines, International Journal of Computational Intelligence and Organizations, 1, 144153 4.43 Smith, R. G., Davis, R. (1981): Frameworks for cooperation in distributed problem solving, IEEE Transactions on Systems, Man, and Cybernetics. SMC11, 61-70 4.44 Toussaint, G. T. (1971): Note on optimal selection of independent binaryvalued features for pattern recognition, IEEE Transactions on Information Theory, 17, 618 4.45 Turney, P., (1997): How to shift bias: lessons from the baldwin effect, Evolutionary Computation, 4, 271-295 4.46 Vafaie, H., De Jong, K. (1994): Improving a rule induction system using genetic algorithms, in: Michalski, R., Tecuci, G., Eds., Machine Learning: A Multistartegy Approach Volume IV, Morgan Kaufmann, San Francisco 4.47 Whittaker, J. (1990): Graphical models in applied multivariate statistics, Wiley, NY 4.48 Yang, J., Honavar, V. (1998): Feature subset selection using a genetic algorithm, IEEE Intelligent Systems, 13, 4449

5. A Rule Extraction System with Class-Dependent Features
Xiuju Ful and Lipo Wang2 Institute of High Performance Computing, Science Park 2, 117528,Singapore fuxjOihpc.a-star.edu.sg School of Electrical and Electronic Engineering, Nanyang Technological University (NTU), Nanyang Avenue, Singapore 639798. elpwang@ntu.edu.sg http: //www.ntu.edu.sg/home/elpwang

Abstract: In the context of rule extraction, irrelevant or redundant features in data sets often impede the rule extraction computational efficiency and detrimentally affect the accuracy of rules. Data dimensionality reduction is desirable as a preprocessing procedure for rule extraction. We propose a rule extraction system for extracting rules based on class-dependent features which is selected by genetic algorithms (GAS). The major parts of the rule extraction system are: (1) class-dependent feature selection, (2) RBF neural network classifiers with class-dependent features, (3) rule extraction. The objectives of this chapter are: (1) to identify the essential characteristics of our proposed rule extraction system (2) to study the various choices in a data preprocessing procedure and (3) to explore the concept of class-dependent feature selection. In this chapter, first, we overview rule extraction systems from the view point of its components. Then we propose a decompositional rule extraction method based on RBF neural networks. In the proposed rule extraction method, rules are extracted from trained RBF neural networks with classdependent features. GA is used to determine the feature subsets corresponding to different classes. Rules are extracted from trained RBF neural networks by a gradient descent method.

5.1 Overview
5.1.1 Rule Extraction Systems

Huge amounts of data have been stored in documents or in hard disks of computers. Data mining i5.33, 5.371 is very useful in economic and scientific domains. Knowledge discovery from databases (KDD) techniques are used to reveal critical information hidden in data sets. As one of important tasks in KDD, rule extraction has attracted much attention in recent years. The goal of a rule extraction system is to obtain insights for numerical data sets, and further describe and visualize the concepts of data. Generally, a rule extraction system shown in Fig. 5.1 includes the follow components:

80

Fu and Wang

1. Data collection Data are collected in various domains, such as in aerospace, banking and finance, retail and marketing, etc. Valuable information is hidden in huge volumes of data, which calls for intelligent and efficient techniques for discovering knowledge in order to make better decisions, improve profits, save resources, and reduce labor costs. 2. Data preprocessing Diverse data formats and data objects are stored in data repositories. Many variables (attributes) are collected for the purpose to illustrate the concept of objects. However, not all attributes are necessary for analyzing data, i.e., some irrelevant or unimportant data may be included into data sets. In order to remove irrelevant information which may interfere the data analysis process, data dimensionality reduction (DDR) is widely explored for both memory constraint and speed limitation. Hence, the follow preprocessing for data is needed. - Feature selection: Much research work [5.23, 5.25,5.26] has been carried out in choosing a feature subset to represent the concept of data with the removal of irrelevant and redundant features. - Normalization: Text inputs have to transformed into numerical ones. For neural networks, input values are usually normalized between [0,1]. 3. The selection of rule extraction tools Decision trees, neural networks, and genetic algorithms, etc., are often used as tools for rule extraction. - Neural networks: Since neural networks are excellent at predicting, learning from experiences, and generalizing from previous examples, many researchers focus on applying neural networks in the area of rule extraction [5.17, 5.27, 5.43, 5.451. However, a disadvantage of neural networks is that it is difficult to determine neural network architectures and train parameters. Explaining the operation of a trained network is also difficult. - Decision trees: Decision trees [5.12, 5.491 can form concise rules in contrast to neural networks. However, the accuracy of decision trees is often lower than neural networks for noisy data and it is difficult for decision trees to tackle dynamic data. Decision trees can work together with neural networks for the rule extraction task. Zhao [5.51] constructed a decision tree with each node being an expert neural network for obtaining the advantages of both the decision tree and the neural network. Tsang et a1 [5.48] and Umano et a1 [5.49] combined neural networks with decision trees to obtain better performance in rule extraction. - GA: Due to its ability to search globally for the optimal solution to a problem, GA has often been combined with neural networks in rule extraction tasks. Fukumi and Akarnatsu [5.9] used GA to prune the connections in neural networks before extracting rules. Hruschka and

5. A Rule Extraction System

81

Ebecken [5.14]proposed clustering genetic algorithm (CGA) to cluster the activation values of the hidden units of a trained neural network. Rules were then extracted based on the results from CGA. Ishibuchi et a1 [5.15]-[5.18]used GA to obtain concise rules by selecting important members from the rules obtained from a neural network. 4. Expression of the extracted rules Usually, the rules are in IF-THEN forms. The premise parts of rules are composed of different combinations of inputs. There are 3 kinds of rule decision boundaries: - hyper-rectangular - hyper-plane - hyper-ellipse They are shown in Fig. 5.2-5.4. The hyper-rectangular boundary is the simplest. However, since the distributions of data may be different for different problems, different decision boundaries or combinations of different boundaries may be required (see Fig. 5.5) for different problems. Finding the most efficient decision boundary type will be one of future tasks. By rule extraction techniques, people can learn what neural networks have generalized from data sets and how neural network models predict and estimate, which is useful in breaking the black-box curse of neural networks. Neural networks can be applied more widely in diverse rule extraction techniques.
5.1.2 Categories of Rule Extraction Systems

Many methods have been proposed for rule extraction. These rule extraction systems can be characterized by:
1. Form of allowed inputs: continuous, discrete, or both continuous and discrete variables. 2. Form of extracted rule decision boundaries: hyper-rectangular, hyperplane, hyper-ellipse 3. Approach for searching rules: pedagogical and decompositional approaches [5.42]

There are quite a few of methods dealing with discrete variables [5.42, 5.461 or continuous variables [5.45, 5.471. Only a few of methods deal with both continuous and discrete variables [5.7, 5.31. Some rule extraction methods extract rules with hyper-plane decision boundaries [5.13, 5.91, and some with hyper-rectangular rule decision boundaries 15.3, 5.16, 5.271. Rules with hyper-ellipse decision boundaries can be obtained from RBF-based rule extraction methods directly, however, the complexity of extracted rules makes it unpopular.

82

Fu and Wang

Fig. 5.1. A rule extraction system

The pedagogical algorithms consider a neural network to be a black box and use only the activation value of input and output units in the neural network when extracting rules through a neural network. In contrast, the decompositional algorithms consider each unit in a neural network and unify them into the rules corresponding to the neural network. Compared with the former algorithms, the later ones can utilize each hidden unit of neural networks, and can obtain detail rules [5.44]. 5.1.3 Data Dimensionality Reduction In many application areas, knowledge is discovered from large databases using data mining methods. With static rule extraction methods, in most cases, it is evident that the accuracy of extracted rules is better and the size of data can be reduced to save the computation burden if fewer features are selected. And DDR procedure may reduce the number of features that need to be collected.

5. A Rule Extraction System

83

Fig. 5.2. Hyper-rectangular decision boundary

Fig. 5.3. Hyper-plane decision boundary

Fu and Wang

4

I
Fig. 5.4. Hyper-ellipse decision boundary
A

I
Fig. 5.5. Decision boundaries of mixed types

5 . A Rule Extraction System

85

Feature extraction and feature selection. DDR is to map high-dimensional patterns onto lower-dimensional patterns. Techniques for DDR may be classified into two categories: feature extraction and feature selection. Feature extraction creates a number of new features through a transformation of the raw features. Linear Discriminant Analysis (LDA) [5.23, 5.25, 5.261 and Principal Components Analysis (PCA) [5.21] are two popular techniques for feature extraction. Though the transformations are designed to maintain concepts in the data, it is difficult to prevent by-products from affecting detrimentally the original concepts in the data. Feature selection techniques select the best subset of features out of the original set. Feature selection is desirable since it does not generate new features or unwanted by-products. The attributes which are important to maintain the concepts in the original data are selected from the entire attribute set. How to determine the importance level of attributes is the key to feature selection techniques. Mutual-information-based feature selection (MIFS) [5.25, 5.11 is a common method of feature selection, in which "the information content" of each attribute (feature) is evaluated with regard to class labels and other attributes. By calculating mutual information, the importance level of features are ranked based on their ability to maximizing the evaluation formula. However, in MIFS, the number of features to be selected need to be pre-defined. Filter and wrapper approaches. In feature selection algorithms, there are two basic categories. The first is the filter approach [5.5, 5.501 which sieves a suitable feature subset based on a fitness criterion, such as the inconsistency between the feature subset with class labels. The second is the wrapper approach [5.19,5.31,5.32,5.38]. In the wrapper approach, feature selection is wrapped in the induction algorithm. The feature subset is selected during the reasoning process of an induction algorithm. In [5.32],the importance factor of each input feature of a multi-layer perceptron (MLP) neural network is determined by the weighted connections between the input and the second layer of the MLP during training. The features with importance factors below a certain level are eliminated. The difference of the two algorithms lies in whether or not the feature selection is carried out independently of induction algorithms. Sometimes, the filter approach can not efficiently remove the irrelevant features because it totally ignores the effect of the selected feature subset on the performance of induction algorithms. The wrapper approach can be time consuming especially for those induction algorithms that are computationally intensive, such as neural networks. [5.50] combines the filter and the wrapper approaches to reduce time complexity and improve classification accuracy. Class-independent and class-dependent feature selection. With the consideration that a feature has its own expertise for discriminating different classes, feature selection may be classified into class-dependent feature selection and class-independent feature selection. In data mining applications,

