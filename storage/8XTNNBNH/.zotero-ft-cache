Computers in Biology and Medicine 37 (2007) 1334 – 1341 www.intl.elsevierhealth.com/journals/cobm

Grading of renal cell carcinoma by 3D morphological analysis of cell nuclei
Hyun-Ju Choi a , Heung-Kook Choi b,∗
a BK21 Medical Science Education Center, School of Medicine, Pusan National University, Pusan, Republic of Korea b School of Computer Engineering, Inje University, Gimhae, Republic of Korea

Received 8 June 2006; received in revised form 10 December 2006; accepted 13 December 2006

Abstract This study attempted to develop a method for 3D visualization and quantitative analysis of cell nuclei for renal cell carcinoma (RCC) grading and evaluated the feasibility of such quantitative analysis. We compared the correct classiﬁcation rate (CCR) for each of the classiﬁers based on the 2D features of cell nuclei (diameter, area, perimeter, and circularity) and the 3D features of cell nuclei (volume, surface area, and spherical shape factor). The results showed that the classiﬁer using the 3D features provided better results for grading. Our method could overcome the limitations inherent in 2D analysis and could improve the accuracy and reproducibility of quantiﬁcation of cell nuclei. 2007 Elsevier Ltd. All rights reserved.
Keywords: Renal cell carcinoma; Nuclear grading system; Confocal laser scanning microscopy; 3D visualization; 3D quantitative analysis; 3D feature extraction

1. Introduction Renal cell carcinoma (RCC) grading began in the United States in 1932. Since then, Fuhrman grading system has been widely accepted and most commonly used, which is regarded to be strongly associated with prognosis and survival [1–4]. However, conventional visual analysis for grading has low reproducibility as it is based on subjective evaluation, which is prone to inter- and intra-observer variation [5]. Although many attempts were made to overcome this limitation of qualitative evaluation by using computer-assisted microscopic analysis of Feulgen stained nuclei [6–8], it is glean to ﬁnd the objective and reproducible virtual methods nuclear and nucleolar parameters based on three-dimensional (3D) analysis. Most of these studies used two-dimensional (2D) images of thin tissue sections that contained only partial cell nuclei, owing to the truncation of nuclei during the sectioning process; this makes highly accurate quantiﬁcation difﬁcult. Cutting can lead to inaccurate quantiﬁcation, as determining the size or diameter of a nucleus depends on the angle of physical sectioning relative to the position of the nucleus. For example, if a nucleus with an ellipsoidal shape is positioned horizontally in the section,
∗ Corresponding author. Tel.: +82 55 320 3437; fax: +82 55 322 3107.

E-mail address: cschk@inje.ac.kr (H.-K. Choi). 0010-4825/$ - see front matter 2007 Elsevier Ltd. All rights reserved. doi:10.1016/j.compbiomed.2006.12.008

the surface area observed for the nucleus may be quite large, whereas if it is positioned vertically, the area viewed in the section may be relatively small. Thus, a feature analysis based on 2D images cannot give accurate results. Such complications can be overcome by using confocal laser scanning microscopy (CLSM) to obtain a series of consecutive 2D optical slices without physical sectioning. From the volumetric data obtained from CLSM, we can construct a 3D visualization, and quantify 3D features. Several studies have investigated how to obtain more objective results using CLSM. Lockett et al. [9] used interactive algorithms for the segmentation of nuclei in 3D images, and applied them to confocal images of nuclei inside thick tissue sections. Jeroen et al. [10] proposed an intuitive, contour-based, segmentation algorithm. Adiga et al. [11,12] presented region-based techniques, in particular seeded volume growing, for segmentation of volumetric histopathological images and applied an active contour model for segmentation of 3D histopathological images. However, most of these studies focused on the segmentation of cell nuclei in volumetric images of a thick tissue specimen. Although 3D visualization and analysis of computed tomography, as well as magnetic resonance and ultrasound images, are generally used for medical diagnosis [13–15], use of these methods to analyze histopathological images is infrequent. There are also few appropriate tools for analyzing volumetric histopathological images. In addition, although all of the studies conﬁrmed

H.-J. Choi, H.-K. Choi / Computers in Biology and Medicine 37 (2007) 1334 – 1341

1335

that there is prognostic merit in RCC grading, there is no clear answer about which grading system is better or worse in a 2D analysis. A new nuclear RCC grading system based on the 3D features of a cell nucleus could reduce this problem, allowing us to develop a standard for 3D cell nuclei features. 2. Materials and methods 2.1. Specimen preparation and image acquisition Eight cases of RCC were obtained from the Department of Pathology, Yonsei University College of Medicine. They had been ﬁxed in 10% neutral-buffered formalin and embedded in parafﬁn before receipt. The tissues were cut into 20- m sections, stained with propidium iodide (PI) containing RNase A (ﬁnal concentration, 0.5 mg/mL), and mounted in a ﬂuorescent mounting medium (DAKO, Carpinteria, California, USA). The RCC tissues were imaged with a TCS SP2 AOBS confocal imaging system (Leica Microsystems Ltd., Mannheim, Germany) equipped for Leica Dmire2 (Leica Microsystems Ltd., Mannheim, Germany), a 63×, 1.4 NA HEX PL-Apochromat objective lens (Leica Microsystems Ltd., Mannheim, Germany), and a HeNe laser. We acquired a series of 2D optical sections, 0.4 m apart, starting above the top surface of the section and extending down to the bottom surface. There were a total of 50 slices for each volume data, and each slice was a 24-bit/pixel image with a size of 512 × 512 pixels. 2.2. Segmentation of cell nuclei Thresholding is a simple and frequently used method of image segmentation, based on histogram characteristics of the image’s pixel intensities. However, it is difﬁcult and tedious to determine different thresholds manually to segment volumetric data with a series of consecutive 2D images. To obtain the optimal threshold for each image automatically, we used Otsu’s method [16] and Pun’s method [17,18] for automatic threshold selection. We tested the two methods on the images. Almost all the gray level values fell in the ﬁrst quarter of the histogram. There was a slight difference in the results when using Otsu’s and Pun’s methods. Both of them successfully separated objects and background. The thresholding values in Pun’s method were lower than those in Otsu’s method in all the tested images. By using visual inspection, we used Pun’s method to segment cell nuclei. To evaluate segmentation quality after initial segmentation, we used arithmetic and logic operations. We used an AND masking operation to isolate an area for processing. This highlights the area and differentiates it from the rest of the image. Subtraction between the two images results in a new image whose pixel at coordinate (x, y) is the difference between the pixels in that same location. We applied the AND operation to the original and the segmented cell nuclei image. We subtracted the result image of the AND operation from the original image, and tested on the images. Since white pixels in the resulting image could be interpreted

Fig. 1. The procedure used to connect discontinuous cell nuclei.

as an error, we calculated the percentage of the difference using the formula: Error rate [%] = Total number of white pixels × 100, Total number of image pixels

where the total number of image pixels is the image size (width × height). The mean error rate was less than 5%. After initial segmentation, we need a post-processing step to correct and remove any incorrectly segmented nuclei. We must consider two problems at this stage: fragmentation of a cell nucleus makes it difﬁcult to recognize it as one cell nucleus; and touching cell nuclei might be processed as one cell nucleus, even if there are two or more cell nuclei involved. These problems can lead to inaccurate quantitative analysis. To connect a discontinuous cell nucleus, we ﬁrst reduced the cell nucleus to lines a single pixel wide, using a thinning operation. After the thinning operation, we used a hit-or-miss transform to ﬁnd endpoints, which we deﬁned as object pixels with, at most, one object pixel among the neighboring pixels [19]. Then, we made a matrix containing information about the position and label of each endpoint. Based on this matrix, we computed the Euclidean distance between the endpoints. If the distance was less than a threshold chosen by visual inspection, we drew a line between the two endpoints. Finally, we obtained a connected cell nucleus. Fig. 1 shows the results of the connection step. We used the Watershed algorithm to separate touching cell nuclei. This method is very useful in many problem areas of image segmentation. We applied the watershed algorithm in the following way: after the initial segmentation, we performed several morphological operations. We did a distance transform on the objects. A distance transform assigns a value representing distance to the image background. We applied a watershed segmentation to the inverse results of the distance transform. We built a dam based on Vincent and Soille’s immersion principle and drew the watershed line corresponding to the dam [20]. Fig. 2 shows the results of the separation step.

1336

H.-J. Choi, H.-K. Choi / Computers in Biology and Medicine 37 (2007) 1334 – 1341

extracted contours, and surface approximation. First, to extract contours from a segmented binary image, a Laplacian of Gaussian (LoG) operator was used to detect the overall boundary. Second, the smoothing algorithms proposed by Ryu et al. [22] were used to reﬁne the contour data because of the irregularity of chord length within a contour and the topological inconsistency between contours. As smoothing in the horizontal direction requires resampling the new contour data with the unit chord length from the initial contour, we deﬁned the unit chord length and performed the resampling process until all chord lengths converged on the unit chord length. To smooth in the vertical direction, we removed wiggles that could be estimated by the degree of change in the discrete curvature using the Laplacian smoothing algorithm [23]. Third, the Lofting algorithm was used to skin surfaces.
Fig. 2. The procedure used to separate touching cell nuclei.

2.4. 3D labeling Connected-component labeling is a preprocessing step and is typically performed before the quantitative analysis. In this study, we used a new 3D labeling method based on slice information [24]. After applying a 2D connected-component labeling algorithm to each slice by using a contour-tracing technique [25], we used the labeled information to detect objects in the next slice that might belong to the same object. For example, if there was an object common to the kth and (k + 1)th image slices, we compared the center pixels of each object to determine if the objects were connected. If they were connected, we assigned the same label to both. If a common object existed in consecutive slices but the center pixels were unconnected owing to holes in each object, we compared the remaining regions of the object, omitting the center pixels, to determine whether they were connected. If the two objects were connected, we assigned the same label; if the two objects were not connected, we assigned a different label to the objects in the (k + 1)th image.
Fig. 3. Image segmentation by the watershed algorithm: (a) ﬂuorescence-strained cell nuclei; (b) the resulting image after initial segmentation; (c) over-segmented objects and (d) the result after removing spurious watershed lines.

2.5. 3D feature measurements Feature extraction is a crucial step in most cytometry studies; it deﬁnes what is to be measured and how the measurements will take place. Features selected for measurement should agree with a pathologist’s view of what an important feature is. Most RCC grading systems are based on morphonuclear criteria, such as nuclear size and shape. Variations in nuclear size and shape can be important diagnostic factors, which can be expressed and quantiﬁed by morphometric features. The following parameters deﬁne the characteristics of a cell nucleus in three dimensions [26,27]: Volume: This is determined by the total number of voxels in the nucleus. The number of voxels multiplied by the size of a voxel gives the size of a cell nucleus in standard units. Surface area: The area of a 3D cell nucleus can be approximated by the number of voxels belonging to the nucleus that have at least one neighboring background voxel. However, to ﬁnd all the surface voxels, the relationships between voxels must be recomputed using the connectivity operation. We used

However, when we applied watershed segmentation to an entire image, it led to over-segmentation. Fig. 3(c) shows how some objects in the image were divided into several parts. This over-segmentation could be reduced by merging small objects with neighboring objects [21], but it is difﬁcult and complicated to make a rule for selecting which objects to merge. Therefore, watershed lines consisting of objects less than 5 pixels long or more than 30 pixels long were deleted from the watershed image. An AND operation was applied to the resulting image and the segmented cell nuclei image. The result, after removing many other spurious watershed lines, can be seen in Fig. 3(d). 2.3. Surface rendering We used a contour-based surface rendering method consisting of three steps: contour data extraction, smoothing of the

H.-J. Choi, H.-K. Choi / Computers in Biology and Medicine 37 (2007) 1334 – 1341

1337

Fig. 5. Comparison of cell nuclei in section images and cell nuclei in three-dimensions.

Fig. 4. Results of the three-dimensional visualization: surface-rendering image for cell nuclei of Grade 1 (a), Grade 2 (b), Grade 3 (c), and Grade 4 (d).

Nevertheless, in three dimensions, we saw that an identical cell nucleus had an irregular shape and a different size (see Fig. 5). 3.2. Results of data analysis We performed a data analysis to analyze extracted 3D nuclear features and evaluate the signiﬁcance. The total tested data set consisted of 238 cell nuclei. The number of cell nuclei for each grade was 52, 54, 61, and 71, respectively. A pathologist selected the tested data as representative samples of cell nuclei for each grade. In order to compare features of cell nuclei measured in three-dimensions (volume, surface area, and spherical shape factor) with features of cell nuclei measured in two-dimensions (diameter, area, perimeter, and circularity) for identical cell nuclei, we projected section images for each volume into x, y plane and used the projected images for extracting 2D feature measurements. To evaluate what quantitative features of 3D analysis could contribute to diagnostic information and how it could increase the accuracy of nuclear grading, we analyzed the statistical difference of 3D features among the grades. We used an analysis of variance (ANOVA) to determine the levels of statistical signiﬁcance in the differences in distribution across the grades. For each test, we found the F-value as a result of the ANOVA. The F-value is the ratio of a between-group sum of squares (between-group variability) to a within-group sum of squares (within-group variability). Optimal features will have a high between-group variability compared to within-group variability. This means that the best feature will have the largest Fvalue. We found that volume is the best feature in grading. The results of ANOVA for each feature are shown in Table 1. We compared the 3D features of cell nuclei for each grade. Table 2 shows the measurement data for nuclear volume, surface area, and spherical shape factor in each case. The mean volume and mean surface area of cell nuclei of the highest grade were greater than those of the lowest grade cell nuclei. We observed an increase in volume and surface area according to the grade progression. The mean spherical shape factor of the lowest grade cell nuclei is greater than that of the highestgrade cell nuclei, indicating that lower-grade cell nuclei are closer to a spherical shape than are higher-grade cell nuclei, as the spherical shape factor becomes 1 for a perfect sphere. Based on the minimum error rate classiﬁcation of Bayesian decision theory, we created two classiﬁers using the 2D features of cell nuclei (diameter, area, perimeter, and circularity)

Heron’s formula as an alternate way to measure surface area, calculating the area of a triangle directly in terms of the lengths of the three sides, since the rendered surfaces consist of triangles in computer graphics. After calculating each of the triangle areas, we obtained the total surface area using the sum of all triangle areas. S= s(s − a)(s − b)(s − c),

where a, b, c are the lengths of the sides of a triangle and s = (a + b + c)/2. Spherical shape factor: This represents how similar the shape of the cell nucleus is to a sphere. If A is the surface area of the nucleus and V is the volume of the nucleus, then the spherical shape factor is deﬁned as 36 · · V 2 /A3 . 3. Results We implemented the proposed methods using Microsoft Visual C++ (Redmond, Washington, USA) and Open GL (Mountain View, California, USA) and tested them with human RCC tissue stack images. The total tested image data included 20 volume data obtained from eight RCC tissue slides. The number of volume data for each grade was 5, respectively. A pathologist classiﬁed all volume data. For each volume of data, the total number of slices was 50, and each slice was a 24-bit/pixel image with a size of 512 × 512 pixels. The scanning interval between slices was 0.4 m. 3.1. Results of 3D visualization Fig. 4 shows the results of the surface rendering. Grade 1, shown in Fig. 4(a), is characterized by an ordered pattern of nuclei with a slight variation. In Grade 2, shown in Fig. 4(b), the enlargement of the nuclei is more easily recognizable. In Grade 3, shown in Fig. 4(c), a general impression of disorder dominates. Grade 4, shown in Fig. 4(d), is a case with a more pronounced impression of disorder, often with extreme variations in each of the features described in 3D feature measurements. We conﬁrmed the limitations of 2D analysis in 3D visualization; cell nuclei in the section images were small and circular.

1338

H.-J. Choi, H.-K. Choi / Computers in Biology and Medicine 37 (2007) 1334 – 1341

Table 1 The results of ANOVA for nuclear volume, surface area and spherical shape factor
Source DF Sum of squares 39522658.12 8646352.89 19760885.08 5913874.38 2.3249 2.6618 Mean square 13174219.37 356.54 Error Model Surface area Error Model Spherical shape factor Error 234 0.0113 DF = Degree of freedom; Model = Between sum of squares; Error = Within sum of squares. 234 3 25272.97 0.7749 68.13 < .0001 234 3 36950.23 6586961.69 260.63 < .0001 < .0001 F-value Pr > F

Model Volume

3

Table 2 Measurement data for nuclear volume, surface area and spherical shape factor
Feature Grade Mean ± SD Results of ANOVA for each feature between two grades Two grades Volume ( m3 ) 1 2 3 4 1 2 3 4 1 2 3 4 352.97 ± 68.58 523.39 ± 74.70 641.09 ± 137.57 1377.25 ± 315.71 312.85 ± 49.74 466.30 ± 64.64 572.59 ± 104.31 1056.10 ± 264.93 0.48 ± 0.10 0.33 ± 0.12 0.27 ± 0.11 0.21 ± 0.09 1,2 2,3 3,4 1,4 1,2 2,3 3,4 1,4 1,2 2,3 3,4 1,4 F-value Pr > F < .0001 < .0001 < .0001 < .0001 < .0001 < .0001 < .0001 < .0001 < .0001 0.0073 0.0012 < .0001

149.94 31.33 284.93 528.14 186.58 41.82 179.15 398.13 48.49 7.48 11.05 237.58

Surface area ( m2 )

Spherical shape factor SD = Standard deviation.

Table 3 Confusion matrix for the classiﬁer using the 2D features
Grade 1 2 3 4 Total Grade 1 22 2 0 0 24 Grade 2 4 15 9 0 28 Grade 3 0 10 20 8 38 Grade 4 0 0 1 28 29 Total 26 27 30 36 119 % 85 56 67 78 71

and the 3D features of cell nuclei (volume, surface area, and spherical shape factor) and compared the correct classiﬁcation rate (CCR) for each classiﬁer for a training data set and a test data set. One hundred and nineteen cell nuclei out of the total data set consisted of 238 cell nuclei were used to train classiﬁers and the rest were used to test the classiﬁers. Our comparison reveled that the CCRs were 71% and 77% for the classiﬁer using the 2D and 3D features, respectively. The results showed

that the classiﬁer using the 3D features provided better results for grading in Tables 3 and 4. 4. Discussion and conclusion Many studies report that a nucleus’ size and variation are important features of RCC grading systems [28–30]. Pathologists usually estimate nuclear size from the 2D area of a

H.-J. Choi, H.-K. Choi / Computers in Biology and Medicine 37 (2007) 1334 – 1341
Table 4 Confusion matrix for the classiﬁer using the 3D features
Grade 1 2 3 4 Total Grade 1 22 2 0 0 24 Grade 2 3 16 6 0 25 Grade 3 1 9 24 6 40 Grade 4 0 0 0 30 30 Total 26 27 30 36 119

1339

% 85 59 80 83 77

nuclear proﬁle. However, since cells and nuclei are 3D structures, an estimate of nuclear enlargement and its variation should use 3D nuclear morphometry. Yorukoglu et al. [31] investigated mean nuclear volume (MNV) in RCC to deﬁne a cutoff value that could determine the prognosis. Their results indicate that MNV is slightly greater in a high grade, but the difference was not signiﬁcant. In contrast, Fujikawa et al. [32] reported that MNV correlates with prognosis, grade, and metastases. We also found a statistically signiﬁcant correlation between the nuclear grade and the 3D features of volume, surface area, and spherical shape factor. This disagreement may be owing to differences in histologic area selection or image acquisition. We observed an increase in volume and surface area according to the grade progression. We could easily identify extreme grades because of the marked difference, whereas cell nuclei with intermediate grades exhibited relatively a slight difference between two grades. However, the F-value of each 3D feature between Grade 2 and 3 in Table 2 represents that 3D features are also good features in classifying two grades. This could improve the accuracy of diagnosis. On the whole, a comparison of the sizes of 3D cell nuclei between grades revealed a statistical difference. When we compared the two classiﬁers used to grade renal cell carcinoma, the classiﬁer using the 3D features of cell nuclei resulted in better performance for grading. This indicated that our study showed the future potential that a nuclear grading system based on the 3D features of a cell nucleus might be an ideal grading system. Our connecting step in the post processing of an initial segmentation can overcome the problem caused by fragmentation of a cell nucleus. In addition, pathologists can avoid the problem of cell nuclei that are touching, using our modiﬁed watershed segmentation method, by removing spurious watershed lines. However, some problems remain. Our method requires human intervention for interactive correction. The deleted spurious watershed lines were determined empirically. The variations in the choice of them depend on the choice of test image. Therefore, it is necessary to test the robustness and variation of the proposed values by using images from the same ﬁeld of view, captured with different magniﬁcation, varying focus and illumination. However, we did not acquire images at different magniﬁcation and evaluate the robustness of them. In particular, a study should be designed to separate the touching cell nuclei in the z-direction.

Compared with the conventional 3D labeling algorithm, our method has advantages; memory use is efﬁcient, and it is possible to combine a variety of 2D labeling algorithms to ﬁnd appropriate labeling. Also, a labeling algorithm based on contour tracking does not require re-labeling throughout the entire process, as is required by other algorithms. We found a statistically signiﬁcant correlation between nuclear grade and 3D morphological features. However, morphometric characteristics of cell nuclei are not the only way to describe nuclear appearance. Chromatin pattern can also play a signiﬁcant part in RCC grading [33]. Researchers can quantify a chromatic pattern by texture analysis, using co-occurrence matrix or run length matrix calculations [34,35]. Therefore, it is necessary to develop a method for 3D texture analysis of cell nuclei. As Goldstein [36] states, an ideal grading system for RCC can be easily and reproducibly applied by pathologists, accounting for the grade heterogeneity of RCC. Our nuclear grading system, based on the 3D features of a cell nucleus, provides distinct dividing points between grades and provides data that are easily interpreted for diagnosis. A 3D visualization of cell nuclei offers a realistic display and provides additional valuable medical information that can lead to an objective diagnosis. However, we will need to apply additional research to a great number of cell nuclei in order to validate our results. 5. Summary Conventional visual analysis for grading renal cell carcinoma (RCC) has low reproducibility as it is based on subjective evaluation, which is prone to inter- and intra-observer variation. Although many studies have tried computerized image analyses for overcoming this problem, two-dimensional (2D) image analysis of thin tissue sections that contain partial cell nuclei also makes highly accurate quantiﬁcation difﬁcult. This study has attempted to develop a method for 3D visualization and quantitative analysis of cell nuclei for RCC grading and evaluated the feasibility of such quantitative analysis. First, we acquired volumetric RCC data for each grade (Grade1,2,3 and 4) using confocal laser scanning microscopy and used Pun’s method to segment cell nuclei. Second, to determine quantitative features, we used a 3D labeling method based on slice information. After applying the labeling algorithm, we determined the measurements of cell nuclei using 3D quantitative analysis.

1340

H.-J. Choi, H.-K. Choi / Computers in Biology and Medicine 37 (2007) 1334 – 1341 [13] G. Sundaramoorthy, J.D. Hoford, E.A. Hoffman, W.E. Higgins, Impromptu: a system for automatic 3D medical image analysis, Comput. Med. Imaging Graph. 19 (1) (1995) 131–143. [14] B. Diallo, F. Dolidon, J.M. Travere, B. Mazoyer, VoxeLine: a software program for 3D real time visualization of bilmedical images, Comput. Med. Imaging Graph. 22 (1998) 275–289. [15] D.R. Holmes, B.J. Davis, C.J. Bruce, R.A. Robb, 3D visualization, analysis, and treatment of the prostate using trans-urethral ultrasound, Comput. Med. Imaging Graph. 27 (2003) 339–349. [16] N. Otsu, A threshold selection method from gray level histograms, IEEE Trans. Syst. Man. Cybern. 9 (1) (1979) 62–69. [17] T. Pun, A new method for gray level picture thresholding using the entropy of the histogram, Signal Process. 2 (1980) 223–237. [18] T. Pun, Entropic thresholding: a new approach, Comput. Graph. Image Process. 16 (1981) 210–239. [19] P. Soille, Morphological Image Analysis, Springer, New York, 1999 pp. 130–135.. [20] L. Vincent, P. Soille, Watersheds in digital spaces: an efﬁcient algorithm based on immersion simulations, IEEE Trans. Anal. Mach. Intell. 13 (6) (1991) 583–597. [21] C. Wahlby, J. Lindblad, E. Bengtsson, L. Bjorkesten, Algorithms for cytoplasm segmentation of ﬂuorescence labeled cells, Anal. Cell. Pathol. 24 (2002) 101–111. [22] J.H. Ryu, H.S. Kim, K.H. Lee, Contour-based algorithms for generating 3D CAD models form medical images, Int. J. Adv. Manuf. Technol. 24 (2004) 112–119. [23] W. Schroeder, H. Martin, B. Lorensen, Visualization Toolkit: An Object-oriented Approach to 3D Graphics, Prentice-Hall, NJ, 1998 pp. 388–390. [24] I.H. Choi, H.J. Choi, B.I. Lee, H.K. Choi, A slice information based labeling algorithm for 3D volume data, J. Korean Inform. Sci. Soc. 31 (2004) 922–928. [25] F. Chang, C.J. Chen, C.J. Lu, A linear time component labeling algorithm using contour tracing technique, Comput. Vis. Image Underst. 93 (2004) 206–220. [26] P.S.U. Adiga, An integrated system for feature evaluation of 3D images of a tissue specimen, Anal. Cell. Pathol. 24 (2002) 47–58. [27] K. Rodenacker, E. Bengtsson, A feature set for cytometry on digitized microscopic images, Anal. Cell. Pathol. 25 (2003) 1–36. [28] J.L. Gutierrez, J.F. Val-Bernal, M.F. Garijo, L. Buelta, J.A. Portillo, Nuclear morphometry in prognosis of renal adenocarcinoma, Urology 39 (1992) 130–134. [29] M.A. Carducci, S. Piantadosi, C.R. Pound, J.I. Epstein, J.W. Simon, F.F. Marshall, A.W. Partin, Nuclear morphometry adds signiﬁcant prognostic information to stage and grade for renal cell carcinoma, Urology 53 (1) (1999) 44–49. [30] F. Erdogan, A. Demirel, O. Polat, Prognostic signiﬁcance of morphologic parameters in renal cell carcinoma, Int. J. Clin. Pract. 58 (4) (2004) 333–336. [31] K. Yorukoglu, S. Aktas, C. Guler, M. Sade, Z. Kirkali, Volume-weighted mean nuclear volume in renal cell carcinoma, Urology 52 (1) (1998) 44–47. [32] K. Fugikawa, M. Sasaki, T. Aoyama, Role of volume weighted mean nuclear volume for predicting disease outcome in patients with renal cell carcinoma, J. Urol. 157 (1997) 1237–1241. [33] C. Francois, C. Moreno, J. Teitelbaum, G. Bigras, I. Salmon, A. Danguy, G. Brugal, R. Velthoven, R. Kiss, C. Decaestecker, Improving accuracy in the grading of renal cell carcinoma by combining the quantitative description of chromatin pattern with the quantitative determination of cell kinetic parameters, Cytometry 42 (2000) 18–26. [34] R.M. Haralick, T. Shanmugan, I. Dinstein, Texture features for image classiﬁcation, IEEE Trans. Syst. Man. Cybern. 3 (1973) 610–621. [35] K. Yogesan, Texture analysis as a prognostic and diagnostic tool in tumor pathology, Ph.D Thesis, Oslo University, Oslo, Norway, 1995. [36] N.S. Goldstein, The current state of renal cell carcinoma grading, Cancer 80 (1997) 977–980.

To evaluate which of the quantitative features provided by 3D analysis could increase accuracy in nuclear grading, we analyzed statistical differences in 3D features among the grades. We compared the correct classiﬁcation rate (CCR) for each of the classiﬁers based on the 2D features of cell nuclei (diameter, area, perimeter, and circularity) and the 3D features of cell nuclei (volume, surface area, and spherical shape factor). For 3D visualization, we used a contour-based method for surface rendering. We found a statistically signiﬁcant correlation between the nuclear grade and the 3D morphological features. Our comparison revealed that the CCRs were 71.42% and 76.60% for the classiﬁer using the 2D and 3D features, respectively. The results showed that the classiﬁer using the 3D features provided better results for grading. 3D visualization of cell nuclei offered a realistic display and additional valuable medical information that can lead to an objective diagnosis. Our method could overcome the limitations inherent in 2D analysis and could improve the accuracy and reproducibility of quantiﬁcation of cell nuclei.

References
[1] J.R. Hand, A. Broders, Carcinoma of kidney: the degree of malignancy in relation to factors bearing on prognosis, J. Urol. 28 (1932) 199–216. [2] D.G. Skinner, R.B. Colvin, C.D. Vermillion, R.C. Pﬁser, W.F. Leadbetter, Diagnosis and management of renal cell carcinoma: a clinical and pathological study of 309 cases, Cancer 28 (1971) 1165–1177. [3] P. Hermanek, A. Sigel, S. Chlepas, Histological grading of renal cell carcinoma, Eur. Urol. 2 (1976) 189–191. [4] S.A. Fuhrman, L.C. Lasky, C. Limas, Prognosis signiﬁcance of morphologic parameters in renal cell carcinoma, Am. J. Surg. Pathol. 6 (1982) 655–663. [5] D. Lanigan, R. Conroy, W.C. Barry, B. Loftus, D. Royston, M. Leader, A comparative analysis of grading system in renal adenocarcinoma, Histopathol. 24 (1994) 473–476. [6] C. Francois, C. Decaestecker, M. Petein, et al., Classiﬁcation strategies for the grading of renal cell carcinoma, based on nuclear morphometry and densitometry, J. Pathol. 183 (1997) 141–150. [7] H.K. Choi, T. Jarkrans, E. Bengtsson, J. Vasko, K. Wester, P.U. Malmstrom, C. Busch, Image analysis based grading of bladder carcinoma; comparison of object, texture and graph based methods and their reproducibility, Anal. Cell. Pathol. 15 (1997) 1–18. [8] C. Francois, C. Decaestecker, O.D. Lathouwer, C. Moreno, A. Peltier, T. Roumeguere, A. Danguy, J.L. Pasteels, E. Wespes, I. Salmon, R.V. Velthoven, R. Kiss, Improving the prognostic value of histopathological grading and clinical staging in renal cell carcinomas by means of computer assisted microscopy, J. Pathol. 187 (1999) 313–320. [9] S.J. Lockett, D. Sudar, C.T. Thompson, D. Pinkel, J.W. Gray, Efﬁcient, interactive, and three-dimensional segmentation of cell nuclei in thick tissue sections, Cytometry 31 (1998) 275–286. [10] A.B.M. Jeroen, A.M.H. Hielke, T. Paulos, S.P. Lennert, M.P. Neal, P.A.B. Jan, J. Paul, Confocal DNA cytometry: a contourbased segmentation algorithm for automated three-dimensional image segmentation, Cytometry 49 (2002) 12–21. [11] P.S.U. Adiga, B.B. Chaudhuri, Region based techniques for segmentation of volumetric histopathological images, Comput. Meth. Programs Biomed. 61 (2000) 23–47. [12] P.S.U. Adiga, Segmentation of volumetric tissue images using constrained active contour models, Comput. Meth. Programs Biomed. 71 (2003) 91–104.

H.-J. Choi, H.-K. Choi / Computers in Biology and Medicine 37 (2007) 1334 – 1341 Hyun-Ju Choi is currently working at the School of Medicine, Pusan National University, Korea, as a Research Professor. She received her Ph.D. in Computer Science, Inje University, Korea in 2005. Her research interest is computerized two- and three-dimensional image analysis using cells and tissues in vivo as well as in vitro.

1341

Heung-Kook Choi, Ph.D., is an Associate Professor at the School of Computer Engineering, Inje University, Korea. He received both B.S. and M.S. degree in Computer Engineering at Linkoping University, Sweden in 1988 and 1990, respectively. His Ph.D. degree received in Computerized Image Analysis at Uppsala University, Sweden in 1996. His interesting researches are in computer graphics and medical image analysis.

