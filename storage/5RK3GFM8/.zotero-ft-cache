AUTOMATED RECOGNITION OF MITOTIC PATTERNS IN FLUORESCENCE MICROSCOPY IMAGES OF HUMAN CELLS N. Harder1 , B. Neumann2 , M. Held2 , U. Liebel2 , H. Erﬂe2 , J. Ellenberg2, R. Eils1, and K. Rohr1 University of Heidelberg, IPMB, and DKFZ Heidelberg, Dept. Bioinformatics and Functional Genomics, Biomedical Computer Vision Group, Im Neuenheimer Feld 364, 69120 Heidelberg, Germany 1, European Molecular Biology Laboratory (EMBL), Gene Expression and Cell Biology/ Biophysics Programmes, Meyerhofstrasse 1, 69117 Heidelberg, Germany 2
ABSTRACT High-throughput screens of the gene function provide rapidly increasing amounts of data. In particular, the analysis of image data acquired in genome-wide cell phenotype screens constitutes a substantial bottleneck in the evaluation process and motivates the development of automated image analysis tools for large-scale experiments. Here we introduce a computational scheme to process multi-cell images as they are produced in high-throughput screens. We describe an approach to automatically segment and classify cell nuclei into different mitotic phenotypes. This enables automated identiﬁcation of cell cultures that show an abnormal mitotic behavior. Our scheme proves a high classiﬁcation accuracy, suggesting a promising future for automating the evaluation of high-throughput experiments. 1. INTRODUCTION The technology of RNA interference (RNAi) is an effective method to identify the biological function of genes in the ﬁeld of functional genomics. Together with the availability of complete genome sequences from several organisms, RNAi enables genome-wide high-throughput screening of gene function [1]. In high-throughput RNAi screens all known genes of the observed organism are systematically silenced one after the other by inhibiting their expression and then the resulting morphological changes are analyzed. However, such large-scale knockdown experiments produce huge amounts of image data that require tools for automated evaluation. Automated image analysis usually comprises segmentation, feature extraction, as well as classiﬁcation of structures of interest in the images. Previous work on automated analysis of cell images has been published in different ﬁelds of application. Based on ﬂuorescence microscopy complete cells as well as single subcellular structures have been studied. Classiﬁcation of complete cells has been performed, for example, to investigate the inﬂuence of drugs on cellular proteins [2]. There, cells are classiﬁed based on morphological characteristics of the plasma membrane that depend on the level of protein activation. Another application of complete cell classiﬁcation has been considered in [3], where the detection of mitotic cells in images from automated microscope systems has been studied. Furthermore, work has been done on automated recognition of subcellular structures, which is a major task in location proteomics (e.g., [4, 5, 6]). In this ﬁeld, the subcellular location of proteins is investigated in order to understand their function. Automated analysis of cell images also plays an increasing role in cytopathology, where computational methods have been developed to segment and classify different cell types in brightﬁeld microscopy images of cell smears for early cancer detection [7]. In this contribution, we present a fully automated approach to analyze multi-cell images from large-scale RNAi screens. In comparison to previous work we analyze cell array images that include a large number of cell nuclei in different mitotic stages. We classify the nuclei into four different phases of the cell life cycle. This enables an evaluation of the mitotic behavior of the considered cell culture over time. Our automated image analysis work ﬂow comprises three steps: (1) Segmentation of multi-cell images, (2) image feature extraction, and (3) classiﬁcation. In order to ﬁnd the most appropriate algorithm for fast and accurate segmentation, we compared three different thresholding techniques according to their segmentation quality and computation time. Our approach allows to minimize the manual evaluation effort, that still slows down such large-scale experiments considerably. Furthermore, the results of an automated evaluation are objective and reproducible. Our approach has been tested using real multi-cell images from high-throughput screens in the framework of the EU project MitoCheck. This project aims to elucidate the coordination of mitotic processes in human cells at a molecular level. The goal is to obtain a better understanding of the mechanisms of cancer development. To identify the genes that are involved in cell division, genome-wide RNAi screens are performed. The effect of a silenced gene on mitosis is studied based on ﬂuorescence microscopy time-lapse images of the treated cell culture. An automated evaluation of the

0-7803-9577-8/06/$20.00 ©2006 IEEE

1016

ISBI 2006

Authorized licensed use limited to: ASTAR. Downloaded on December 15, 2008 at 04:34 from IEEE Xplore. Restrictions apply.

Algorithm Time (sec)

GLOBAL

ADAPT-1

ADAPT-2

0.0875

60.1281

0.1812

Table 1. Average time consumption on AMD Opteron processor (1.8 GHz) for one image (1344 ×1024 pixels ×12 bit). that only for regions that contain a certain amount of information (e.g., a boundary between object and background) the local threshold is calculated which reduces the computation time. Global as well as local grey value thresholds are automatically calculated using Otsu’s threshold selection method. In the ﬁrst version of the algorithm (ADAPT-1) we apply the grey value threshold only to the central pixel of the sliding window and shift the window one pixel per step, what leads to a high segmentation accuracy of 98.0%. As here the sliding windows are heavily overlapping and the variance calculation has to be carried out for each pixel of the image, the computation time is rather high. In the second version of the algorithm (ADAPT-2), the threshold is applied to every pixel of the sliding window and the window is shifted one window width per step. Thus, the single windows do not overlap and the number of variance and local threshold calculations is decreased enormously. In our tests this strategy reduced the computation time by a factor of 330 and still yielded 92.1% correctly segmented nuclei. The loss in segmentation accuracy is due to artefacts that occur because the thresholds change abruptly at the borders of the non-overlapping region windows. Cell nuclei of all classes are affected to the same extent by this effect. The absolute time consumption of each algorithm on an AMD Opteron processor machine with 1.8 GHz is given in Table 1. Here, we used a window width in accordance with the average nucleus diameter (e.g. 30 pixels). Since the speed of the segmentation algorithm is a major criterion in our application and an accuracy of 92.1% in this context is acceptable, we chose to adopt the second version. After image segmentation an object labeling step is performed, holes within objects are ﬁlled, and bounding boxes are calculated. 3. FEATURE EXTRACTION AND CLASSIFICATION OF MITOTIC PATTERNS For analyzing the mitotic behavior of a cell culture, the number of cells in the different stages of the cell life cycle per image frame is an important information. For example, an increased number of dying cells, or an accumulation of mitotic cells give indications that mitosis is affected. To obtain this information we automatically classify each single cell per image frame. 3.1. Feature extraction To derive a quantitative description of single cell images as input for a classiﬁer, a set of robust image features has to be extracted. In our approach we adopt a large feature set

Fig. 1. Multi-cell image from a high-throughput experiment. resulting images requires classiﬁcation and quantiﬁcation of different mitotic patterns. In the following sections, we ﬁrst describe our segmentation algorithm that is based on adaptive thresholding. Then we detail the feature extraction and the classiﬁcation step (Section 3). Experimental results are presented in Section 4. 2. SEGMENTATION OF MULTI-CELL IMAGES The high-throughput screening images in our application typically contain multiple cells (see Figure 1). Consequently, segmentation and labeling of single objects is a crucial step. Various advanced segmentation algorithms have been described in the literature, but as computation time plays an important role when dealing with huge amounts of data, segmentation accuracy as well as speed of the algorithm are decisive criteria. We investigated three different thresholding techniques and evaluated the segmentation accuracy by manually counting correctly and incorrectly segmented cells. This manual evaluation has been performed for each tested algorithm for four different images that included in total 761 cell nuclei. The ﬁrst technique (GLOBAL) is a global thresholding scheme, where the threshold is automatically calculated using Otsu’s threshold selection method [8]. However, a global threshold did not yield satisfying results, even after applying background correction, due to overlapping grey value intervals of background and objects. The evaluation of the segmentation accuracy resulted in only 55.9% correctly segmented cell nuclei. Note, that in all experiments we set the threshold for the minimum contrast of considered cells to about 2% of the maximum grey value of the image. The second and the third technique are two versions of an adaptive thresholding algorithm. This algorithm uses a quadratic sliding window to calculate local thresholds for different regions of an image. A local threshold is only calculated if the variance within the window reaches a user-deﬁned threshold, else a global threshold is used [9]. This ensures

1017
Authorized licensed use limited to: ASTAR. Downloaded on December 15, 2008 at 04:34 from IEEE Xplore. Restrictions apply.

Feature type Granularity Object-related Edge-related Tree-structured wavelets Haralick texture Gray scale invariants Zernike moments

Number 21 8 3 2 260 10 49

Classes Interphase Mitosis Apoptosis Shape Total

Training set 258 88 48 116 510

Test set 64 22 12 29 127

Total 322 110 60 145 637

Table 3. Numbers of samples per class and set sizes. the EU project MitoCheck at the European Molecular Biology Laboratory (EMBL) Heidelberg. Chromosome morphology is visualized using a HeLa (Kyoto) cell line stably expressing the chromosomal marker histone 2B-EGFP. In one image there are about 200-400 nuclei with an average diameter of approximately 30 pixels. All images have a grey value depth of 12 bit and a resolution of 1344 ×1024 pixels. An example image can be seen in Figure 1. A representative set of single cell nuclei from different images taken from different experiments has been manually classiﬁed by biologists at EMBL. The objects have been assigned to four classes: (1) nuclei in the growing and resting phase (interphase), (2) mitotic nuclei (mitosis), (3) nuclei performing programmed cell death (apoptosis), and (4) a class which covers cases of clustered nuclei (shape). Figure 2 shows example images for each class. The total number of manually classiﬁed cell objects is 637 and the number of objects per class is given in Table 3. 4.2. Classiﬁcation results We tested our approach using the above described manually classiﬁed image data. The cell nuclei were extracted automatically from the multi-cell images using the segmentation approach described above. For each of the 637 cell images the 353 features mentioned in Sect. 3.1 were extracted. We split the available samples for each class randomly in training data and test data at the ratio of 4:1, resulting in a training set size of 510 and a test set size of 127. Table 3 shows the number of training and testing samples per class. For the training set we standardized each feature to a mean value of zero and a standard deviation of one. In the test set, the feature values were linearly transformed based on the transformation parameters from the training set. Then we trained a SVM classiﬁer with a RBF kernel based on the training data set as described above. The samples of the test set were classiﬁed into the four classes interphase, mitosis, apoptosis and shape (Figure 2). An evaluation of the classiﬁcation result yielded an overall classiﬁcation accuracy of 96.9%. Thereby, 123 out of the 127 test set samples were correctly classiﬁed. Since our test set was relatively large, the result obtained from this classiﬁcation can already be considered to be signiﬁcant. In order to check the reliability of the result we repeated the classiﬁcation step, applying a ten-fold outer crossvalidation on the whole data set of 637 images. This clas-

Table 2. Feature types and numbers of extracted features.

Interphase

Mitosis

Apoptosis

Shape

Fig. 2. Example images representing the four classes. previously used for the classiﬁcation of subcellular phenotypes [6] and apply it to cell nuclei from multi-cell array images. The feature set includes granularity features, object- and edge-related features, tree-structured wavelet features, Haralick texture features, grey scale invariants, and Zernike moments. A list of the number of features per type is given in Table 2. In total we compute 353 features per cell object. 3.2. Classiﬁcation In previous work different classiﬁers have been used for the classiﬁcation of cellular and subcellular patterns. The most common methods are Support Vector Machines (SVM) (e.g. [6, 10]), Artiﬁcial Neural Networks (ANN) (e.g. [4, 5]), and Bayesian classiﬁers (e.g. [2, 7]). In our work we use SVMs with a Radial Basis Function (RBF) as kernel function. SVMs are mathematically wellfounded and their complexity is independent of the dimension in feature space compared to other classiﬁcation methods. This striking property allows us to work with a high number of features and we can skip the feature selection step as it is no longer crucial. We solve the multi-class classiﬁcation problem with a “one-against-one” approach. For k classes this methods constructs k(k-1)/2 binary classiﬁers and trains each one with data from two classes. To optimize the penalty parameter C and the kernel parameter γ for the Radial Basis Function, we perform a three-fold cross-validation with varying values of C and γ on the training set (model selection) prior to the actual training of the classiﬁer. 4. EXPERIMENTAL RESULTS 4.1. Image data In our study we use images that have been acquired using a wide-ﬁeld microscopy screening system in the framework of

1018
Authorized licensed use limited to: ASTAR. Downloaded on December 15, 2008 at 04:34 from IEEE Xplore. Restrictions apply.

True Class Interphase Mitosis Apoptosis Shape

Interph. 100 0 0 0

Classiﬁer Output Mitosis Apoptos. 0 0 91 9 17 83 0 0

Shape 0 0 0 100

is the application of feature selection methods to determine those features with the highest discriminative power. 6. REFERENCES [1] A. Friedman and N. Perriman, “Genome-wide highthroughput screens in functional genomics,” Current Oppinion in Genetics & Development, vol. 14, pp. 470– 476, 2004. [2] J. Lindblad, C. Waehlby, E. Bengtsson, and A. Zaltsman, “Image analysis for automatic segmentation of cytoplasms and classiﬁcation of rac1 activation,” Cytometry Part A, vol. 57A, pp. 22–33, 2003. [3] G. Gallardo, F. Yang, F. Ianzini, M. Mackey, and M. Sonka, “Mitotic cell recognition with hidden markov models,” in Medical Imaging 2004: Visualization, Image-Guided Procedures, and Display, Proc SPIE (J. R L Galloway, ed.), vol. 5367, pp. 661–668, 2004. [4] M. Boland and R. Murphy, “A neural network classiﬁer capable of recognizing the patterns of all major subcellular structures in ﬂuorescence microscope images of hela cells,” Bioinformatics, vol. 17, no. 12, pp. 1213– 1223, 2001. [5] A. Danckaert, E. Gonzalez-Couto, L. Bollondi, N. Thompson, and B. Hayes, “Automated recognition of intracellular organelles in confocal microscope images,” Trafﬁc, vol. 3, pp. 66–73, 2002. [6] C. Conrad, H. Erﬂe, P. Warnat, N. Daigle, T. Lörch, J. Ellenberg, R. Pepperkok, and R. Eils, “Automatic identiﬁcation of subcellular phenotypes on human cell arrays,” Genome Research, vol. 14, pp. 1130–1136, 2004. [7] T. Wuerﬂinger, J. Stockhausen, D. Meyer-Ebrecht, and A. Boecking, “Robust automatic coregistration, segmentation, and classiﬁcation of cell nuclei in multimodal cytopathological microscopic images,” Computerized Medical Imaging and Graphics, vol. 28, pp. 87– 98, 2004. [8] N. Otsu, “A threshold selection method from grey level histograms,” IEEE Transactions on Systems, Man and Cybernetics, vol. 9, pp. 62–66, 1979. [9] R. Gonzalez and R. Woods, Digital Image Processing. Prentice Hall, 2nd ed., January 2002. [10] K. Huang and R. Murphy, “Automated classiﬁcation of subcellular patterns in multicell images without segmentation into single cells,” in Proc IEEE Internat Symposium on Biomedical Imaging: From Nano to Macro (ISBI ’04), pp. 1139–1142, 2004.

Table 4. Confusion matrix; 510 training and 127 test samples; overall accuracy: 96.9%. Classiﬁer Output Mitosis Apoptos. 0.31 0 90.91 9.09 20.00 78.33 0 0

True Class Interphase Mitosis Apoptosis Shape

Interph. 99.38 0 1.67 0

Shape 0.31 0 0 100

Table 5. Averaged confusion matrix; ten-fold cross validation on 637 samples; average accuracy: 96.0%. siﬁcation yielded an average accuracy of 96.0%. Thus, both classiﬁcation results correspond very well and we can draw the conclusion that we can rely on an overall classiﬁcation accuracy of around 96%. We also determined the confusion matrices for both classiﬁcation experiments and as can be seen from Tables 4 and 5, misclassiﬁcations appeared mainly between the classes mitosis and apoptosis. The reason for this misclassiﬁcation is illustrated by Figure 3: some samples from these two classes are nearly indistinguishable even for a human observer. The lower classiﬁcation accuracy of the apoptosis class can be ascribed to the comparatively small number of 60 samples in this class (see Table 3). 5. CONCLUSION We have introduced an approach for automated recognition of mitotic patterns which can handle multi-cell images and classiﬁes the segmented cell nuclei with a high accuracy into four classes. The approach enables fast and reliable automatic analysis of large-scale high-throughput RNAi screens. Since certain mitotic patterns are hard to distinguish based on single images, exploitation of temporal information by tracking of nuclei throughout image sequences, is one possibility to further improve the classiﬁcation performance. Another issue

Mitosis

Apoptosis

Fig. 3. Very similar image examples of the classes mitosis and apoptosis based on manual classiﬁcation by a biologist.

1019
Authorized licensed use limited to: ASTAR. Downloaded on December 15, 2008 at 04:34 from IEEE Xplore. Restrictions apply.

