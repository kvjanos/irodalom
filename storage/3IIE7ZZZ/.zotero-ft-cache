International Journal of Computer Vision 48(3), 215–231, 2002 c 2002 Kluwer Academic Publishers. Manufactured in The Netherlands.

Hamilton-Jacobi Skeletons
KALEEM SIDDIQI AND SYLVAIN BOUIX School of Computer Science & Center for Intelligent Machines, McGill University, Montreal, QC H3A 2A7, Canada
siddiqi@cim.mcgill.ca sbouix@cim.mcgill.ca

ALLEN TANNENBAUM Department of Electrical & Computer Engineering and Department of Biomedical Engineering, Georgia Institute of Technology, Atlanta, GA 30082-0250, USA
tannenba@ece.gatech.edu

STEVEN W. ZUCKER Departments of Computer Science and Electrical Engineering and Center for Computational Vision & Control, Yale University, New Haven, CT 06520-8285, USA
zucker-steven@cs.yale.edu

Received June 30, 2000; Revised August 8, 2001; Accepted November 29, 2001

Abstract. The eikonal equation and variants of it are of signiﬁcant interest for problems in computer vision and image processing. It is the basis for continuous versions of mathematical morphology, stereo, shape-from-shading and for recent dynamic theories of shape. Its numerical simulation can be delicate, owing to the formation of singularities in the evolving front and is typically based on level set methods. However, there are more classical approaches rooted in Hamiltonian physics which have yet to be widely used by the computer vision community. In this paper we review the Hamiltonian formulation, which offers speciﬁc advantages when it comes to the detection of singularities or shocks. We specialize to the case of Blum’s grassﬁre ﬂow and measure the average outward ﬂux of the vector ﬁeld that underlies the Hamiltonian system. This measure has very different limiting behaviors depending upon whether the region over which it is computed shrinks to a singular point or a non-singular one. Hence, it is an effective way to distinguish between these two cases. We combine the ﬂux measurement with a homotopy preserving thinning process applied in a discrete lattice. This leads to a robust and accurate algorithm for computing skeletons in 2D as well as 3D, which has low computational complexity. We illustrate the approach with several computational examples. Keywords: eikonal equation, Hamiltonian systems, ﬂux and divergence, 2D and 3D skeletons, shape analysis

1.

Introduction

Variational principles have emerged naturally from considerations of energy minimization in mechanics (Lanczos, 1986). We consider these in the context of

the eikonal equation, which arises in geometrical optics and has become of great interest for problems in computer vision (Bruss, 1989; Kimia et al., 1994). It is the basis for continuous versions of mathematical morphology (Brockett and Maragos, 1992; Sapiro et al.,

216

Siddiqi et al.

1992; van den Boomgaard and Smeulders, 1994), as well as for Blum’s grassﬁre transform (Blum, 1973) and dynamic theories of shape representation (Kimia et al., 1995; Tari et al., 1997). It has also been used for applications in image processing and analysis (Sethian, 1996a; Caselles et al., 1998), shape-fromshading (Horn and Brooks, 1989; Rouy and Tourin, 1992; Oliensis and Dupuis, 1994; Kimmel et al., 1995b) and stereo (Faugeras and Keriven, 1998). As is well known, some care must be taken with the numerical simulation of this equation, since it is a hyperbolic partial differential equation for which a smooth initial front may develop singularities or shocks as it propagates. At such points, classical concepts such as the normal to a curve and its curvature are not deﬁned. Nevertheless, it is precisely these points that are important for the above applications in computer vision since, e.g., it is they which denote the skeleton (see Fig. 3.) To continue the evolution while preserving shocks, the technology of level set methods introduced by Osher and Sethian (1988) has proved to be extremely powerful. The approach relies on the notion of a weak solution, developed in viscosity theory (Crandall et al., 1992), and the introduction of an appropriate entropy condition to select it. The representation of the evolving front as a level set of a hypersurface allows topological changes to be handled in a natural way and robust, efﬁcient implementations have recently been developed (Sethian, 1996b). As pointed out by Osher and Sethian (1988), level set methods are Eulerian in nature because computations are restricted to grid points whose locations are ﬁxed. For such methods, the question of computing the locus of shocks for dynamically changing systems remains of crucial importance, i.e., the methods are shock preserving but do not explicitly detect shocks. Shock detection methods which rely on interpolation of the underlying hypersurface are computationally very expensive. Numerical thresholds are introduced, and high order accurate numerical schemes must be used (Osher and Shu, 1991; Siddiqi et al., 1997). On the other hand, there are more classical methods rooted in Hamiltonian physics, which can also be used to study shock theory. Although such formulations have been applied to computer vision problems (Horn and Brooks, 1989; Rouy and Tourin, 1992; Oliensis and Dupuis, 1994), the numerical methods have yet to be widely used. In this paper we review the Hamiltonian formalism for simulating the eikonal

equation which offers a number of conceptual advantages when it comes to shock tracking. Hamiltonian systems are fundamental in classical physics and have a natural physical interpretation based on elementary Hamiltonian and Lagrangian mechanics. The existence of such simple differential equations is also relevant to considering whether these models have any possible biological implementations (Miller and Zucker, 1999). We specialize to the case of Blum’s grassﬁre ﬂow (Blum, 1973) and compute a measure of the average outward ﬂux of the vector ﬁeld underlying the Hamiltonian system. As the region over which this ﬂux is computed shrinks to a point, the measure can be shown to have very different limiting behaviors depending upon whether or not that point is singular. Thus, it is a very effective way of distinguishing between medial and non-medial points. We combine the average outward ﬂux measure with a homotopy preserving thinning process applied in a discrete lattice. This leads to a robust and efﬁcient algorithm for computing skeletons in 2D as well as 3D which has low computational complexity. We illustrate the method with a number of examples of medial axes (2D) and medial surfaces (3D) of synthetic objects as well as complex anatomical structures obtained from medical images. To the best of our knowledge, the closest work in computer vision is the formulation of Oliensis and Dupuis of the shape-from-shading problem (Oliensis and Dupuis, 1994). Their method also uses HamiltonJacobi theory and has similar robust numerical properties. In particular, a density function for marker particles is propagated to obtain estimates of where particles accumulate. This strategy is used to distinguish sources from sinks in order to reconstruct shape from intensity images. We now review some relevant background on skeletons, followed by a brief overview of skeletonization approaches related to our method. 1.1. 2D and 3D Skeletons

The 2D skeleton (medial axis) of a closed set A ⊂ R2 is the locus of centers of maximal open discs contained within the complement of the set (Blum, 1973). An open disc is maximal if there exists no other open disc contained in the complement of A that properly contains the disc. The 3D skeleton (medial surface) of a closed set A ⊂ R3 is deﬁned in an analogous fashion as the locus of centers of maximal open spheres contained

Hamilton-Jacobi Skeletons

217

in the complement of the set. Both types of skeletons have been widely used in bio-medicine for tasks involving object representation (N¨ f et al., 1996; Stetten a and Pizer, 1999), registration (Liu et al., 1998a) and segmentation (Sebastian et al., 1998). They have also been used for graph-based object recognition in computer vision (Ogniewicz, 1993; Zhu and Yuille, 1996; Sharvit et al., 1998; Liu and Geiger, 1999; Siddiqi et al., 1999b), for animating objects in graphics (Teichmann and Teller, 1998; Pizer et al., 2001) and for manipulating them in computer-aided design. Despite their popularity, their numerical computation remains nontrivial. Most algorithms are not stable with respect to small perturbations of the boundary, and heuristic measures for simpliﬁcation are often introduced. Interest in the skeleton as a representation for an object stems from a number of interesting properties: (i) it is a thin set, i.e., it contains no interior points, (ii) it is homotopic to the original shape, (iii) it is invariant under Euclidean transformations of the object (rotations and translations) and (iv) given the radius of the maximal inscribed circle or sphere associated which each skeletal point, the object can be reconstructed exactly. Hence, it provides a compact representation while preserving the object’s genus and making certain useful properties explicit, such as its local width. Approaches to computing skeletons can be broadly organized into three classes. First, methods based on thinning attempt to realize Blum’s grassﬁre formulation (Blum, 1973) by peeling away layers from an object while retaining special points (Arcelli and Sanniti di Baja, 1985; Lee and Kashyap, 1994; Borgefors et al., 1999; Manzanera et al., 1999). It is possible to deﬁne erosion rules in a lattice such that the topology of the object is preserved. However, these methods are quite sensitive to Euclidean transformations of the data and typically fail to localize skeletal points accurately. As a consequence, only a coarse approximation to the object is usually reconstructed (Manzanera et al., 1999; Bertrand, 1995; Lee and Kashyap, 1994). Second, it has been shown that under appropriate smoothness conditions the vertices of the Voronoi diagram of a set of boundary points converges to the exact skeleton as the sampling rate increases (Schmitt, 1989). This property has been exploited to develop skeletonization algorithms in 2D (Ogniewicz, 1993), as well as extensions to 3D (Sheehy et al., 1996; Sherbrooke et al., 1996). The dual of the Voronoi diagram, the Delaunay triangulation (or tetrahedralization in 3D)

has also been used extensively. Here the skeleton is deﬁned as the locus of centers of circumscribed circles of each triangle (spheres of each tetrahedra in 3D) (Goldak et al., 1991; N¨ f et al., 1996). Both types of a methods ensure homotopy between objects and their skeletons and accurately localize skeletal points, provided that the boundary is sampled densely. Unfortunately, the techniques used to prune elements of the Voronoi graph which correspond to small perturbations of the boundary are typically based on heuristics. In practice, the results are not invariant under Euclidean transformations, and the optimization step, particularly in 3D, can have a high computational complexity (N¨ f a et al., 1996). A third class of methods exploits the fact that the locus of skeletal points coincides with the singularities of a Euclidean distance function to the boundary. These approaches attempt to detect local maxima of the distance function, or the corresponding discontinuities in its derivatives (Arcelli and di Baja, 1992; Leymarie and Levine, 1992; Gomez and Faugeras, 2000). The numerical detection of these singularities is itself a non-trivial problem; whereas it may be possible to localize them, ensuring homotopy with the original object is difﬁcult. The are also some recent approaches to computing 2D and 3D skeletons which combine aspects of thinning, Voronoi diagrams and distance functions (Malandain and Fernandez-Vidal, 1998; Zhou et al., 1998; Borgefors et al., 1999; Tek and Kimia, 1999). 1.2. Related Work

We now present a brief overview of selected approaches that are related to the method we develop in this paper. We refrain from an exhaustive review of the large body of work in computer vision and computational geometry on computing 2D and 3D skeletons, since this is beyond the scope of this paper. Leymarie and Levine (1992) have simulated the grassﬁre by utilizing the magnitude of the gradient vector ﬁeld of a signed distance function to attract a snake moving in from the object’s boundary. In this technique the contour has to be ﬁrst segmented at curvature extrema, which is itself a challenging problem. Kimmel et al. (1995a) have also proposed a method where the contour is ﬁrst segmented at locations of positive curvature maxima. Outward distance functions to each segment are then computed and the skeleton is obtained by interpolating the zero level set of

218

Siddiqi et al.

the distance map differences and removing spurious points. Liu et al. (1998b) have introduced a variational approach to computing symmetric axis trees, where portions of a curve are matched against others, incorporating constraints including co-circularity and parallelism. The approach leads to an abstraction that is related to the medial axis but is comprised by a different locus of points. Dynamic programming is used to make the computation efﬁcient. Tek and Kimia (1999) have proposed an approach for calculating symmetry maps, which is based on the combination of a wavefront propagation technique with an exact (analytic) distance function. In this technique the representation must be pruned in order to distinguish salient branches from unwanted ones. Pudney (1998) has introduced a distance ordered homotopy preserving thinning procedure where points are removed in order of their distance from the boundary while anchoring end points and centers of maximal balls identiﬁed from a chamfer distance function. Malandain and Fernandez-Vidal (1998) obtain two sets based on thresholding a function of two heuristic measures, φ and d, to characterize the singularities of the Euclidean distance function. The two sets are combined using a topological reconstruction process. Tari and Shah (1998) have proposed a characterization of the symmetries of n-dimensional shapes by looking at properties of the Hessian of a suitably deﬁned scalar edge-strength functional. Furst and Pizer (1998) have introduced a notion of an optimal parameter height ridge in arbitrary dimension by exploiting a sub-dimensional maximum property. Kalitzin et al. (1998) have considered index computations on vector ﬁelds associated with scalar images in order to identify their singularities. Vector ﬁelds rooted in magnetostatics have also been used for extracting symmetry and edge lines in greyscale images (Cross and Hancock, 1997). 2. The Eikonal Equation

Figure 1. A geometric view of a monotonically advancing front (Eq. (1)). T (x, y) is a graph of the ‘solution’ surface, the level sets of which are the evolved curves.

case F ≤ 0 is also allowed). Let T (x, y) be a graph of the solution surface, obtained by superimposing all the evolved curves in time (see Fig. 1). In other words, T (x, y) is the time at which the curve crosses a point (x, y) in the plane. Referring to the ﬁgure, the speed of the front is given by F(x, y) = d 1 1 1 = = = . h tan(α) d ∇T

Hence, T (x, y) satisﬁes the eikonal equation ∇T F = 1. (2)

We begin by showing the connection between a monotonically advancing front and the well known eikonal equation. Consider the curve evolution equation ∂C = FN , ∂t (1)

where C is the vector of curve coordinates, N is the unit inward normal and F = F(x, y) is the speed of the front at each point in the plane, with F ≥ 0 (the

A number of algorithms have been recently developed to numerically solve this equation, including Sethian’s fast marching method (Sethian, 1996b) which systematically constructs T using only upwind values, Rouy and Tourin’s (1992) viscosity solutions approach and Sussman et al.’s (1994) level set method for incompressible two-phase ﬂows. However, none of these methods address the issue of shock detection explicitly, and more work has to be done to track shocks. A different approach, which is related to the solution surface T (x, y) viewed as a graph, has been proposed by Shah (1996) and Tari et al. (1997). Here the key idea is to use an edge strength functional v in place of the surface T (x, y), computed by a linear diffusion equation. The equation can be efﬁciently implemented, and the framework extends to greyscale images as well as curves with triple point junctions. It provides an approximation to the reaction-diffusion space introduced in Kimia et al. (1995) but does not extend to the extreme cases, i.e., morphological erosion by a disc structuring element (reaction) or motion by curvature (diffusion). Hence, points of maximum (local) curvature of the evolved curves are interpreted as skeletal points. This regularized skeleton is typically not connected,

Hamilton-Jacobi Skeletons

219

and its relation to the classical skeleton, obtained from the eikonal equation with F = 1, is as yet unclear. In the next section, we shall consider an alternate framework for solving the eikonal equation, which is based on the canonical equations of Hamilton. The technique is widely used in classical mechanics and rests on the use of a Legendre transformation (see Arnold (1989) and Shankar (1994)), which takes a system of n second-order differential equations to a mathematically equivalent system of 2n ﬁrst-order differential equations. We believe that the method offers speciﬁc advantages over alternatives for a number of vision problems that involve shock tracking and skeletonization.

The key to the Hamiltonian formalism is to exchange the roles of q and p by replacing the Lagrangian L(q, q) ˙ ˙ with a Hamiltonian H(q, p) such that the velocities now become the derived quantities q= ˙ ∂H . ∂p

This can be done by applying the following Legendre transformation: H(q, p) = p · q − L(q, q) ˙ ˙ (4)

3.

Hamilton’s Canonical Equations and the Hamilton-Jacobi Skeleton Flow

where the q s are written as functions of q’s and p’s. It ˙ is a simple exercise to verify that the above expression for the velocities q then holds. One can also take partial ˙ derivatives of the Hamiltonian with respect to the q’s and verify that ∂H ∂L =− . ∂q ∂q Using Eq. (3), ∂L can be replaced with p to give ˙ ∂q Hamilton’s canonical equations: p=− ˙ ∂H , ∂q q= ˙ ∂H . ∂p (5)

We begin this section with an overview of the Hamiltonian formalism, taken from Arnold (1989) and Shankar (1994). Although this is standard material in classical mechanics, these techniques may be unfamiliar to the general computer vision audience. In a Lagrangian formulation the independent variables are the coordinates q of particles and their velocities q. ˙ For example, in the context of the Eq. (1) these would be the positions of points along the curve C and their associated velocities FN . Each particle follows the path of least action in reaching a future location at a future time. In mathematical terms, the action function minimized, Sq0 ,t0 , is given by Sq0 ,t0 (q, t) = L dt.

γ

Here γ is an extremal curve connecting the points (q0 , t0 ) and (q, t) and L(q, q) is the Lagrangian. In ˙ other words, of all possible paths connecting (q0 , t0 ) and (q, t), the trajectory γ followed by the particle is the one that minimizes the action function. The associated Euler-Lagrange equation is d ∂L ∂L − =0 dt ∂ q ˙ ∂q where the momenta are derived quantities given by p= ∂L . ∂q ˙ (3)

Thus, in the Hamiltonian formalism one starts with the initial positions and momenta (q(0), p(0)) and integrates Eq. (5) to obtain the phase space (q(t), p(t)) of the system. A comparison of the Lagrangian and Hamiltonian formalisms is presented in Table 1. Following Arnold (1989, pp. 248–258), we now use Huygens’ principle to show the connection between the eikonal equation and a Hamilton-Jacobi equation. For every point q0 , deﬁne the function Sq0 (q) as the cost of the path from q0 to q (see Fig. 2). As indicated earlier, the trajectory followed from q0 to q will be the path of least action. The wave front generated at time t is given by {q : Sq0 (q) = t}. The vector p = ∂ S is called the ∂q vector of normal slowness of the front. By Huygens’ principle the direction of the ray q is conjugate to the ˙ direction of motion of the front, i.e., p · q = 1. In an ˙ anisotropic medium the vectors p and q have different ˙ directions in general. Let us specialize to the case of a monotonically advancing front in an inhomogeneous but isotropic medium (Eq. (1)). Here the speed F(x, y) depends only on position (not on direction), and the directions of

220

Siddiqi et al.

Table 1.

A comparison of the Lagrangian and Hamiltonian formalisms, taken from Shankar (1994). The Hamiltonian formalism The state of the system is described by (q, p). The state may be represented by a point in a 2n-dimensional phase space. The 2n coordinates and momenta obey 2n ﬁrst-order equations. For a given H only one trajectory passes through a given point in the phase space.

The Lagrangian formalism The state of the system is described by (q, q). ˙ The state may be represented by a point moving with a velocity in an n-dimensional conﬁguration space. The n coordinates evolve according to n second-order equations. For a given L several trajectories may pass through a given point in the conﬁguration space.

Figure 2. Direction of a ray q and the direction of motion of the ˙ wave front p. From Arnold (1989).

p and q coincide. The Lagrangian associated with the ˙ action function minimized (Eq. (3)) is given by L= 1 1 ∂γ /∂t = q . ˙ F(x, y) F(x, y)

This can be interpreted as a conformal (inﬁnitesimal) length element, and we have assumed that the extremals emanating from the point (q0 , t0 ) do not intersect elsewhere, i.e., they form a central ﬁeld of extremals. For an isotropic medium the extremals turn out to be straight lines, and for the special case F(x, y) = −1 the action function becomes Euclidean length. It can be shown that the vector of normal slowness, p = ∂ S , is not arbitrary but satisﬁes the Hamilton∂q Jacobi equation ∂S ∂S = −H q, , ∂t ∂q (6)

under the equivalent Hamiltonian system given by Eq. (5). This offers a number of advantages, the most signiﬁcant being that the equations become linear and hence trivial to simulate numerically. We shall now derive this system of equations for the special case of a front advancing with speed F(x, y) = 1. This case is of particular interest for shape analysis because the locus of shocks which from coincides with the trace of the Blum skeleton (Blum, 1973; Brockett and Maragos, 1992; Kimia et al., 1995). For the case of a front moving with constant speed, recall that the action function being minimized is Euclidean length and hence S can be viewed as a Euclidean distance function from the initial curve C0 . Furthermore, the magnitude of its gradient, ∇ S , is identical to 1 in its smooth regime, which is precisely where the assumption of a central ﬁeld of extremals is valid. With q = (x, y), p = (Sx , Sy ), p = 1, we associate to the evolving plane curve C ⊂ R2 the surface ˜ C ⊂ R4 given by ˜ C : = (x, y, Sx , Sy ) : (x, y)
2 2 ∈ C, Sx + Sy = 1, p · q = 1 . ˙

The Hamiltonian function obtained by applying the Legendre transformation (Eq. (4)) to the Lagrangian L = − q is given by ˙
2 2 H = p · q − L = 1 + Sx + S y 2 . ˙
1

The associated Hamiltonian system is p=− ˙ ∂H = (0, 0), ∂q q= ˙ ∂H = (Sx , Sy ). ∂p (7) ˜ C can be evolved under this system of equations, with ˜ C(t) ⊂ R4 denoting the resulting (contact) surface. The

where the Hamiltonian function H(q, p) is the Legendre transformation with respect to q of the ˙ Lagrangian discussed earlier (Arnold, 1989). Rather than solve the nonlinear Hamilton-Jacobi equation for the action function S (which will give the solution surface T (x, y) to Eq. (2)), it is much more convenient to look at the evolution of the phase space (q(t), p(t))

Hamilton-Jacobi Skeletons

221

˜ projection of C(t) onto R2 will then give the parallel evolution of C at time t, C(t). We illustrate this ﬂow by representing the initial curve with a sequence of marker particles and then evolving them according to Eq. (7). Further details are presented in Siddiqi et al. (1999a). With q = (x, y), p = (Sx , Sy ) = ∇ S, the system of equations becomes ˙ ˙ ˙ ˙ { Sx = 0, Sy = 0; x = Sx , y = Sy }, a gradient dynamical system. The second equation indicates that the trajectory of the marker particles will be governed by the vector ﬁeld obtained from the gradient of the Euclidean distance function S, and the ﬁrst indicates that this vector ﬁeld does not change with time and can be computed once at the beginning of the simulation. Projecting this 4D system onto the (x, y) plane for each instance of time t will give the evolved curve C(t). The superposition of all the level curves gives the solution surface T (x, y) in Fig. 1. Figure 3 depicts the evolution of marker particles, with speed F = 1, for several different shapes. Whereas a variety of methods can be used to simulate the eikonal equation, including level set techniques

and their fast marching versions (Sethian, 1996b), the Hamiltonian formalism offers the advantage that the computed ﬂow is less sensitive to boundary details. Furthermore, the formation of shocks can be made explicit. As shown in the following section the key idea is to exploit a measure of the average outward ﬂux of the vector ﬁeld q. ˙ 4. Flux and Divergence

We approach the discrimination of medial points, which coincide with the shocks of the grassﬁre ﬂow, from non-medial ones, by computing the average outward ﬂux of the vector ﬁeld q about a point. The average ˙ outward ﬂux is deﬁned as the outward ﬂux through the boundary of a region containing the point, normalized by the length of the boundary
δR

q, N ds ˙ length(δ R)

(8)

Here ds is an element of the bounding contour δ R of the region R and N is the outward normal at each point of the contour. Via the divergence theorem div(q)da ≡ ˙
R

δR

q, N ds, ˙

(9)

where da is an area element. Thus the outward ﬂux is related to the divergence in the following way div(q) ≡ lim ˙
δR

a→0

q, N ds ˙ . a

(10)

Figure 3. The evolution of marker particles under the Hamiltonian system. The initial particles are placed on the boundary and iterations of the process are superimposed. These correspond to level sets of the solution surface T (x, y) in Fig. 1.

The outward ﬂux, or equivalently the integral of the divergence of q, measures the degree to which the ﬂow ˙ generated by q is area preserving for the region over ˙ which it is computed. To elaborate, the outward ﬂux (and hence also the average outward ﬂux) is negative if the area enclosed by the region δ R is shrinking under the action of the Hamiltonian ﬂow, positive if it is growing and zero otherwise. This quantity is clearly strongly dependent on the shape of the region R. However, it can be shown that in the limit as the region δ R shrinks to a non-medial point, the average outward ﬂux approaches zero independent of the shape of R. When considering a region δ R that contains a medial point, unfortunately the standard form of the divergence theorem does not apply since the vector ﬁeld q becomes singular. Instead, the limiting behavior of ˙ the average outward ﬂux as the region δ R shrinks to a

222

Siddiqi et al.

medial point can be considered. Furthermore, it can be shown that there is a constant c R > 0 depending on the shape of the region R such that the average outward ﬂux appoaches a strictly negative number bounded above by c R × q, N , where N is now a one-sided normal ˙ to the medial axis or surface.1 This constant covers all the cases of a regular axis point, a branch point, or an end point. Thus, in the limit as δ R shrinks to a point the average outward ﬂux calculation is an effective way of detecting the singularities of the vector ﬁeld q. Non-medial points give values that are close to zero ˙ and medial points corresponding to strong singularities give large negative values. Whereas thus far we have focused on the case of a (2D) closed curve, the very same analysis applies to a closed (3D) surface evolving according to an eikonal equation. One simply has to replace the initial closed curve C with the closed surface S in Eq. (1), add a third coordinate z to the phase space in Eq. (7) and replace the area element with a volume element and the contour integral with a surface integral in Eqs. (8)–(10). Figure 4 illustrates the average outward ﬂux computation on the silhouette of a panther shape, where values close to zero are shown in medium grey. All computations are carried out on a rectangular lattice, although the bounding curve is shown in interpolated form. Strictly speaking, the average outward ﬂux is desired only in the limit as the region shrinks to a point. However, the average outward ﬂux over a very small neighborhood (a circle in 2D or a sphere in 3D) provides a sufﬁcient approximation to the limiting values. Strong singularities correspond either to high magnitude negative (dark grey) or positive numbers (light grey), depending upon whether the vector ﬁeld is collapsing at or emanating from a particular point. A threshold on the average outward ﬂux yields a close approximation to the skeleton, as used in Siddiqi et al. (1999a).

Figure 5. Thresholding the average outward ﬂux map in Fig. 4. A high threshold yields a connected set, but it is not thin and unwanted branches are present (left). A low threshold yields a closer approximation to the desired medial axis, but the result is now disconnected (right).

However, in general it is impossible to guarantee that the result obtained by simple thresholding is homotopic to the original shape. A high threshold may yield a connected set, but it is not thin and unwanted branches may be present, Fig. 5 (left). A low threshold yields a thin set, but it may be disconnected, Fig. 5 (right). The solution, as we shall now show, is to introduce additional constraints to ensure that the resulting skeleton is homotopic to the shape. The essential idea is to incorporate a homotopy preserving thinning process, where the removal of points is guided by the average outward ﬂux values. In the context of the Hamilton-Jacobi skeleton ﬂow (Eq. (7)), this leads to a robust and efﬁcient algorithm for computing 2D and 3D skeletons. 5. Homotopy Preserving Skeletons

Our goal is to combine the divergence computation with a digital thinning process, such that as many points as possible are removed without altering the object’s topology. In digital topology a point is simple if its removal does not change the topology of the object. In 2D we shall consider rectangular lattices, where a point is a unit square with 8 neighbors, as shown in Fig. 6 (left). Hence, a 2D digital point is simple if its removal does not disconnect the object or create a hole. In 3D we shall consider cubic lattices, where a point is a unit cube with 6 faces, 12 edges and 8 vertices. Hence, a 3D digital point is simple if its removal does not disconnect the object,

Figure 4. The gradient vector ﬁeld of a signed distance function to the boundary of a panther shape (left), with the associated average outward ﬂux (right). Whereas the smooth regime of the vector ﬁeld gives zero ﬂux (medium grey), strong singularities give either large negative values (dark grey) in the interior or large positive values (light grey) in the exterior.

Figure 6. Left: A 3 × 3 neighborhood of a candidate point for removal P. Right: An example neighborhood graph for which P is simple. There is no edge between neighbors 6 and 8 (see text).

Hamilton-Jacobi Skeletons

223

create a hole, or create a cavity (Kong and Rosenfeld, 1989). 5.1. 2D Simple Points

Consider the 3 × 3 neighborhood of a 2D digital point P contained within an object and select those neighbors which are also contained within the object. Construct a neighborhood graph by placing edges between all pairs of neighbors (not including P) that are 4-adjacent or 8-adjacent to one another. If any of the 3-tuples {2, 3, 4}, {4, 5, 6}, {6, 7, 8}, or {8, 1, 2}, are nodes of the graph, remove the corresponding diagonal edges {2, 4}, {4, 6}, {6, 8}, or {8, 2}, respectively. This ensures that there are no degenerate cycles in the neighborhood graph (cycles of length 3). Now, observe that if the removal of P disconnects the object, or introduces a hole, the neighborhood graph will not be connected, or will have a cycle, respectively. Conversely, a connected graph that has no cycles is a tree. Hence, we have a criterion to decide whether or not P is simple: Proposition 1. A 2D digital point P is simple if and only if its 3 × 3 neighborhood graph, with cycles of length 3 removed, is a tree. A straightforward way of determining whether or not a graph is a tree is to check that its Euler characteristic |V | − |E| (the number of vertices minus the number of edges) is identical to 1. This check only has to be performed locally, in the 3 × 3 neighborhood of P. Figure 6 (right) shows an example neighborhood graph for which P can be removed. 5.2. 3D Simple Points

a set of points O is n-connected, if for every pair of points (xi , x j ) ∈ O × O, there is a n-path from xi to x j . Based on these deﬁnitions, Malandain et al. (1993) provide a topological classiﬁcation of a point x in a cubic lattice by computing two numbers: (i) C ∗ : the number of 26-connected components 26-adjacent to ∗ ¯ x in O ∩ N26 and (ii) C: the number of 6-connected ¯ components 6-adjacent to x in O ∩ N18 . An important result with respect to our goal of thinning is the following: Theorem 1 (Malandain et al., 1993). P is simple if ¯ C ∗ (P) = 1 and C(P) = 1. We can now determine whether or not the removal of a point will alter the topology of a digital object. When preserving homotopy is the only concern, simple points can be removed sequentially until no more simple points are left. The resulting set will be thin and homotopic to the object. However, without a further criterion the relationship to the skeleton will be uncertain since the locus of surviving points depends entirely on the order in which the simple points are removed. In the current context, we have derived a natural criterion for ordering the thinning, based on the average outward ﬂux of the gradient vector ﬁeld of the Euclidean distance function.

5.3.

Flux-Ordered Thinning

In 3D a digital point can have three types of neighbors: two points are 6-neighbors if they share a face; two points are 18-neighbors if they share a face or an edge; and two points are 26-neighbors if they share a face, an edge or a vertex. This induces three nconnectivities, where n ∈ {6, 18, 26}, as well as three nneighborhoods for x(Nn (x)). An n-neighborhood with∗ out its central point is deﬁned as Nn = Nn (x) \ {x}. An object A is n-adjacent to an object B, if there exist two points x ∈ A and y ∈ B such that x is an nneighbor of y. A n-path from x1 to xk is a sequence of points x1 , x2 , . . . , xk , such that for all xi , 1 < i ≤ k, xi−1 is n-adjacent to xi . An object represented by

Recall from Section 4, that the average outward ﬂux of the gradient vector ﬁeld of the Euclidean distance function can be used to distinguish non-medial points from medial ones. This quantity tends to zero for the former, but approaches a negative number below a constant times q, N for the latter, where N is the one˙ sided normal to the medial axis or surface. Hence, the average outward ﬂux provides a natural measure of the “strength” of a skeletal point for numerical computations. The essential idea is to order the thinning such that the weakest points are removed ﬁrst and to stop the process when all surviving points are not simple, or have a total average outward ﬂux below some chosen (negative) value, or both. This will accurately localize the skeleton and also ensure homotopy with the original object. Unfortunately the result is not guaranteed to be a thin set, i.e., one without an interior.

224

Siddiqi et al.

One way of satisfying this last constraint is to deﬁne an appropriate notion of an end point. Such a point would correspond to the end point of a curve (in 2D or 3D), or a point on the rim of a surface, in 3D. The thinning process would proceed as before, but the threshold criterion for removal would be applied only to end points. Hence, all surviving points which were not end points would not be simple and the result would be a thin set. In 2D, an end point will be viewed as any point that could be the end of a 4-connected or 8-connected digital curve. It is straightforward to see that such a point may be characterized as follows: Proposition 2. A 2D point P could be an end point of a 1 pixel thick digital curve if, in a 3 × 3 neighborhood, it has a single neighbor, or it has two neighbors, both of which are 4-adjacent to one another. In 3D, the characterization of an end point is more difﬁcult. An end point is either the end of a 26connected curve, or a corner or point on the rim of a 26-connected surface. In R3 , if there exists a plane that passes through a point p such that the intersection of the plane with the object includes an open curve which ends at p, then p is an end point of a 3D curve, or is on the rim or corner of a 3D surface. This criterion can be discretized easily to 26-connected digital objects by examining 9 digital planes in the 26-neighborhood of p as in Pudney (1998). 5.4. The Algorithm and its Complexity

Algorithm 1 The Flux-Ordered Thinning Algorithm. Part I: Average Outward Flux Compute the distance transform of the object D (Borgefors, 1984). Compute the gradient vector ﬁeld ∇ D. Compute the average outward ﬂux of ∇D using Eq. (9) For each point P in the interior of the object n Flux(P) = i=1 < Ni , ∇ D(Pi ) > /n, where Pi is an n-neighbor (n = 8 in 2D, n = 26 in 3D) of P and Ni is the outward normal at Pi of the unit (disc in 2D, sphere in 3D) centered at P. Part II: Homotopy Preserving Thinning For each point P on the boundary of the object if (P is simple) insert (P, Heap) with Flux(P) as the sorting key for insertion While (Heap.size > 0) P = HeapExtractMax(Heap) if (P is simple) if (P is not an end point) or (Flux(P) > Thresh) Remove P for all neighbors Q of P if (Q is simple) insert (Q, Heap) else mark P as a skeletal (end) point end { if } end { if } end { while } We now analyze the complexity of the algorithm. The computation of the distance transform (Borgefors, 1984), the gradient vector ﬁeld and the average outward ﬂux are all O(n) operations. Here n is the total number of points in the array. The implementation of the thinning is more subtle. We claim an O(k log(k)) worst case complexity, where k is the number of points inside the object. The explanation is as follows. At ﬁrst, store only the points that are on the outer layer of the object in a heap, using the average outward ﬂux as the sorting key for insertion. The extraction of the maximum from the heap will provide the best candidate for removal. If this point is removable, then delete it from the object and add its simple (potentially removable) neighbors to the heap. A point can only be inserted a constant number of times (at most 26 times for a 3D, 26-neighborhood and at most 8 times for a 2D, 8-neighborhood) and insertion in a heap, as well as the extraction of the minimum,

The essential idea behind the ﬂux-ordered thinning process is to remove simple points sequentially, ordered by their average outward ﬂux, until a threshold is reached. Subsequently, simple points are removed if they are not end points. The procedure converges when all remaining points are either not simple or are end points. The thinning process can be made very efﬁcient by observing that a point which does not have at least one background point as an immediate neighbor cannot be removed, since this would create a hole or a cavity. Therefore, the only potentially removable points are on the border of the object. Once a border point is removed, only its neighbors may become removable. This suggests the implementation of the thinning process using a heap. A full description of the procedure is given in Algorithm 1.

Hamilton-Jacobi Skeletons are both O(log(l)) operations, where l is the number of elements in the heap. There cannot be more than k elements in the heap, because we only have a total of k points within the object. The worst case complexity for thinning is therefore O(k log(k)). Hence, the worst case complexity of the algorithm is O(n) + O(k log(k)). We should point out that this is a very loose upper bound. The heap only contains points from the object’s surface and therefore in practice the complexity is almost linear in the number of digital points n. 6. 6.1. Examples Medial Axes

225

We ﬁrst present examples of medial axes, computed for a range of 2D binary shapes. The same outward ﬂux threshold was used in each example to determine which end points to preserve. The input is a 2D binary array where the foreground and background are identiﬁed by distinct values. The implementation then uses an exact (signed) distance function to a piecewise circular arc interpolation of the boundary, which allows for subpixel computations (details are presented in Dimitrov et al. (2000)). Figure 7 (left) shows the subpixel medial axis for the panther silhouette with branch points shown as empty circles and end points as closed circles. The accuracy of the representation is illustrated in Fig. 7 (right), where the shape is reconstructed as the envelope of the maximal inscribed discs associated with each medial axis point. Figure 8 depicts subpixel medial axes for a number of other shapes. The results demonstrate the robustness of the framework under Euclidean transformations, as well as changes in scale. 6.2. Medial Surfaces

Figure 8. Subpixel medial axes for a range of shapes, obtained by ﬂux-ordered thinning. The detected end points and branch points are circled.

function (Borgefors, 1984) which provides a good approximation to the true distance function. Once again, the only free parameter is the choice of the outward ﬂux threshold below which the removal of end points is blocked. For these examples, the value was selected so that approximately 25% of the points within the volume had a lower average outward ﬂux. 6.2.1. Accuracy, Stability and Robustness 6.2.1.1. Accuracy. We test the method by using synthetic objects for which the expected structure of the medial surface is known. Figures 9 and 10 illustrate the computation of the ﬂux-based medial surfaces for a cube and a cylinder, respectively. In both cases the computations lead to the structures one would expect when considering the loci of centres of maximal inscribed spheres. Also, the reconstruction from the medial surface and its associated distance function is accurate. 6.2.1.2. Stability. Next we test the sensitivity of the method to boundary perturbations. Figure 11 shows the same cube as earlier, but with points randomly

Next we illustrate the algorithm with both synthetic data and volumetric structures segmented from medical images. For these we used the D-Euclidean distance

Figure 7. Left: A subpixel medial axis, with branch points shown as empty circles and end points as ﬁlled circles. Compare with the results in Fig. 5. Right: The reconstruction as the envelope of the maximal inscribed disks (grey) of the medial axis, overlaid on the original shape.

226

Siddiqi et al.

Figure 9. First column: Three views of a cube. Second column: The corresponding ﬂux-based medial surfaces. Third column: The object reconstructed from the medial surfaces in the previous column.

Figure 11. First row: Three views of the cube in Fig. 9, but with up to 4 voxels in depth removed randomly from the surface. Second row: The resulting medial surface. Third row: Three views of a cube in Fig. 9, but with up to 4 voxels in depth added randomly to the surface. Fourth row: The resulting medial surface.

Figure 10. First column: Three views of a cylinder. Second column: The corresponding ﬂux-based medial surfaces. Third column: The object reconstructed from the medial surfaces in the previous column.

Figure 12. Top row: Three views of the cube in Fig. 9 but with up to 30 voxels in depth randomly removed or added to the surface. Bottom row: The resulting medial surface shows spurious branches and sheets but has a smooth main structure.

removed (top row) or added (bottom row), up to a depth of four voxels. The resulting medial surface is no longer as smooth as before but the irregularities seen in Fig. 11 are not spurious sheets. In fact, using the method described in Section 6.2.2, this particular medial surface is labeled exactly like the surface in

Fig. 13. This illustrates the stability of the method in the presence of moderate boundary noise. The boundary protrusions or indentations have to be signiﬁcant in order for spurious branches or sheets to appear, as illustrated in Fig. 12.

Hamilton-Jacobi Skeletons

227

Figure 13. Top row: The medial surface of the cube in Fig. 9. Bottom row: The cube is rotated by 30 degrees around the z axis and its medial surface is recomputed. The viewing directions are the same for the top and bottom rows. The two medial surfaces have also been automatically segmented into surface points (light grey), junction points and border points (dark grey) using the classiﬁcation of Malandain et al. (1993).

Figure 14. The medial surface of a cylinder is labeled into border points (dark grey), surface points (light grey), curve points (dark grey) and junction points (black).

6.2.1.3. Robustness. Third, we test the robustness of the method under rotation. We rotate the cube by 30 degrees around the z axis and compute its medial surface. Figure 13 compares this result with the medial surface of the original cube. The two outputs are clearly almost identical. 6.2.2. Labeling the Medial Surface. The medial surface can be labeled using the classiﬁcation of Malandain et al. (1993). Speciﬁcally, the numbers C ∗ ¯ and C, described in Section 5, can be used to classify curve points, surface points, border points and junction points. However, junction points can be misclassiﬁed as surface points when certain special conﬁgurations of voxels occur, and these cases have to be dealt with using a new deﬁnition for simple surfaces (Malandain et al., 1993). ¯ Let x be a surface point (C = 2 and C ∗ = 1). Let Bx and C x be the two connected components of ¯ O ∩ N18 6-adjacent to x. Two surface points x and y are in an equivalence relation if there exists a 26path x0 , x1 , . . . , xi , . . . , xn with x0 = x and xn = y such that for i ∈ [0, . . . , n − 1], (Bxi ∩ Bxi+1 = ∅ and C xi ∩ C xi+1 = ∅) or (Bxi ∩ C xi+1 = ∅ and C xi ∩ Bxi+1 = ∅). A simple surface is then deﬁned as any equivalence class of this equivalence relation. We use this deﬁnition in our framework to ﬁnd all the misclassiﬁed junctions. If the 26-neighborhood of a previously classiﬁed surface point x is not a simple surface, then x is a junction point. Figures 13 and 14 illustrate the labeling of the medial surface of a cube and a cylinder. The medial surface of the cylinder is

correctly labeled as having two simple sheets connected by a 3D digital curve through two junction points. The same deﬁnition can be used to extract the individual simple surfaces comprising the medial surface of an object. The idea is to ﬁnd an unmarked surface point on the medial surface and use it as a “source” to build its associated simple surface using a depth ﬁrst search strategy. The next simple surface is built from the next unmarked surface point and so on, until all surface points are marked. 6.2.3. Experiments on MR and MRA Data. We now illustrate the method on volumetric data segmented from medical images. Figure 15 illustrates the results on brain ventricles obtained from a magnetic resonance

Figure 15. First column: Four views of the ventricles of a brain, segmented from volumetric MR data using an active surface. Second column: The corresponding medial surfaces obtained by thresholding the ﬂux map. Third column: The ﬂux-based medial surfaces obtained using the same threshold, but with the incorporation of homotopy preserving thinning. Fourth column: The ventricles reconstructed from the ﬂux-based medial surfaces in the previous column.

228

Siddiqi et al.

(MR) image. The medial surface consists of two main sheets which reﬂect the “butterﬂy-like” structure of the original object. The ﬁgure demonstrates that thresholding the ﬂux (second column) results in erroneous topologies, whereas the full algorithm (third column) computes medial surfaces which are both thin and topologically correct. The ventricles reconstructed from the medial surface in the third column are shown in the fourth column. Next, we illustrate the approach on a (partial) data set of blood vessels obtained from a magnetic resonance angiography (MRA) image of the brain, in Fig. 16. The blood vessels have complex topology with loops (due to pathologies) and are already quite thin in several places. The bottom row illustrates the accuracy of the method, where the medial surfaces are shown embedded within the original data set. Generically these structures are thin sheets which approach 3D curves when the blood vessels become perfectly cylindrical. In a number of medical applications where the objects are tubular structures, an explicit reduction of the medial surface to a set of 3D curves is of interest (Ge et al., 1998; Borgefors et al., 1998, 1999; Zhou et al., 1998). There is a straightforward modiﬁcation of our framework which allows this. The essential idea is to modify the end point criteria such that only end points of 3D curves are preserved. Rim and corner points of sur-

Figure 17. Left column: Blood vessels segmented from volumetric MRA data, with a magniﬁed portion shown in the second row. Middle column: The ﬂux-based 3D curves. Right column: The ﬂux-based 3D curves are shown embedded within the vessel data.

faces are now considered to be removable points during the thinning process, resulting in a medial surface consisting only of 3D curves. This is illustrated for a portion of the vessel data in Fig. 17, which gives three 1 voxel wide 26-connected 3D digital curves. Finally, Fig. 18 illustrates the 3D medial surface of the sulci of a brain. Rather than show the entire surface, which is difﬁcult to visualize, we have shown an X, Y and Z slice through the volume in grey, with the intersection of that slice and the medial surface shown in black. The medial surface is well localized and captures the complex topology of the object’s shape. The computation times for the 3D examples running on a dual

Figure 16. Top row: Blood vessels segmented from volumetric MRA data with magniﬁed portions shown in the middle and right columns. Middle row: The corresponding ﬂux-based medial surfaces. Third row: The ﬂux-based medial surfaces (solid) are shown within the vessel surfaces (transparent).

Figure 18. Top row: Medial surfaces of the sulci of a brain, segmented from an MR image. The three columns represent X, Y and Z slices through the volume, shown in grey. The cross section through the 3D medial surface in each slice is shown in black. Bottom row: A zoom-in on a selected region of the corresponding slice in the top row, to show detail.

Hamilton-Jacobi Skeletons

229

Table 2. Data set Cube Cylinder Ventricles Vessels Sulci

The computation times for the 3D examples, running on a dual processor 550 MHz Pentium III machine. Array size (n) 128 × 128 × 128 128 × 128 × 128 192 × 169 × 99 63 × 151 × 164 192 × 169 × 99 Number of points (k) 120000 26260 30909 14377 798221 DT 26.21 s 26.40 s 39.60 s 14.07 s 38.71 s Div 6.18 s 6.18 s 9.44 s 3.31 s 10.54 s Thin 33.50 s 8.15 s 10.17 s 3.74 s 240.85 s Total 65.89 s 40.73 s 59.21 s 21.12 s 290.1 s

The times taken in seconds to compute the distance transform (DT), the divergence map (Div) and to carry out the thinning (Thin), are each shown separately. The results are consistent with the complexity analysis in Section 5.4.

processor 550 MHz Pentium III machine are shown in Table 2. As predicted by the complexity analysis in Section 5.4, the computations of the distance transform and the divergence map are linear in the size n of the 3D array, while the thinning procedure has an O(k log(k)) dependence on k, the number of points contained within the volume. 7. Conclusions

Malandain et al. (1993), can be readily incorporated. Thus, the approach has a number of advantages over alternative methods in the literature. Finally, it should be clear that whereas we have focused on the interior of an object, the skeleton of the background can be similarly obtained by locating points with high positive average outward ﬂux. Acknowledgments This work was supported by the Natural Sciences and Engineering Research Council of Canada, FCAR Qu´ bec, the Canadian Foundation for Innovation, the e National Science Foundation, the Air Force Ofﬁce of Scientiﬁc Research, the Army Research Ofﬁce and by a Multi University Research Initiative grant. We are grateful to Pavel Dimitrov and Carlos Phillips for help with the 2D simulations. Louis Collins, Georges Le Goualher, Belinda Lee and Terry Peters kindly supplied the medical data. Finally, we are particularly grateful to James Damon of the Department of Mathematics at the University of North Carolina, Chapel Hill with whom we have had many useful discussions. He pointed us to an alternate form of the divergence theorem that could be applied in regions containing medial points. He used this form to show that for medial points the average outward ﬂux measure tends to a negative number in the limit as the region is shrunk to the point under consideration. This calculation lends our algorithm a very strong theoretical motivation. Note
1. The proof of this fact was conveyed to us by James Damon in personal communications. He pointed us to an alternate form of the divergence theorem that could be applied in regions intersecting the medial axis or surface, which he used to work out the limiting behavior of the average outward ﬂux. We are grateful to him for this analysis.

In this paper we have applied a Hamiltonian formalism to the eikonal equation, which offers conceptual advantages when it comes to shock detection. The calculation shows that when applied to Blum’s grassﬁre ﬂow, the gradient vector ﬁeld q of the signed Euclidean distance ˙ function to the object’s boundary drives the motion of points on the bounding curve (2D) or surface (3D). A measure of the average outward ﬂux of this vector ﬁeld can be used to distinguish medial points from nonmedial ones. In the limit as the region about which this ﬂux is computed shrinks to a point, the measure tends to zero for non-medial points but to a negative number below a constant factor times q · N for medial points, ˙ where N is the one-sided normal to the medial axis or surface. We have combined this measure with a homotopy preserving thinning process on a discrete lattice to develop an algorithm that is computationally efﬁcient and yields skeletons that are homotopic to the original objects and thin in 2D as well as in 3D. Whereas in theory the average outward ﬂux is desired only in the limit as the region shrinks to a point, our experiments show that the average outward ﬂux computed over a very small neighborhood (a circle in 2D or a sphere in 3D) provides a sufﬁcient approximation to the limiting values. This, being an integral formulation, is robust to boundary perturbations and digital rotations, as demonstrated by our numerical experiments. We have also illustrated that digital segmentations of medial axes and surfaces such as those proposed in

230

Siddiqi et al.

References
Arcelli, C. and di Baja, G.S. 1985. A width-independent fast thinning algorithm. IEEE Transactions on Pattern Analysis and Machine Intelligence, 7(4):463–474. Arcelli, C. and di Baja, G.S. 1992. Ridge points in euclidean distance maps. Pattern Recognition Letters, 13(4):237–243. Arnold, V.I. 1989. Mathematical Methods of Classical Mechanics, 2nd edn. Springer-Verlag: Berlin. Bertrand, G. 1995. A parallel thinning algorithm for medial surfaces. Pattern Recognition Letters, 16:979–986. Blum, H. 1973. Biological shape and visual science. Journal of Theoretical Biology, 38:205–287. Borgefors, G. 1984. Distance transformations in arbitrary dimensions. Computer Vision Graphics and Image Processing, 27:321– 345. Borgefors, G., Nystrom, I., and Baja, G.S.D. 1998. Skeletonizing volume objects part II: From surface to curve skeleton. In International Workshop on Syntatical and Structural Pattern Recognition, pp. 220–229. Borgefors, G., Nystrom, I., and Baja, G.S.D. 1999. Computing skeletons in three dimensions. Pattern Recognition, 32:1225–1236. Brockett, R. and Maragos, P. 1992. Evolution equations for continuous-scale morphology. In Proceedings of the IEEE Conference on Acoustics, Speech and Signal Processing, San Francisco, CA. Bruss, A.R. 1989. The eikonal equation: Some results applicable to computer vision. In Shape From Shading, B.K.P. Horn and M.J. Brooks (Eds.). MIT Press: Cambridge, MA, pp. 69–87. Caselles, V., Morel, J.-M., Sapiro, G., and Tannenbaum, A. (Eds.). 1998. IEEE Transactions on Image Processing, Special Issue on PDEs and Geometry-Driven Diffusion in Image Processing and Analysis. Crandall, M.G., Ishii, H., and Lions, P.-L. 1992. User’s guide to viscosity solutions of second order partial differential equations. Bulletin of the American Mathematical Society, 27(1):1–67. Cross, A.D.J. and Hancock, E.R. 1997. Scale-space vector ﬁelds for feature analysis. In Conference on Computer Vision and Pattern Recognition, pp. 738–743. Dimitrov, P., Phillips, C., and Siddiqi, K. 2000. Robust and efﬁcient skeletal graphs. In Conference on Computer Vision and Pattern Recognition, Hilton Head, South Carolina, pp. 417–423. Faugeras, O. and Keriven, R. 1998. Complete dense stereovision using level set methods. In European Conference on Computer Vision, vol. 1, pp. 379–393. Furst, J.D. and Pizer, S.M. 1998. Marching optimal parameter ridges: An algorithm to extract shape loci in 3D images. In International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 780–787. Ge, Y., Stelts, D.R., Zha, X., Vining, D., and Wang, J. 1998. Computing the central path of the colon from CT images. In SPIE International Symposium on Medical Imaging, San Francisco, vol. 3338(1), pp. 702–713. Goldak, J.A., Yu, X., Knight, A., and Dong, L. 1991. Constructing discrete medial axis of 3-D objects. International Journal of Computational Geometry and Applications, 1(3):327– 339. Gomez, J. and Faugeras, O. 2000. Level sets and distance functions. In European Conference on Computer Vision, Dublin, Ireland, vol. 1, pp. 588–602.

Horn, B.K.P. and Brooks, M.J. (Eds.). 1989. Shape From Shading. MIT Press: Cambridge, MA. Kalitzin, S.N., ter Haar Romeny, B.M., Salden, A.H., Nacken, P.F.M., and Viergever, M.A. 1998. Topological numbers and singularities in scalar images. Journal of Mathematical Imaging and Vision, 9(3):253–269. Kimia, B.B., Tannenbaum, A., and Zucker, S.W. 1994. On optimal control methods in computer vision and image processing. In Geometry-Driven Diffusion in Computer Vision, B. ter Haar Romeny (Ed.). Kluwer: Norwell, MA, pp. 307–338. Kimia, B.B., Tannenbaum, A., and Zucker, S.W. 1995. Shape, shocks, and deformations I: The components of two-dimensional shape and the reaction-diffusion space. International Journal of Computer Vision, 15:189–224. Kimmel, R., Shaked, D., and Kiryati, N. 1995a. Skeletonization via distance maps and level sets. Computer Vision and Image Understanding, 62(3):382–391. Kimmel, R., Siddiqi, K., Kimia, B.B., and Bruckstein, A. 1995b. Shape from shading: Level set propagation and viscosity solutions. International Journal of Computer Vision, 16(2):107–133. Kong, T.Y. and Rosenfeld, A. 1989. Digital topology: Introduction and survey. Computer Vision Graphics and Image Processing, 48(3):357–393. Lanczos, C. 1986. The Variational Principles of Mechanics. Dover: New York. Lee, T.-C. and Kashyap, R.L. 1994. Building skeleton models via 3-D medial surface/axis thinning algorithm. Graphical Models and Image Processing, 56(6):462–478. Leymarie, F. and Levine, M.D. 1992. Simulating the grassﬁre transform using an active contour model. IEEE Transactions on Pattern Analysis and Machine Intelligence, 14(1):56–75. Liu, A., Bullitt, E., and Pizer, S.M. 1998a. 3D/2D registration via skeletal near projective invariance in tubular objects. In International Conference on Medical Image Computing and ComputerAssisted Intervention, pp. 952–963. Liu, T.-L. and Geiger, D. 1999. Approximate tree matching and shape similarity. In International Conference on Computer Vision, Kerkyra, Greece, pp. 456–461. Liu, T.-L., Geiger, D., and Kohn, R.V. 1998b. Representation and selfsimilarity of shapes. In International Conference on Computer Vision. Malandain, G., Bertrand, G., and Ayache, N. 1993. Topological segmentation of discrete surfaces. International Journal of Computer Vision, 10(2):183–197. Malandain, G. and Fernandez-Vidal, S. 1998. Euclidean skeletons. Image and Vision Computing, 16:317–327. Manzanera, A., Bernard, T.M., Preteux, F., and Longuet, B. 1999. Medial faces from a concise 3D thinning algorithm. In International Conference on Computer Vision, Kerkyra, Greece, pp. 337– 343. Miller, D. and Zucker, S.W. 1999. Computing with self-excitatory cliques. Neural Computation, 11(1):21–66. N¨ f, M., K¨ bler, O., Kikinis, R., Shenton, M.E., and Sz´ kely, G. a u e 1996. Characterization and recognition of 3D organ shape in medical image analysis using skeletonization. In IEEE Workshop on Mathematical Methods in Biomedical Image Analysis. Ogniewicz, R.L. 1993. Discrete Voronoi Skeletons. Hartung-Gorre. Oliensis, J. and Dupuis, P. 1994. An optimal control formulation and related numerical methods for a problem in shape construction. Annals of Applied Probability, 4(2):287–346.

Hamilton-Jacobi Skeletons

231

Osher, S. and Shu, C.-W. 1991. High-order essentially nonoscillatory schemes for Hamilton-Jacobi equations. SIAM Journal of Numerical Analysis, 28:907–922. Osher, S.J. and Sethian, J.A. 1988. Fronts propagating with curvature dependent speed: Algorithms based on Hamilton-Jacobi formulations. Journal of Computational Physics, 79:12–49. Pizer, S.M., Joshi, S., Fletcher, P., Styner, M., Tracton, G., and Chen, Z. 2001. Segmentation of single-ﬁgure objects by deformable M-reps. In Medical Image Computing and Computer-Assisted Intervention, W.J. Niessen and M.A. Viergever (Eds.). vol. 2208 of Lecture Notes in Computer Science. Springer: Berlin, pp. 862– 871. Pudney, C. 1998. Distance-ordered homotopic thinning: A skeletonization algorithm for 3D digital images. Computer Vision and Image Understanding, 72(3):404–413. Rouy, E. and Tourin, A. 1992. A viscosity solutions approach to shape-from-shading. SIAM Journal of Numerical Analysis, 29(3):867–884. Sapiro, G., Kimia, B.B., Kimmel, R., Shaked, D., and Bruckstein, A. 1992. Implementing continuous-scale morphology. Pattern Recognition, 26(9). Schmitt, M. 1989. Some examples of algorithms analysis in computational geometry by means of mathematical morphology techniques. In Lecture Notes in Computer Science, Geometry and Robotics, vol. 391, J. Boissonnat and J. Laumond (Eds.). SpringerVerlag: Berlin, pp. 225–246. Sebastian, T.B., Tek, H., Crisco, J.J., Wolfe, S.W., and Kimia, B.B. 1998. Segmentation of carpal bones from 3D CT images using skeletally coupled deformable models. In International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 1184–1194. Sethian, J. 1996a. Level Set Methods: Evolving Interfaces in Geometry, Fluid Mechanics, Computer Vision, and Materials Science. Cambridge University Press: Cambridge. Sethian, J.A. 1996b. A fast marching level set method for monotonically advancing fronts. In Proceedings of the National Academy of Sciences, USA, 93:1591–1595. Shah, J. 1996. A common framework for curve evolution, segmentation and anisotropic diffusion. In Conference on Computer Vision and Pattern Recognition, pp. 136–142. Shankar, R. 1994. Principles of Quantum Mechanics. Plenum Press: New York. Sharvit, D., Chan, J., Tek, H., and Kimia, B.B. 1998. Symmetrybased indexing of image databases. In IEEE Workshop on ContentBased Access of Image and Video Libraries. Sheehy, D.J., Armstrong, C.G., and Robinson, D.J. 1996. Shape

description by medial surface construction. IEEE Transactions on Visualization and Computer Graphics, 2(1):62–72. Sherbrooke, E.C., Patrikalakis, N., and Brisson, E. 1996. An algorithm for the medial axis transform of 3D polyhedral solids. IEEE Transactions on Visualization and Computer Graphics, 2(1):44– 61. Siddiqi, K., Bouix, S., Tannenbaum, A., and Zucker, S.W. 1999a. The Hamilton-Jacobi Skeleton. In International Conference on Computer Vision, Kerkyra, Greece, pp. 828–834. Siddiqi, K., Kimia, B.B., and Shu, C. 1997. Geometric shockcapturing eno schemes for subpixel interpolation, computation and curve evolution. Graphical Models and Image Processing, 59(5):278–301. Siddiqi, K., Shokoufandeh, A., Dickinson, S.J., and Zucker, S.W. 1999b. Shock graphs and shape matching. International Journal of Computer Vision, 35(1):13–32. Stetten, G.D., and Pizer, S.M. 1999. Automated identiﬁcation and measurement of objects via populations of medial primitives, with application to real time 3D echocardiography. In International Conference on Information Processing in Medical Imaging, pp. 84–97. Sussman, M., Smereka, P., and Osher, S. 1994. A level set approach for computing solutions to incompressible two-phase ﬂow. Journal of Computational Physics, 114:146–154. Tari, S. and Shah, J. 1998. Local symmetries of shapes in arbitrary dimension. In International Conference on Computer Vision, Bombay, India. Tari, Z.S.G., Shah, J., and Pien, H. 1997. Extraction of shape skeletons from grayscale images. Computer Vision and Image Understanding, 66:133–146. Teichmann, M. and Teller, S. 1998. Assisted articulation of closed polygonal models. In 9th Eurographics Workshop on Animation and Simulation. Tek, H. and Kimia, B.B. 1999. Symmetry maps of free-form curve segments via wave propagation. In International Conference on Computer Vision, Kerkyra, Greece, pp. 362–369. van den Boomgaard, R. and Smeulders, A. 1994. The morphological structure of images: The differential equations of morphological scale-space. IEEE Transactions on Pattern Analysis and Machine intelligence, 16(11):1101–1113. Zhou, Y., Kaufman, A., and Toga, A.W. 1998. 3D skeleton and centerline generation based on an approximate minimum distance ﬁeld. International Journal of the Visual Computer, 14(7):303–314. Zhu, S. and Yuille, A.L. 1996. FORMS: A ﬂexible object recognition and modeling system. International Journal of Computer Vision, 20(3):187–212.

