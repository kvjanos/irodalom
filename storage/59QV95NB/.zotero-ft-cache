PET Meets Optical Imaging
A Laurin Publication

Photonic Solutions for Biotechnology and Medicine February 2004

Clearing Up Deconvolution

Photonics Aids Burn Diagnosis

A Laurin Publication

IMAGING SOFTWARE

Photonic Solutions for Biotechnology and Medicine

Clearing Up Deconvolution
Dr. David S.C. Biggs, AutoQuant Imaging Inc. Deconvolution software produces images with increased resolution, better contrast and improved signal-to-noise ratio and is becoming a standard part of digital microscopy, especially in the life sciences.

O

ver the past decade, deconvolution in microscopy has advanced from a technique used by only the most advanced die-hard microscopist to a routine part of the imaging process in many laboratories and core facilities. The maturing of deconvolution has been fueled by the widespread tran-

sition to digital microscopy through more sensitive CCD cameras, more accurate focusing mechanisms, better objective lenses and an abundance of new fluorophores. In addition, the significant increases in computer storage and processing power mean that deconvolution no longer limits the speed of an experi-

ment. Ongoing efforts to improve processing algorithms and software development to produce user-friendly applications have made deconvolution accessible to a large majority of the microscopy community. However, to many, deconvolution still needs to be demystified. Many believe that the algorithms are too complex to understand or that processing the images will somehow destroy the integrity of the data.

Why deconvolution?
Deconvolution, deblurring and image restoration are all computer processing techniques designed to overcome the physical optical limitations of a variety of microscope modalities. Computer deconvolution was initiated by the desire to remove the characteristic out-of-focus haze that contaminated images from a wide-field microscope (Figure 1). A microscope is often characterized by its point spread function, or PSF — a twoor three-dimensional description of how a single point of light in the specimen is transformed by the instrument and presented to the user. Imaging a small point of light, such as a fluorescent bead, in a wide-field microscope and focusing through the slide produces the characteristic 3-D hourglass shape (Figure 2A). Every imaging system has a unique PSF as determined by the combined optical

Figure 1. In wide-field fluorescence microscopy, the specimen is excited with a specific wavelength, and emission occurs at a longer wavelength. Focusing the light onto the specimen causes the characteristic cone-shaped point spread function. Optical sectioning is achieved by moving either the stage or the objective lens so that the focus moves up and down through the specimen.

Reprinted from the February 2004 issue of Biophotonics International © Laurin Publishing Co. Inc.

Figure 2. An Olympus wide-field microscope using a 1.35-NA oil objective lens with emission filter at 600 nm imaged 100-nm fluorescent beads at the Marine Biological Laboratory in Woods Hole, Mass. The images have 64-nm pixels and 300 nm between Z sections (42 slices total). The A sections show X-Y and X-Z slices through a single bead on the left and the sum projection of all slices at right. B shows the original sum projection of four beads on the left and, at right, sum projection following 20 iterations of maximum likelihood blind deconvolution. Peak intensity of the deconvolved volume increased by a factor of more than 100, while the total summed intensity remained constant.
characteristics of the sample, coverslip, objective lens, wavelength and microscope.1 For example, confocal microscopes have a PSF that typically looks like an oval football (or ellipsoid) in the axial direction. An arbitrary object can be thought of as a large collection of point sources of light at different positions and with different intensities. The image presented to the user can be described as a summed collection of PSFs, each centered at, and scaled in intensity according to, the location of the corresponding point sources within the sample. Mathematically, this operation is called convolution. Therefore, instead of seeing a clean image, a mass of PSFs overlap, creating the typical haze that obscures features of interest (Figure 2B). The image from the microscope is not the true object, but merely a representation of it. Because the influence of the microscope’s optics can be modeled mathematically, the aim of deconvolution is to use computer processing to reverse that influence and recover the underlying object. One of the most famous uses of deconvolution was the processing of astronomical imagery from the Hubble Space Telescope when it was launched with its spherically aberrated primary mirror. Despite the space missions to correct the optical faults, deconvolution is still used as a regular part of postprocessing Hubble imagery. There are many approaches to deconvolving microscope imagery, but all require knowledge of the PSF. One method is to use a theoretical PSF based upon a computational model of the optical system used to obtain the image. This assumes that the microscope is operating optimally and that the specimen is ideally mounted. To more accurately characterize the performance of the microscope, it is typical to use a measured PSF, whereby a fluorescent bead smaller than the resolution of the microscope is imaged in 3-D, and the empirical measurement is the basis for the PSF. The PSF should be reimaged if part of the optical system is changed (e.g., objective lens or wavelength). The bead also should be mounted in the same medium as the specimen. Some users may even embed beads in the mounting medium with the specimen as a reference. Imaging beads is an excellent method for characterizing the performance of the microscope and objective lens. The defocused image should appear the same both above and below the bead and be circular. Any deviations from this could indicate spherical aberrations from a refractive index mismatch, dirt on the lens

Figure 3. The bead slide from Figure 2 was imaged using the same microscope and objective with a confocal scan head (Olympus FluoView) at 38-nm X-Y pixels and 30-nm Z sections. The sum projections of the original volume in both X-Y and X-Z are on the left, and the projections following iterative blind deconvolution, on the right. The confocal images are scaled to twice the size of the wide-field images for clarity.

Figure 4. Wide-field fluorescence images of the leg of a fruit fly embryo were acquired with a 1.25-NA oil objective and 168 optical sections (400-nm Z-axis steps). The images at left show maximum intensity (brightest point) projections in X-Y and X-Z of the original image volume, and those at right show maximum intensity projections following maximum likelihood iterative blind deconvolution. The deconvolved data show a significant decrease in out-of-focus blur, both laterally and axially. Original data courtesy of Leica Microsystems, Cambridge, UK.
or some other distortion. Imaging beads to characterize the PSF requires high signal-to-noise-ratio images and, sometimes, averaging multiple beads. Most algorithms also will preprocess the PSF image to remove noise and impose rotational and possibly axial symmetry. A single PSF to characterize an entire optical system or an entire volume may not provide the optimal result because it doesn’t take into account variations across the field of view or through the depth of the specimen. A final approach to determining the PSF of the microscope is to extract it directly from the image data. At first, this may seem counterintuitive, as the algorithm is trying to solve for both the image and PSF from a single observation. However, basic knowledge about the microscope allows constraints to be imposed. For example, knowing the spatial and spectral shape of the PSF and other image characteristics can make this a mathematical reality. This technique is termed blind deconvolution because the PSF is unknown a priori and is adaptively estimated directly from the data set, which means the best PSF that fits the data is obtained.2 and the PSF. Also, once the PSF has been estimated, it can be reused — for example, to deconvolve a time-lapse image sequence. A further benefit of the adaptive method is that, if the image volume is subdivided during processing, a different PSF will be determined for each region so that it varies across the image. Image restoration techniques vary in their assumptions, speed, performance and ability to quantify the final result. The simplest are often termed deblurring and are fast image-sharpening methods. “Nearest neighbors” is a well known technique that requires three sequential slices. The blur in the center slice is approximated by a blurred version of the slice above and below. The estimated blur is then subtracted, leaving the in-focus features. This operation is very fast, but the result is nonquantitative because fluorescence intensities (photons) are removed rather than reassigned to their source. A single-slice version of the algorithm, termed “no neighbors,” is essentially an unsharp mask — a photographic technique whereby a blurred version of an image is subtracted from the original, leaving the sharp features. Another image restoration technique is the 3-D inverse filter, which requires a 3-D PSF. The inverse filter, or Wiener filter, is a single-step operation performed in Fourier (or frequency) space by dividing the captured image by the PSF.

Unlike no/nearest neighbors, the entire 3-D volume is processed simultaneously, and intensities are retained rather than removed. This algorithm is a fast and effective way to remove the majority of the blur using either a theoretical or a measured PSF. Image noise is usually managed through an adjustable smoothing operation applied during processing. The results are qualitative and generally better than the no/nearest neighbor methods, especially in the X-Z and Y-Z perspectives. A more rigorous approach is constrained iterative deconvolution, which uses an algorithm that produces successive improvements to the estimate of the real specimen from the captured image.3 Iterative methods take an estimate of the object, blur it using the PSF and compare the result with the observed image. Any difference is used to update the estimate of the object. As the iterations proceed, the object estimate converges to the most accurate solution as defined by the imaging model. Again, when using blind deconvolution, this most accurate solution applies to both the object and PSF. There are many constrained iterative methods that vary based upon implementation, noise handling, resolution enhancement and ability to quantify the final result. The algorithms are often classified by terms such as least squares, maximum entropy and maximum likelihood estimation.4

Deconvolution vs. confocal
Processing of 3-D data sets from widefield microscopy is the most common use of deconvolution because of the inherent haze in images. However, a growing number of other microscopy applications can benefit from the improved contrast, resolution and signal-to-noise ratio of deconvolution. Digital approaches to image restoration of wide-field microscope imagery were often thought of as competing with confocal microscopy. The confocal microscope delivers excellent optical sections from thick specimens, but the light rejected by the pinhole can result in low signal levels. Images obtained using a confocal microscope can be improved considerably with respect to axial resolution and signal-to-noise ratio by employing iterative deconvolution. Often, it may be desirable to open the confocal pinhole for very dim specimens to admit more light to the detector. In these cases,

Reusing the PSF
Hence, in constrained iterative deconvolution using the blind approach, successive iterations update both the image

deconvolution does an excellent job of ameliorating the loss of signal resolution, while further improving the signal-tonoise characteristics.5 The question of whether wide-field microscopy plus deconvolution is better than confocal microscopy depends upon the resilience of the specimen under exposure to light. Fragile live specimens will survive longer with the lower light exposure of wide-field microscopy, whereas confocal produces better contrast with thick specimens. Another type of confocal microscopy, spinning disk confocal microscopy, is a multipoint scanning system that uses a CCD camera and can collect optical sections very quickly, making it well-suited to live-cell imaging. Image characteristics from a spinning disk confocal microscope, whether illuminated by laser or arc lamp, fall between those of a widefield and a laser-scanning confocal microscope, making deconvolution technology a perfect complement. Deconvolution applies equally to 2-D and 3-D image volumes, providing that there is little out-of-focus contamination. Confocal microscopes produce thin optical sections that can be processed as 2-D samples, especially if the pinhole is opened slightly.5 In wide-field microscopy, a specimen that is optically thin, so that the entire thickness falls in the depth of field of the objective lens, can be processed using a 2-D diffraction-limited PSF. Another 2-D application is total internal reflection fluorescence microscopy, which illuminates structures only on the surface of the slide and produces 2-D images suitable for deconvolution. Today, iterative 2-D deconvolution algorithms can produce quantitatively accurate results from appropriate 2-D samples or imaging methods. Blind deconvolution of 2-D images requires relatively little information about the image or how it was captured to produce a desirable result, making it a widely applicable solution.

Figure 5. Dual-channel confocal fluorescence images of paper fibers were acquired with a 0.75-NA air objective and 95 optical sections. The images at left show the maximum intensity (brightest point) projections in X-Y and X-Z of the original image volume, and those at right show the maximum intensity projections following 10 iterations of maximum likelihood blind deconvolution. The deconvolved data show a major improvement in axial resolution. Original data courtesy of Jerry Benham, Nikon USA.

Using the data
Once the images are deconvolved, the question often arises as to how the user can know that the results are valid. First, the user should examine all the optical slices in the original and deconvolved volumes to see that features and details appear in both. Even if they weren’t noticeable before because of the haze, details should be at least faintly visible.

Figure 6. In 2-D wide-field fluorescence images taken of a bovine endothelial cell, the left portion shows the original image and the right, the result of 2-D iterative blind deconvolution. No microscope parameters were available to aid deconvolution. Original data courtesy of Leica Microsystems, Cambridge, UK.

Overprocessing the data (e.g., too many iterations) may result in false features being accentuated out of noise. Artifacts also can occur at the edge of the image. Ideally, the specimen should fall entirely within the field of view; however, if the object extends beyond the edge, not all of the haze is captured, and the edge data may be invalid. The algorithms have various methods to prevent edge discontinuities. In addition, processing can cause ringing or ripple artifacts around edges in the specimen. This may result from image saturation, an incorrect PSF, spherical aberration or excessive noise. Beyond creating a pretty picture, the deconvolved data can be quantified if constrained iterative algorithms are used. Quantification of surface area and volume will be more accurate with deconvolved data because haze in the raw data will tend to overestimate structure size. Quantitation of fluorescent intensities, without considering deconvolution, can be difficult because a myriad of external factors affect fluorescence emission and detection. Fortunately, deconvolution will significantly increase peak fluorescent intensity by concentrating the outof-focus light into its point of origin. Simply put, deconvolution will improve the dynamic range of the images obtained on an imaging system. Intensity quantitation will then be more accurate because light from any one structure will not contaminate those nearby.

Proper imaging
Deconvolution by computer processing is possible when the mathematical model assumed closely matches what is physically occurring in the microscope.

This means that any deviations from the model not accounted for can cause artifacts. Once the objective lens and the sample setup are optimized, there are several important considerations when collecting the imagery, including: • Correctly sampling in both X-Y and Z. • Focusing sufficiently above and below the specimen. • Ensuring that the illumination source is stable and uniform. • Preventing image saturation. • Minimizing stage vibration and specimen movement. • Correcting for any camera or detector defects. Each objective lens has a characteristic resolution, both laterally and axially, and the digital imaging should be matched to it to sample the specimen, according to the Nyquist sampling theorem. Taking Z sections at intervals greater than half the depth of field of the objective lens results in undersampling because the entire specimen is not captured, and the deconvolution algorithm may be unable to reconstruct an optimal result. Moreover, image pixels larger than half the X-Y resolution of the lens can cause aliasing, whereby the pixel size is larger than the smallest observable feature, which again can limit the algorithm’s performance. For example, with a 1.4-NA oil objective lens and green light, the recommended sampling is approximately 100nm pixels in X-Y and 250-nm steps in Z. These ideal settings may have to be compromised if the specimen is sensitive to light or is moving. Capturing sufficient photons may require binning in the cam-

era to increase the signal, or larger Z-steps to reduce photobleaching. Spherical aberration is a major issue when imaging 3-D specimens and is primarily caused by a mismatch in refractive index between the lens immersion medium and the specimen embedding medium. Spherical aberration, which increases blur and reduces image intensity, ideally should be corrected at the microscope, rather than by postprocessing. Restoration artifacts can occur if the PSF used for deconvolution does not take into account the spherical aberrations present. While deconvolution algorithms can produce impressive results from hazy data, nothing can compensate for poor imaging techniques. The adage “garbage in, garbage out” is true for the application of image processing algorithms. Deconvolution will not make bad data good; it will make good data better. The better the data you collect for deconvolution, the more optimized your microscope will be. When pushing the limits of optical microscopy to image the faintest and smallest cellular structures, compromises must be made. However, with the proper balance among signal, resolution and deconvolution, a scientifically valid image can be formed. By combining the best hardware and software technologies, your biological imaging capabilities can be improved significantly. Deconvolution algorithms will continue to develop and become faster and more versatile, supporting a wider range of microscope modalities and providing a more accurate model of the underlying physics.

G

References
1. Inoué et al (1997). Video Microscopy. Second edition. Plenum Press. 2. T. Holmes et al (1995). Light microscopic images reconstructed by maximum likelihood deconvolution. Handbook of Biological Confocal Microscopy. Second edition. Plenum Press, pp. 389-402. 3. D. Agard (June 1984). Optical sectioning microscopy: cellular architecture in three dimensions. ANN. REV. BIOPHYS. BIOENG., pp. 191-219. 4. J. Swedlow et al (November 2001). A working person’s guide to deconvolution in light microscopy. BIOTECHNIQUES, pp. 1076-1097. 5. J. Larson (May 2002). Two-dimensional and three-dimensional blind deconvolution of fluorescence confocal images. Proceedings of SPIE.

Acknowledgments
The author wishes to acknowledge Timothy Holmes, Bob Kolbe, Russell Ulbrich and Enrico Stefani for their valuable feedback and input on this article.

Meet the author
David S.C. Biggs is a senior research scientist at AutoQuant Imaging Inc. in Watervliet, N.Y.

Resource
For more information about deconvolution and microscopy, see the Molecular Expressions Web site: www.microscopy.fsu.edu/ primer/digitalimaging/deconvolution/deconvolutionhome.html.

