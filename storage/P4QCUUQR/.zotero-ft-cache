Data Mining: A Heuristic Approach
Hussein A. Abbass Ruhul A. Sarker Charles S. Newton University of New South Wales, Australia

Idea Group Publishing

Information Science Publishing

Hershey • London • Melbourne • Singapore • Beijing

Acquisitions Editor: Managing Editor: Development Editor: Copy Editor: Typesetter: Cover Design: Printed at:

Mehdi Khosrowpour Jan Travers Michele Rossi Maria Boyer Tamara Gillis Debra Andree Integrated Book Technology

Published in the United States of America by Idea Group Publishing 1331 E. Chocolate Avenue Hershey PA 17033-1117 Tel: 717-533-8845 Fax: 717-533-8661 E-mail: cust@idea-group.com Web site: http://www.idea-group.com and in the United Kingdom by Idea Group Publishing 3 Henrietta Street Covent Garden London WC2E 8LU Tel: 44 20 7240 0856 Fax: 44 20 7379 3313 Web site: http://www.eurospan.co.uk Copyright © 2002 by Idea Group Publishing. All rights reserved. No part of this book may be reproduced in any form or by any means, electronic or mechanical, including photocopying, without written permission from the publisher. Library of Congress Cataloging-in-Publication Data Data mining : a heuristic approach / [edited by] Hussein Aly Abbass, Ruhul Amin Sarker, Charles S. Newton. p. cm. Includes index. ISBN 1-930708-25-4 1. Data mining. 2. Database searching. 3. Heuristic programming. I. Abbass, Hussein. II. Sarker, Ruhul. III. Newton, Charles, 1942QA76.9.D343 D36 2001 006.31--dc21 2001039775

British Cataloguing in Publication Data A Cataloguing in Publication record for this book is available from the British Library.

NEW from Idea Group Publishing
• • • • • • • • • • • • • • • • • • • • • • • • • • • Data Mining: A Heuristic Approach Hussein Aly Abbass, Ruhul Amin Sarker and Charles S. Newton/ 1-930708-25-4 Managing Information Technology in Small Business: Challenges and Solutions Stephen Burgess/ 1-930708-35-1 Managing Web Usage in the Workplace: A Social, Ethical and Legal Perspective Murugan Anandarajan and Claire A. Simmers/ 1-930708-18-1 Challenges of Information Technology Education in the 21st Century Eli Cohen/ 1-930708-34-3 Social Responsibility in the Information Age: Issues and Controversies Gurpreet Dhillon/ 1-930708-11-4 Database Integrity: Challenges and Solutions Jorge H. Doorn and Laura Rivero/ 1-930708-38-6 Managing Virtual Web Organizations in the 21st Century: Issues and Challenges Ulrich Franke/ 1-930708-24-6 Managing Business with Electronic Commerce: Issues and Trends Aryya Gangopadhyay/ 1-930708-12-2 Electronic Government: Design, Applications and Management Åke Grönlund/ 1-930708-19-X Knowledge Media in Health Care: Opportunities and Challenges Rolf Grutter/ 1-930708-13-0 Internet Management Issues: A Global Perspective John D. Haynes/ 1-930708-21-1 Enterprise Resource Planning: Global Opportunities and Challenges Liaquat Hossain, Jon David Patrick and M. A. Rashid/ 1-930708-36-X The Design and Management of Effective Distance Learning Programs Richard Discenza, Caroline Howard, and Karen Schenk/ 1-930708-20-3 Multirate Systems: Design and Applications Gordana Jovanovic-Dolecek/ 1-930708-30-0 Managing IT/Community Partnerships in the 21st Century Jonathan Lazar/ 1-930708-33-5 Multimedia Networking: Technology, Management and Applications Syed Mahbubur Rahman/ 1-930708-14-9 Cases on Worldwide E-Commerce: Theory in Action Mahesh Raisinghani/ 1-930708-27-0 Designing Instruction for Technology-Enhanced Learning Patricia L. Rogers/ 1-930708-28-9 Heuristic and Optimization for Knowledge Discovery Ruhul Amin Sarker, Hussein Aly Abbass and Charles Newton/ 1-930708-26-2 Distributed Multimedia Databases: Techniques and Applications Timothy K. Shih/ 1-930708-29-7 Neural Networks in Business: Techniques and Applications Kate Smith and Jatinder Gupta/ 1-930708-31-9 Information Technology and Collective Obligations: Topics and Debate Robert Skovira/ 1-930708-37-8 Managing the Human Side of Information Technology: Challenges and Solutions Edward Szewczak and Coral Snodgrass/ 1-930708-32-7 Cases on Global IT Applications and Management: Successes and Pitfalls Felix B. Tan/ 1-930708-16-5 Enterprise Networking: Multilayer Switching and Applications Vasilis Theoharakis and Dimitrios Serpanos/ 1-930708-17-3 Measuring the Value of Information Technology Han T. M. van der Zee/ 1-930708-08-4 Business to Business Electronic Commerce: Challenges and Solutions Merrill Warkentin/ 1-930708-09-2

Excellent additions to your library!
Receive the Idea Group Publishing catalog with descriptions of these books by calling, toll free 1/800-345-4332 or visit the IGP Online Bookstore at: http://www.idea-group.com!

Data Mining: A Heuristic Approach Table of Contents
Preface ............................................................................................................................vi

Part One: General Heuristics
Chapter 1: From Evolution to Immune to Swarm to …? A Simple Introduction to Modern Heuristics ....................................................... 1 Hussein A. Abbass, University of New South Wales, Australia Chapter 2: Approximating Proximity for Fast and Robust Distance-Based Clustering ................................................................................ 22 Vladimir Estivill-Castro, University of Newcastle, Australia Michael Houle, University of Sydney, Australia

Part Two: Evolutionary Algorithms
Chapter 3: On the Use of Evolutionary Algorithms in Data Mining .......................... 48 Erick Cantú-Paz, Lawrence Livermore National Laboratory, USA Chandrika Kamath, Lawrence Livermore National Laboratory, USA Chapter 4: The discovery of interesting nuggets using heuristic techniques .......... 72 Beatriz de la Iglesia, University of East Anglia, UK Victor J. Rayward-Smith, University of East Anglia, UK Chapter 5: Estimation of Distribution Algorithms for Feature Subset Selection in Large Dimensionality Domains ..................................................... 97 Iñaki Inza, University of the Basque Country, Spain Pedro Larrañaga, University of the Basque Country, Spain Basilio Sierra, University of the Basque Country, Spain Chapter 6: Towards the Cross-Fertilization of Multiple Heuristics: Evolving Teams of Local Bayesian Learners ................................................... 117 Jorge Muruzábal, Universidad Rey Juan Carlos, Spain Chapter 7: Evolution of Spatial Data Templates for Object Classification .............. 143 Neil Dunstan, University of New England, Australia Michael de Raadt, University of Southern Queensland, Australia

Part Three: Genetic Programming
Chapter 8: Genetic Programming as a Data-Mining Tool ....................................... 157 Peter W.H. Smith, City University, UK

Chapter 9: A Building Block Approach to Genetic Programming for Rule Discovery ............................................................................................. 174 A.P. Engelbrecht, University of Pretoria, South Africa Sonja Rouwhorst, Vrije Universiteit Amsterdam, The Netherlands L. Schoeman, University of Pretoria, South Africa

Part Four: Ant Colony Optimization and Immune Systems
Chapter 10: An Ant Colony Algorithm for Classification Rule Discovery ............. 191 Rafael S. Parpinelli, Centro Federal de Educacao Tecnologica do Parana, Brazil Heitor S. Lopes, Centro Federal de Educacao Tecnologica do Parana, Brazil Alex A. Freitas, Pontificia Universidade Catolica do Parana, Brazil Chapter 11: Artificial Immune Systems: Using the Immune System as Inspiration for Data Mining ......................................................................... 209 Jon Timmis, University of Kent at Canterbury, UK Thomas Knight, University of Kent at Canterbury, UK Chapter 12: aiNet: An Artificial Immune Network for Data Analysis .................... 231 Leandro Nunes de Castro, State University of Campinas, Brazil Fernando J. Von Zuben, State University of Campinas, Brazil

Part Five: Parallel Data Mining
Chapter 13: Parallel Data Mining ............................................................................. 261 David Taniar, Monash University, Australia J. Wenny Rahayu, La Trobe University, Australia About the Authors ...................................................................................................... 290 Index ........................................................................................................................... 297

vi

Preface
The last decade has witnessed a revolution in interdisciplinary research where the boundaries of different areas have overlapped or even disappeared. New fields of research emerge each day where two or more fields have integrated to form a new identity. Examples of these emerging areas include bioinformatics (synthesizing biology with computer and information systems), data mining (combining statistics, optimization, machine learning, artificial intelligence, and databases), and modern heuristics (integrating ideas from tens of fields such as biology, forest, immunology, statistical mechanics, and physics to inspire search techniques). These integrations have proved useful in substantiating problemsolving approaches with reliable and robust techniques to handle the increasing demand from practitioners to solve real-life problems. With the revolution in genetics, databases, automation, and robotics, problems are no longer those that can be solved analytically in a feasible time. Complexity arises because of new discoveries about the genome, path planning, changing environments, chaotic systems, and many others, and has contributed to the increased demand to find search techniques that are capable of getting a good enough solution in a reasonable time. This has directed research into heuristics. During the same period of time, databases have grown exponentially in large stores and companies. In the old days, system analysts faced many difficulties in finding enough data to feed into their models. The picture has changed and now the reverse picture is a daily problem–how to understand the large amount of data we have accumulated over the years. Simultaneously, investors have realized that data is a hidden treasure in their companies. With data, one can analyze the behavior of competitors, understand the system better, and diagnose the faults in strategies and systems. Research into statistics, machine learning, and data analysis has been resurrected. Unfortunately, with the amount of data and the complexity of the underlying models, traditional approaches in statistics, machine learning, and traditional data analysis fail to cope with this level of complexity. The need therefore arises for better approaches that are able to handle complex models in a reasonable amount of time. These approaches have been named data mining (sometimes data farming) to distinguish them from traditional statistics, machine learning, and other data analysis techniques. In addition, decision makers were not interested in techniques that rely too much on the underlying assumptions in statistical models. The challenge is to not have any assumptions about the model and try to come up with something new, something that is not obvious or predictable (at least from the decision makers’ point of view). Some unobvious thing may have significant values to the decision maker. Identifying a hidden trend in the data or a buried fault in the system is by all accounts a treasure for the investor who knows that avoiding loss results in profit and that knowledge in a complex market is a key criterion for success and continuity. Notwithstanding, models that are free from assumptions–or at least have minimum assumptions–are expensive to use. The dramatic search space cannot be navigated using traditional search techniques. This has highlighted a natural demand for the use of heuristic search methods in data mining. This book is a repository of research papers describing the applications of modern

vii
heuristics to data mining. This is a unique–and as far as we know, the first–book that provides up-to-date research in coupling these two topics of modern heuristics and data mining. Although it is by all means an incomplete coverage, it does provide some leading research in this area. This book contains open-solicited and invited chapters written by leading researchers in the field. All chapters were peer reviewed by at least two recognized researchers in the field in addition to one of the editors. Contributors come from almost all the continents and therefore, the book presents a global approach to the discipline. The book contains 13 chapters divided into five parts as follows: • Part 1: General Heuristics • Part 2: Evolutionary Algorithms • Part 3: Genetic Programming • Part 4: Ant Colony Optimization and Immune Systems • Part 5: Parallel Data Mining Part 1 gives an introduction to modern heuristics as presented in the first chapter. The chapter serves as a textbook-like introduction for readers without a background in heuristics or those who would like to refresh their knowledge. Chapter 2 is an excellent example of the use of hill climbing for clustering. In this chapter, Vladimir Estivill-Castro and Michael E. Houle from the University of Newcastle and the University of Sydney, respectively, provide a methodical overview of clustering and hill climbing methods to clustering. They detail the use of proximity information to assess the scalability and robustness of clustering. Part 2 covers the well-known evolutionary algorithms. After almost three decades of continuous research in this area, the vast amount of papers in the literature is beyond a single survey paper. However, in Chapter 3, Erick Cantú-Paz and Chandrika Kamath from Lawrence Livermore National Laboratory, USA, provide a brave and very successful attempt to survey the literature describing the use of evolutionary algorithms in data mining. With over 75 references, they scrutinize the data mining process and the role of evolutionary algorithms in each stage of the process. In Chapter 4, Beatriz de la Iglesia and Victor J. Rayward-Smith, from the University of East Anglia, UK, provide a superb paper on the application of Simulated Annealing, Tabu Search, and Genetic Algorithms (GA) to nugget discovery or classification where an important class is under-represented in the database. They summarize in their chapter different measures of performance for the classification problem in general and compare their results against 12 classification algorithms. Iñaki Inza, Pedro Larrañaga, and Basilio Sierra from the University of the Basque Country, Spain, follow, in Chapter 5, with an outstanding piece of work on feature subset selection using a different type of evolutionary algorithms, the Estimation of Distribution Algorithms (EDA). In EDA, a probability distribution of the best individuals in the population is maintained to sample the individuals in subsequent generations. Traditional crossover and mutation operators are replaced by the re-sampling process. They applied EDA to the Feature Subset Selection problem and showed that it significantly improves the prediction accuracy. In Chapter 6, Jorge Muruzábal from the University of Rey Juan Carlos, Spain, presents the brilliant idea of evolving teams of local Bayesian learners. Bayes theorem was resurrected as a result of the revolution in computer science. Nevertheless, Bayesian approaches, such as

viii
Bayesian Networks, require large amounts of computational effort, and the search algorithm can easily become stuck in a local minimum. Dr. Muruzábal combined the power of the Bayesian approach with the ability of Evolutionary Algorithms and Learning Classifier Systems for the classification process. Neil Dunstan from the University of New England, and Michael de Raadt from the University of Southern Queensland, Australia, provide an interesting application of the use of evolutionary algorithms for the classification and detection of Unexploded Ordnance present on military sites in Chapter 7. Part 3 covers the area of Genetic Programming (GP). GP is very similar to the traditional GA in its use of selection and recombination as the means of evolution. Different from GA, GP represents the solution as a tree, and therefore the crossover and mutation operators are adopted to handle tree structures. This part starts with Chapter 8 by Peter W.H. Smith from City University, UK, who provides an interesting introduction to the use of GP for data mining and the problems facing GP in this domain. Before discarding GP as a useful tool for data mining, A.P. Engelbrecht and L Schoeman from the University of Pretoria, South Africa along with Sonja Rouwhorst from the University of Vrije, The Netherlands, provide a building block approach to genetic programming for rule discovery in Chapter 9. They show that their proposed GP methodology is comparable to the famous C4.5 decision tree classifier–a famous decision tree classifier. Part 4 covers the increasingly growing areas of Ant Colony Optimization and Immune Systems. Rafael S. Parpinelli and Heitor S. Lopes from Centro Federal de Educacao Tecnologica do Parana, and Alex A. Freitas from Pontificia Universidade Catolica do Parana, Brazil, present a pioneer attempt, in Chapter 10, to apply ant colony optimization to rule discovery. Their results are very promising and through an extremely interesting approach, they present their techniques. Jon Timmis and Thomas Knight, from the University of Kent at Canterbury, UK, introduce Artificial Immune Systems (AIS) in Chapter 11. In a notable presentation, they present the AIS domain and how can it be used for data mining. Leandro Nunes de Castro and Fernando J. Von Zuben, from the State University of Campinas, Brazil, follow in Chapter 12 with the use of AIS for clustering. The chapter presents a remarkable metaphor for the use of AIS with an outstanding potential for the proposed algorithm. In general, the data mining task is very expensive, whether we are using heuristics or any other technique. It was therefore impossible not to present this book without discussing parallel data mining. This is the task carried out by David Taniar from Monash University and J. Wenny Rahayu from La Trobe University, Australia, in Part 5, Chapter 13. They both have written a self-contained and detailed chapter in an exhilarating style, thereby bringing the book to a close. It is hoped that this book will trigger great interest into data mining and heuristics, leading to many more articles and books!

ix

Acknowledgments
We would like to express our gratitude to the contributors without whose submissions this book would not have been born. We owe a great deal to the reviewers who reviewed entire chapters and gave the authors and editors much needed guidance. Also, we would like to thank those dedicated reviewers, who did not contribute through authoring chapters to the current book or to our second book Heuristics and Optimization for Knowledge Discovery– Paul Darwen, Ross Hayward, and Joarder Kamruzzaman. A further special note of thanks must go also to all the staff at Idea Group Publishing, whose contributions throughout the whole process from the conception of the idea to final publication have been invaluable. In closing, we wish to thank all the authors for their insights and excellent contributions to this book. In addition, this book would not have been possible without the ongoing professional support from Senior Editor Dr. Mehdi Khosrowpour, Managing Editor Ms. Jan Travers and Development Editor Ms. Michele Rossi at Idea Group Publishing. Finally, we want to thank our families for their love, support, and patience throughout this project. Hussein A. Abbass, Ruhul Sarker, and Charles Newton Editors (2001)

PART ONE: GENERAL HEURISTICS

2 Abbass

Chapter I

From Evolution to Immune to Swarm to ...? A Simple Introduction to Modern Heuristics
Hussein A. Abbass University of New South Wales, Australia

The definition of heuristic search has evolved over the last two decades. With the continuous success of modern heuristics in solving many combinatorial problems, it is imperative to scrutinize the success of these methods applied to data mining. This book provides a repository for the applications of heuristics to data mining. In this chapter, however, we present a textbook-like simple introduction to heuristics. It is apparent that the limited space of this chapter will not be enough to elucidate each of the discussed techniques. Notwithstanding, our emphasis will be conceptual. We will familiarize the reader with the different heuristics effortlessly, together with a list of references that should allow the researcher to find his/her own way in this large area of research. The heuristics that will be covered in this chapter are simulated annealing (SA), tabu search (TS), genetic algorithms (GA), immune systems (IS), and ant colony optimization (ACO).

Copyright © 2002, Idea Group Publishing.

From Evolution to Immune to Swarm to ... 3

INTRODUCTION
Problem solving is the core of many disciplines. To solve a problem properly, we need first to represent it. Problem representation is a critical step in problem solving as it can help in finding good solutions quickly and it can make it almost impossible not to find a solution at all. In practice, there are many different ways to represent a problem. For example, operations research (OR) is a field that represents a problem quantitatively. In artificial intelligence (AI), a problem is usually represented by a graph, whether this graph is a network, tree, or any other graph representation. In computer science and engineering, tools such as system charts are used to assist in the problem representation. In general, deciding on an appropriate representation of a problem influences the choice of the appropriate approach to solve it. Therefore, we need somehow to choose the problem solving approach before representing the problem. However, it is often difficult to decide on the problem solving approach before completing the representation. For example, we may choose to represent a problem using an optimization model, then we find out that this is not suitable because there are some qualitative aspects that also need to be captured in our representation. Once a problem is represented, the need arises for a search algorithm to explore the different alternatives (solutions) to solve the problem and to choose one or more good possible solutions. If there are no means of evaluating the solutions’ quality, we are usually just interested in finding any solution. If there is a criterion that we can use to differentiate between different solutions, we are usually interested in finding the best or optimal solution. Two types of optimality are generally distinguished: local and global. A local optimal solution is the best solution found within a region (neighborhood) of the search space, but not necessarily the best solution in the overall search space. A global optimal solution is the best solution in the overall search space. To formally define these concepts, we need first to introduce one of the definitions of a neighborhood. A neighborhood Bδ(x) in the search space θ(X) defined on X ⊆ Rn and centered on a solution x is defined by the Euclidean distance δ; that is Bδ(x) = {x ∈ Rn | ||x – x|| <δ, δ>0}. Now, we can define local and global optimality as follows: Definition 1: Local optimality A solution x∈θ(X) is said to be a local minimum of the problem iff ∃ δ>0 such that f(x) ≤ f(x)∀x ∈ (Bδ(x)∩ θ(X)). Definition 2: Global optimality A solution x∈θ(X) is said to be a global minimum of the problem iff ∃ δ>0 such that f(x) ≤ f(x)∀x ∈ θ(X). Finding a global optimal solution in most real-life applications is difficult. The number of alternatives that exist in the search space is usually enormous and cannot be searched in a reasonable amount of time. However, we are usually interested in good enough solutions—or what we will call from now on, satisfactory solutions. To search for a local, global, or satisfactory solution, we need to use a search mechanism. Search is an important field of research, not only because it serves all

4 Abbass

disciplines, but also because problems are getting larger and more complex; therefore, more efficient search techniques need to be developed every day. This is true whether a problem is solved quantitatively or qualitatively. In the literature, there exist three types of search mechanisms (Turban, 1990), analytical, blind, and heuristic search techniques. These are discussed below. • Analytical Search: An analytical search algorithm is guided using some mathematical function. In optimization, for example, some search algorithms are guided using the gradient, whereas others the Hessian. These types of algorithms guarantee to find the optimal solution if it exists. However, in most cases they only guarantee to find a local optimal solution and not the global one. • Blind Search: Blind search—sometimes called unguided search - is usually categorized into two classes: complete and incomplete. A complete search technique simply enumerates the search space and exhaustively searches for the optimal solution. An incomplete search technique keeps generating a set of solutions until an optimal one is found. Incomplete search techniques do not guarantee to find the optimal solution since they are usually biased in the way they search the problem space. • Heuristic Search: It is a guided search, widely used in practice, but does not guarantee to find the optimal solution. However, in most cases it works and produces high quality (satisfactory) solutions. To be concise in our description, we need to distinguish between a general purpose search technique (such as all the techniques covered in this chapter), which can be applied to a wide range of problems, and a special purpose search technique which is domain specific (such as GSAT for the propositional satisfiability problem and back-propagation for training artificial neural networks) which will not be addressed in this chapter. A general search algorithm has three main phases: initial start, a method for generating solutions, and a criterion to terminate the search. Logically, to search a space, we need to find a starting point. The choice of a starting point is very critical in most search algorithms as it usually biases the search towards some area of the search space. This is the first type of bias introduced into the search algorithm, and to overcome this bias, we usually need to run the algorithm many times with different starting points. The second stage in a search algorithm is to define how a new solution can be generated, another type of bias. An algorithm, which is guided by the gradient, may become stuck in a saddle point. Finally, the choice of a stopping criterion depends on the problem on hand. If we have a large-scale problem, the decision maker may not be willing to wait for years to get a solution. In this case, we may end the search even before the algorithm stabilizes. From some researchers’ points of view, this is unacceptable. However in practice, it is necessary. An important issue that needs to be considered in the design of a search algorithm is whether it is population based or not. Most traditional OR and AI methods maintain a single solution at a time. Therefore, the algorithm starts with a

From Evolution to Immune to Swarm to ... 5

solution and then moves from it to another. Some heuristic search methods, however, use a population(s) of solutions. In this case, we try to improve the population as a whole, rather than improving a single solution at a time. Other heuristics maintain a probability distribution of the population instead of storing a large number of individuals (solutions) in the memory. Another issue when designing a search algorithm is the balance between intensification and exploration of the search. Early intensification of the search increases the probability that the algorithm will return a local optimal solution. Late intensification of the search may result in a waste of resources. The last issue which should be considered in designing a search algorithm is the type of knowledge used by the algorithm and the type of search strategy. Positive knowledge means that the algorithm rewards good solutions and negative knowledge means that the algorithm penalizes bad solutions. By rewarding or penalizing some solutions in the search space, an algorithm generates some belief about the good or bad areas in the search. A positive search strategy biases the search towards a good area of the search space, and a negative search strategy avoids an already explored area to explore those areas in the search space that have not been previously covered. Keeping these issues of designing a search algorithm in mind, we can now introduce heuristic search. The word heuristic originated from the Greek root ευρισκω, or to discover. In problem solving, a heuristic is a rule of thumb approach. In artificial intelligence, a heuristic is a procedure that may lack a proof. In optimization, a heuristic is an approach which may not be guaranteed to converge. In all previous fields, a heuristic is a type of search that may not be guaranteed to find a solution, but put simply “it works”. About heuristics, Newell and Simon wrote (Simon 1960): “We now have the elements of a theory of heuristic (as contrasted with algorithmic) problem solving; and we can use this theory both to understand human heuristic processes and to simulate such processes with digital computers.” The area of Heuristics has evolved rapidly over the last two decades. Researchers, who are used to working with conventional heuristic search techniques, are becoming interested in finding a new A* algorithm for their problems. A* is a search technique that is guided by the solution’s cost estimate. For an algorithm to qualify to be A*, a proof is usually undertaken to show that this algorithm guarantees to find the minimum solution, if it exists. This is a very nice characteristic. However, it does not say anything regarding the efficiency and scalability of these algorithms with regard to large-scale problems. Nowadays, heuristic search left the cage of conventional AI-type search and is now inspired by biology, statistical mechanics, neuroscience, and physics, to name but a few. We will see some of these heuristics in this chapter, but since the field is evolving rapidly, a single chapter can only provide a simple introduction to the topic. These new heuristic search techniques will be called modern heuristics, to distinguish them from the A*-type heuristics. A core issue in many modern heuristics is the process for generating solutions

6 Abbass

from within the neighborhood. This process can be done in many different ways. We will propose one way in the next section. The remaining sections of this chapter will then present different modern heuristics.

GENERATION OF NEIGHBORHOOD SOLUTIONS
In our introduction, we defined the neighborhood of a solution x as all solutions within an Euclidean distance of at most δ from x. This might be suitable for continuous domains. However, for discrete domains, the Euclidean distance is not the best choice. One metric measure for discrete binary domains is the hamming distance, which is simply the number of corresponding bits with different values in the two solutions. Therefore, if we have a solution of length n, the number of solutions in the neighborhood (we will call it the neighborhood size) defined by a hamming distance of 1 is simply n. We will call the distance, δ, that defines a neighborhood, the neighborhood length or radius. Now, we can imagine the importance of the neighborhood length. If we assume a large-scale problem with a million binary variables, the smallest neighborhood length for this problem (a neighborhood length of 1) defines a neighborhood size of one million. This size will obviously influence the amount of time needed to search a neighborhood. Let us now define a simple neighborhood function that we can use in the rest of this chapter. A solution x is generated in the neighborhood of another solution x by changing up to ζ variables of x, where ζ is the neighborhood length. The neighborhood length is measured in terms of the number of cells with different values in both solutions. Figure 1 presents an algorithm for generating solutions at random from the neighborhood of x.

Figure 1: Generation of neighborhood solutions function neighborhood(x,ζ) x←x i=0 while i < ζ k= random(0,1) x n x[k] = random(0,1) i=i+1 Loop return x end function

From Evolution to Immune to Swarm to ... 7

Figure 2: Hill climbing algorithm initialize the neighborhood length to ζ initialize optimal solution xopt ∈ θ(x) and its objective value fopt = f(xopt) repeat x ∈ neighbourhood(xopt,ζ), f = f(x) if f < fopt then xopt=x, fopt =f until loop condition is satisfied return xopt and fopt

HILL CLIMBING
Hill climbing is the greediest heuristic ever. The idea is simply not to accept a move unless it improves the best solution found so far. This represents a pure search intensification without any chance for search exploration; therefore the algorithm is more likely to return a local optimum and be very sensitive in relating to the starting point. In Figure 2, the hill climbing algorithm is presented. The algorithm starts by initializing a solution at random. A loop is then constructed to generate a solution in the neighborhood of the current one. If the new solution is better than the current one, it is accepted; otherwise it is rejected and a new solution from the neighborhood is generated.

SIMULATED ANNEALING
In the process of physical annealing (Rodrigues and Anjo, 1993), a solid is heated until all particles randomly arrange themselves forming the liquid state. A slow cooling process is then used to crystallize the liquid. That is, the particles are free to move at high temperatures and then will gradually lose their mobility when the temperature decreases (Ansari and Hou, 1997). This process is described in the early work in statistical mechanics of Metropolis (Metropolis et al., 1953) and is well known as the Metropolis algorithm (Figure 3). Figure 3: Metropolis algorithm. define the transition of the substance from state i with energy E(i) to state j with energy E(j) to be i →j define T to be a temperature level if E(i) ≤ E(j) then accept i →j  E (i ) − E ( j )  if E(i) > E(j) then accept i →j with probability exp KT    where K is the Boltzmann constant

8 Abbass

Kirkpatrick et al. (1998) defined an analogy between the Metropolis algorithm and the search for solutions in complex combinatorial optimization problems where they developed the idea of simulated annealing (SA). Simply speaking, SA is a stochastic computational technique that searches for global optimal solutions in optimization problems. In complex combinatorial optimization problems, it is usually easy to be trapped in a local optimum. The main goal here is to give the algorithm more time in the search space exploration by accepting moves, which may degrade the solution quality, with some probability depending on a parameter called the “temperature.” When the temperature is high, the algorithm behaves like random search (i.e., accepts all transitions whether they are good or not, to enable search exploration). A cooling mechanism is used to gradually reduce the temperature. The algorithm performs similar to a greedy hill-climbing algorithm when the temperature reaches zero (enabling search intensification). If this process is given sufficient time, there is a high probability that it will result in a global optimal solution (Ansari and Hou, 1997). The algorithm escapes a local optimal solution by moving with some probability to those solutions which degrade the current one and accordingly gives a high opportunity to explore more of the search space. The probability of accepting a bad solution, p(T), follows a Boltzmann (also known as the Gibbs) distribution of:
π (T ) = exp 
 E (i) − E ( j)   KT  

(1)

where E(i) is the energy or objective value of the current solution, E(j) is the previous solution’s energy, T is the temperature, and K is a Boltzmann constant. In actual implementation, K can be taken as a scaling factor to keep the temperature between 0 and 1, if it is desirable that the temperature falls within this interval. Unlike most heuristic search techniques, there is a proof for the convergence of SA (Ansari and Hou, 1997) assuming that the time , L, spent at each temperature level, T, is sufficient, usually when T→0, L→∞.

The Algorithm
There are two main approaches in SA: homogeneous and non-homogeneous (Vidal, 1993). In the former, the temperature is not updated after each step in the search space, although for the latter it is. It is found that in homogeneous SA, the transitions or generations of solutions for each temperature level represent a Markov chain of length equal to the number of transitions at that temperature level. The proof for the convergence of SA uses the homogenous version. The Markov chain length represents the time taken at each temperature level. The homogeneous algorithm is shown in Figure 4. The homogeneous algorithm starts with three inputs from the user, the initial temperature T, the initial Markov chain length L, and the neighborhood length ζ. Then, it generates an initial solution, evaluates it, and stores it as the best solution found so far. After that, for each temperature level, a new solution is generated from

From Evolution to Immune to Swarm to ... 9

Figure 4: General homogeneous simulated annealing algorithm initialize the temperature to T initialize the chain length to L initialize the neighborhood length to ζ x0 ∈ θ(x), f0 = f(x0) initialize optimal solution xopt to be x0 and its objective value fopt = f0 initialize current solution x to be x0 and its objective value f\ = f0 repeat for j = 0 to L i = i+1 xi ∈ neighbourhood(x,ζ), fi = f(xi) ∆(f) = fi – f\ if fi < fopt then xopt = xi,, fopt = fi if fi < f\ then x = xi,, f\ = fi else if exp(-∆(f)/T) > random(0,1) then x = xi,, f\ = fi next j update L and T until loop condition is satisfied return xopt and fopt the current solution neighborhood function neighbourhood(x,ζ), tested, and replaces the current optimal solution if it is better than it. The new solution is then tested against the previous solution—if it is better, the algorithm accepts it; otherwise it is accepted with a certain probability as specified in Equation 1. After completing each Markov chain of length L, the temperature and the Markov chain length are updated. The question now is: how to update the temperature T or the cooling schedule.

Cooling Schedule
In the beginning of the simulated annealing run, we need to find a reasonable value of T such that most transitions are accepted. This value can first be guessed. We then increase T with some factor until all transitions are accepted. Another way is to generate a set of random solutions and find the minimum temperature T that guarantees the acceptance of these solutions. Following the determination of the starting value of T, we need to define a cooling schedule for it. Two methods are usually used in the literature. The first is static, where we need to define a discount parameter . After the completion of each Markov chain, k, adjust T as follows (Vidal, 1993): Tk+1 = α x Tk, 0 < α < 1 (2) The second is dynamic, where one of its versions was introduced by Huang, Romeo, and Sangiovanni-Vincetilli (1986). Here,

10 Abbass
   T ∆(E)   − k 2   σ   T k  

(3)

TK +1 = T k e

∆ (E ) = ETk − E Tk − 1

(4)
k

where is the variance of the accepted solutions at temperature level . When σ T2 is large—which will usually take place at the start of the search while the algorithm is behaving like a random search - the change in the temperature will be very small. Whenσ T2 is small—which will usually take place at the end of the search while intensification of the search is at its peak—the temperature will diminish to zero quickly.
k

TABU SEARCH
Glover (1989, 1990) introduced tabu search (TS) as a method for escaping local optima. The goal is to obtain a list of forbidden (tabu) solutions/directions in the neighborhood of a solution to avoid cycling between solutions while allowing a direction, which may degrade the solution although it may help in escaping from the local optimum. Similar to SA, we need to specify how to generate solutions in the current solution’s neighborhood. Furthermore, the temperature parameter in SA is replaced with a list of forbidden solutions/directions updated after each step. When generating a solution in the neighborhood, this solution should not be in any of the directions listed in the tabu-list, although a direction in the tabu-list may be chosen with some probability if it results in a solution which is better than the current one. In essence, the tabu-list aims at constraining or limiting the search scope in the neighborhood while still having a chance to select one of these directions. Figure 5: The tabu search algorithm initialize the neighborhood length to ζ initialize the memory, M, to empty x0 ∈ θ(x), f0 = f(x0) xopt = x0, fopt = f0 x = x0, f\ = f0 i=1 repeat i=i+1 xi ∈ neighborhood(x,ζ), fi = f(xi) if fi < fopt then xopt = xi,, fopt = fi if fi < f\ then x = xi,, f\ = fi else if xk ∉ M then x = xi,, f\ = fi update M with xk until loop condition is satisfied return xopt and fopt

From Evolution to Immune to Swarm to ... 11

The Algorithm
The TS algorithm is presented in Figure 5. A new solution is generated within the current solution’s neighborhood function neighborhood(x,ζ). If the new solution is better than the best solution found so far, it is accepted and saved as the best found. If the new solution is better than the current solution, it is accepted and saved as the current solution. If the new solution is not better than the current solution and it is not in a direction within the tabu list M, it is accepted as the current solution and the search continues from there. If the solution is tabu, the current solution remains unchanged and a new solution is generated. After accepting a solution, M is updated to forbid returning to this solution again. The list M can be a list of the solutions visited in the last n iterations. However, this is a memory-consuming process and it is a limited type of memory. Another possibility is to define the neighborhood in terms of a set of moves. Therefore, instead of storing the solution, the reverse of the move, which produced this solution, is stored instead. Clearly, this approach prohibits, not only returning to where we came from, but also many other possible solutions. Notwithstanding, since the tabu list is a short-term memory list, at some point in the search, the reverse of the move will be eliminated from the tabu list, therefore, allowing to explore this part of the search space which was tabu. A very important parameter here, in addition to the neighborhood length which is a critical parameter for many other heuristics such as SA, is the choice of the tabulist size which is referred to in the literature as the adaptive memory. This is a problem-dependent parameter, since the choice of a large size would be inefficient in terms of memory capacity and the time required to scan the list. On the other hand, choosing the list size to be small would result in a cycling problem; that is, revisiting the same state again (Glover, 1989). In general, the tabu-list’s size is a very critical issue for the following reasons: 1. The performance of tabu search is sensitive to the size of the tabu-list in many cases. 2. There is no general algorithm to determine the optimal tabu-list size apart from experimental results. 3. Choosing a large tabu-list is inefficient in terms of speed and memory.

GENETIC ALGORITHM
The previous heuristics move from a single solution to another single solution, one at a time. In this section, we introduce a different concept where we have a population of solutions and we would like to move from one population to another. Therefore, a group of solutions evolve towards the good area(s) in the search space. In trying to understand evolutionary mechanisms, Holland (1998) devised a new search mechanism, which he called a genetic algorithm, based on Darwin’s (1859) principle of natural selection. In its simple form, a genetic algorithm

12 Abbass

recursively applies the concepts of selection, crossover, and mutation to a randomly generated population of promising solutions with the best solution found being reported. In a comparison to analytical optimization techniques (Goldberg,1989), a number of strings are generated with each finite-length string representing a solution vector coded into some finite alphabet. Instead of using derivatives or similar information, as in analytical optimization techniques, the fitness of a solution is measured relative to all other solutions in the population, and natural operators, such as crossover and mutation, are used to generate new solutions from existing ones. Since GA is contingent upon coding the parameters, the choice of the right representation is a crucial issue (Goldberg, 1989). In its early stage, Holland (1998) coded the strings in GA using the binary set of alphabets {0,1}, that is the binary representation. He introduced the Schema Theorem, which provides a lower bound on the change in the sampling rate for a hyperplane (representing a group of adjacent solutions) from one generation to another. A schema is a subset of the solution space whose elements are identical in particular loci. It is a building block that samples one or more hyperplanes. Other representations use integer or real numbers. A generic GA algorithm is presented in Figure 6.

Reproduction strategies
A reproduction strategy is the process of building a population of individuals in a generation from a previous generation. There are a number of reproduction strategies presented in the literature, among them, canonical, simple, and breedN. Canonical GA (Whitley, 1994) is similar to Schwefel’s (1981) evolutionary strategy where the offspring replace all the parents; that is, the crossover probability is 1. In simple GA (Goldberg, 1989), two individuals are selected and the crossover occurs with a certain probability. If the crossover takes place, the offspring are placed in the Figure 6: A generic genetic algorithm let G denote a generation, P a population of size M, and xl the lth chromosome in P initialize the initial population PG=0 = {x1G=0, …, xMG=0} evaluate every xl ∈ PG=0, l = 1, …, M k=1 while the stopping criteria is not satisfied do select P\ (an intermediate population) from PG=k-1 PG=k ← crossover elements in P\ mutate elements in PG=k evaluate every xl ∈ PG=0, l = 1, …, M k = k+1 end while return the best encountered solution

From Evolution to Immune to Swarm to ... 13

new population; otherwise the parents are cloned. The breeder genetic algorithm (Mühlenbein and Schlierkamp-Voosen, 1993; Mühlenbein and Schlierkamp-Voosen 1994) or the breedN strategy is based on quantitative genetics. It assumes that there is an imaginary breeder who performs a selection of the best N strings in a population and breeds among them. Mühlenbein (1994) comments that if “GA is based on natural selection”, then “breeder GA is based on artificial selection.” Another popular reproduction strategy, the parallel genetic algorithm (Mühlenbein et al. 1988; Mühlenbein 1991), employs parallelism. In parallel GA, a number of populations evolve in parallel but independently, and migration occurs among the populations intermittently. A combination of the breeder GA and parallel GA is known as the distributed breeder genetic algorithm (Mühlenbein and Schlierkamp-Voosen 1993). In a comparison between parallel GA and breeder GA, Mühlenbein (1993) states that “parallel GA models evolution which self-organizes” but “breeder GA models rational controlled evolution.”

Selection
There are many alternatives for selection in GA. One method is based on the principle of “living for the fittest” or fitness-proportionate selection (Jong, 1975), where the objective functions’ values for all the population’s individuals are scaled and an individual is selected in proportion to its fitness. The fitness of an individual is the scaled objective value of that individual. The objective values can be scaled in differing ways, such as linear, sigma, and window scaling. Another alternative is the stochastic-Baker selection (Goldberg, 1989), where the objective values of all the individuals in the population are divided by the average to calculate the fitness, and the individual is copied into the intermediate population a number of times equal to the integer part, if any, of the fitness value. The population is then sorted according to the fraction part of the fitness, and the intermediate population is completed using a fitness-proportionate selection. Tournament selection is another famous strategy (Wetzel, 1983), where N chromosomes are chosen uniformly irrespective of their fitness, and the fittest of these is placed into the intermediate population. As this is usually expensive, a modified version called the modified tournament selection works by selecting an individual at random and up to N trials are made to pick a fitter one. The first fitter individual encountered is selected; otherwise, the first individual wins.

Crossover
Many crossover operators have been developed in the GA literature. Here, four crossover operators (one-point, two-point, uniform, and even-odd) are reported. To disentangle the explication, assume that we have two individuals that we would like to crossover, x = (x1,x2,…,xn) and y = (y1,y2,…,yn) to produce two children, c1 and c2. In one-point crossover (sometimes written 1-point) (Holland, 1998), a cut point, p1 , is generated at random in the range [1,n) and the corresponding parts to the

14 Abbass

right and left of the cut-point are swapped. Assuming that ρ1=2, the two children are formulated as c1= (x1,x2,y3,…,yn) and c2= (y1,y2,x3,…,xn). In two-point crossover (sometimes written 2-points) (Holland 1998; Jong 1975), two cut points, ρ1< ρ2, are generated at random in the range [1,n) and the two middle parts in the two chromosomes are interchanged. Assuming that, the two children are formulated as c1= (x1,y2,y3,y4,y5,x6,…,xn) and c2= (y1,x2,x3,x4,x5,y6,…,yn). In uniform crossover (Ackley 1987), for each two corresponding genes in the parents’ chromosomes, a coin is flipped to choose one of them (50-50 chance) to be placed in the same position as the child. In even-odd crossover, those genes in the even positions of the first chromosome and those in the odd positions of the second are placed in the first child and vice-versa for the second; that is, c1= (y1,x2,y3,…,xn) and c2= (x1,y2,x3,…,yn) assuming n is even.

Mutation
Mutation is a basic operator in GAs that introduces variation within the genetic materials, to maintain enough variations within the population, by changing the loci’s value with a certain probability. If an allele is lost due to selection pressure, mutation increases the probability of retrieving this allele again.

IMMUNE SYSTEMS
In biological immune systems (Hajela and Yoo 1999), type-specific antibodies recognize and eliminate the antigens (i.e., pathogens representing foreign cells and molecules). It has been estimated that the immune system is able to recognize at least 1016 antigens; an overwhelming recognition task given that the genome contains about 105 genes. For all possible antigens that are likely to be encountered, the immune system must use segments of genes to construct the necessary antibodies. For example, there are between 107 and 108 different antibodies in a typical mammal. In biological systems, this recognition problem translates into a complex geometry matching process. The antibody molecule region contains a specialized portion, the paratope, which is constructed from amino acids and is used for identifying other molecules. The amino acids determine the paratope as well as the antigen molecules’ shapes that can be attached to the paratope. Therefore, the antibody can have a geometry that is specific to a particular antigen. To recognize the antigen segment, a subset of the gene segments’ library is synthesized to encode the genetic information of an antibody. The gene segments act cooperatively to partition the antigen recognition task. In immune, an individual’s fitness is determined by its ability to recognize—through chemical binding and electrostatic charges—either a specific or a broader group of antigens.

The algorithm
There are different versions of the algorithms inspired by the immune system. This book contains two chapters about immune systems. In order to reduce the

From Evolution to Immune to Swarm to ... 15

overlap between the chapters, we will restrict our introduction to a simple algorithm that hybridizes immune systems and genetic algorithms. In 1998, an evolutionary approach was suggested by Dasgupta (1998) for use in the cooperative matching task of gene segments. The approach (Dasgupta, 1999) is based on genetic algorithms with a change in the mechanism for computing the fitness function. Therefore, in each GA generation, the top y% individuals in the population are chosen as antigens and compared against the population (antibodies) a number of times suggested to be twice the population size (Dasgupta, 1999). For each time, an antigen is selected at random from the set of antigens and compared to a population’s subset. A similarity measure (assuming a binary representation, the measure is usually the hamming distance between the antigen and each individual in the selected subset) is calculated for all individuals in the selected subset. Then, the similarity value for the individual which has the highest similarity Figure 7: The immune system algorithm let G denote a generation and P a population
 1  M P = 0 =  xG = 0 , K , xG = 0  G  

initialize the initial population of solutions evaluate every x l ∈ PG= 0 , l = 1,K , M compare_with_antigen_and_update_fitness(PG=0) k=1 while the stopping criteria is not satisfied do select P' (an intermediate population) from PG=k-1 mutate element in PG=k evaluate every xl ∈ PG=k, 1, ..., M compare _with_antigen_and_update_fitness (PG=k) k=k+1 return x=arg max l f (xl), xl ∈ PG=k, the best encountered solution procedure compare_with_antigen_and_update_fitness(PG=k) antigen=top y% in (PG=k) l=0 while l<2xM
antibodies ⊂ PG = k randomly select y ∈ antigen find x where similarity ( y, x ) = arg max x ximilarity ( y , x ), x ∈ antibodies add similarity( y, x ) to the fitness of x ∈ PG= k l =l +1

end procedure

16 Abbass

to the antigen is added to its fitness value and the process continues. The algorithm is presented in Figure 7. Different immune concepts inspired other computational models. For further information, the reader may wish to refer to Dasgupta, 1999).

ANT COLONY OPTIMIZATION
Ant Colony Optimization (ACO) (Dorigo and Caro, 1999) is a branch of a newly developed form of artificial intelligence called swarm intelligence. Swarm intelligence is a field which studies “the emergent collective intelligence of groups of simple agents” (Bonabeau et al., 1999). In groups of insects which live in colonies, such as ants and bees, an individual can only do simple tasks on its own while the colony’s cooperative work is the main reason determining the intelligent behavior it shows. Real ants are blind. However, each ant, while it is walking, deposits a chemical substance on the ground called pheromone (Dorigo and Caro, 1999). Pheromone encourages the following ants to stay close to previous moves. The pheromone evaporates with time to allow search exploration. In a couple of experiments presented by Dorigo et al. (1996), the complex behavior of the ants’ colony is illustrated. For example, a set of ants built a path to some food. An obstacle with two ends is then placed in their way where one end of the obstacle was more distant than the other. In the beginning, equal numbers of ants spread around the two ends of the obstacle. Since all ants have almost the same speed, the ants going around the nearer end of the obstacle return before the ants going around the farther end (differential path effect). With time, the amount of pheromone the ants deposit increases more rapidly on the shorter path and so more ants prefer this path. This positive effect is called autocatalysis. The difference between the two paths is called the preferential path effect and it is the cause of the pheromone between the two sides of the obstacle since the ants following the shorter path will make more visits to the source than those following the longer path. Because of pheromone evaporation, pheromone on the longer path vanishes with time.

The Algorithm
The Ant System (AS) (Dorigo et al., 1991) is the first algorithm based on the behavior of real ants for solving combinatorial optimization problems. The algorithm worked well on small problems but did not scale well for large-scale problems (Bonabeau et al., 1999). Many algorithms were developed to improve the performance of AS where two main changes were introduced. First, specialized local search techniques were added to improve the ants’ performance. Second, allowing ants to deposit pheromone while they are building up the solution in addition to the normal rule of AS where an ant deposits pheromone after completing a solution. A generic updated version of the ACO algorithm presented in Dorigo, M. and G. Caro (1999) is presented in Figure 8. In Figure 9, a conceptual diagram of the ACO algorithm is presented.

From Evolution to Immune to Swarm to ... 17

In the figures, the pheromone table is initialized with equal pheromones. The pheromone table represents that amount of pheromone deposited by the ants between two different states (i.e., nodes in the graph). Therefore, the table can be a square matrix with the dimension depending on the number of states (nodes) in the problem. While the termination condition is not satisfied, an ant is created and initialized with an initial state. The ant starts constructing a path from the initial state to its pre-defined goal state (generation of solutions, see Figure 9) using a probabilistic action choice rule based on the ant routing table. Depending on the pheromone update rule, the ant updates the ant routing table (reinforcement). This takes place either after each ant constructs a solution (online update rule) or after all ants have finished constructing their solutions (delayed update rule). In the following two sub-sections, different methods for constructing the ant routing table and pheromone update are given.

Figure 8: Generic ant colony optimization heuristic (Dorigo and Caro, 1999) procedure ACO_heuristic() initialize pheromone_table while (termination_criterion_not_satisfied) foreach ant k do initialize _ant (); M ← update _ant _memory (); Ω ← a set of problem's constraints while (current _state ≠ target _state) A=read _local _ant – routing _table (); P=compute _transition _probabilit ies (A, M, Ω) next _state = apply _ant _decision _policy (P, Ω) move _to _next _state (next _state); if (online _step _by _step _pheronome _update) then deposit _phermone _on _the _visited _arc (); update _ant _routing _table (); M ← update _int ernal _state (); if (online_delayed_pheromone_update) then foreach visited_arc do deposit _phermone _on _the _visited _arc (); update _ant _routing _table (); die(); update_thepheromone_table(); end procedure

18 Abbass

Figure 9: The ant algorithm
Initial data Action choice rule Local objective information

Reinforcement

Generation of solutions

Ant Routing Table (Action Choice Rule)
The ant routing table is a normalization of the pheromone table where the ant builds up its route by a probabilistic rule based on the pheromone available at each possible step and its memory. There are a number of suggestions in the literature for the probabilistic decision (the element in row i column j in the matrix A (Figure 8) representing the probability that the ant will move from the current state i to the next potential state j). The first is the following rule:

α ij =

∑

τ ij (t ) τ il (t )

(5)

l∈ N i

Here, the ant utilizes the pheromone information (τij is the pheromone between the current state i and the next potential state j) only to decide on its next step (Ni is the set of possible transitions from state i). This rule does not require any parameter settings, however it is a biased exploratory strategy that can quickly lead to stagnation. Another rule suggested by Dorigo, Maniezzo and Colorni (1991) is:

α ij =

∑

[τ ij (t )]α [η ij ]β
l∈N i

(6)
β

[τ ij (t )] [η ij ]

α

where we need two parameters α and β. The heuristic value ηij is used for the intensification of the search by means of a greedy behavior. For example, the heuristic value can be the immediate change in the objective resulting from increasing the value of a variable with 1 unit regardless of the effect of this increase on the overall solution. When β=1, α=0 the algorithm behaves like a local search and when β=0, α=1, stagnation may occur as previously mentioned. A balance is usually required between α (the pheromone information’s weight) and β (the local search’s weight). However, this rule is computationally expensive because of the exponents. As an attempt to overcome this, the following rule was suggested (Dorigo and Gambardella, 1997):

From Evolution to Immune to Swarm to ... 19

α ij =

∑

[τ ij (t )][η ij ]β
l∈N i

[τ il (t )][ηil ] β

(7)

where only one parameter β is used. Another alternative is to switch between any of the previous rules and the rule of choosing the transition with the maximum pheromone level, with some probability.

Pheromone update (reinforcement) rule
Each time a pheromone update is required, the ants use the following rule: (8) where ρ is a discount factor for pheromone evaporation, ij represents a transition between state i and state j, and k is the number of ants. A number of suggestions were used in the literature for calculating the rate of pheromone’s change ∆τkij(t-1). For example, in MMAS-QAP system,
k k k τ ij (t ) ← (1 − ρ )τ ij (t − 1) + ∆τ ij (t − 1), ∀ i, j , k

1/ J best if ant k moves from state i to state j k (9) ∆ τ ij (t − 1) =  otherwise 0 where Jbest is the objective value of the best solution found by the colony. We may note here that when the objective value increases, the rate of pheromone change decreases, enabling the search’s intensification. Another suggestion is to calculate ∆τkij(t-1) (Bonabeau et al., 1999) as follows:
∑ C / J k if ant k moves from state i to state j  k ∆ τ ij (t − 1) =  k∈K 0 otherwise 

(10)

where, K is the set of ants that visited transition ij, Jk is the objective value of the solution generated by ant k, C is a constant representing a lower bound on the solutions that will be generated by the algorithm. To summarize, at the beginning of the algorithm, the pheromone matrix is initialized. In each step, the pheromone matrix is normalized to construct the ant routing table. The ants generate a set of solutions (one solution per ant) by moving from a state to another using the action choice rule. Each element in the pheromone matrix is then updated using the pheromone update step and the algorithm continues.

CONCLUSION
In this chapter, we have introduced a set of heuristic search techniques. Although our coverage was very sparse, it provides the reader with the basics of this research area and points to useful references concerning these heuristics. Notwithstanding, there are many general purpose heuristics that have not been covered in

20 Abbass

this chapter, such as evolutionary strategies, evolutionary programming, genetic programming, scatter search, and quantum computing to name but a few. Nevertheless, the heuristics covered in this chapter are the basic ones, and most of the others can be easily followed if the readers have comprehended the material briefly described in this chapter.

ACKNOWLEDGMENT
The author would like to thank the reviewers of this chapter and the other editors for their insightful comments. Also, we owe a great deal to E. Kozan, M. Towsey, and J. Diederich for their insights on an initial draft of this chapter.

REFERENCES
Ackley, D. (1987). A connectionist machine for genetic hill climbing. Kluwer Academic Publisher. Ansari, N. and E. Hou (1997). Computational intelligence for optimization. Kluwer Academic Publisher. Bonabeau, E., M. Dorigo, and G. Theraulaz (1999). Swarm intelligence: from natural to artificial systems. Oxford Press. Darwin, C. (1859). The origins of species by means of natural selection. London, Penguin Classics. Dasgupta, D. (1998). Artificial immune systems and their applications. Springer-Verlag. Dasgupta, D. (1999). Information processing in immune system. In D. Corne, M. Dorigo, and F. Glover (Eds.), New ideas in optimization, pp. 161-166. McGraw-Hill. Dorigo, M. and G. Caro (1999). The ant colony optimization meta-heuristic. In D. Corne, M. Dorigo, and F. Glover (Eds.), New ideas in optimization, pp. 11-32. McGraw-Hill. Dorigo, M. and L. Gambardella (1997). Ant colony system: a cooperative learning approach to the traveling salesman problem. IEEE Transactions on evolutionary computation 1, 53-66. Dorigo, M., V. Maniezzo, and A. Colorni (1991). Positive feedback as a search strategy. Technical Report 91-016, Deipartimento di Elettronica, politecnico do Milano, Italy. Dorigo, M., V. Maniezzo, and A. Colorni (1996). The ant system: optimization by a colony of cooperating agents. IEEE Transactions on Systems, Man, and Cybernetics 26(1), 113. Ferber, J. (1999). Multi-agent systems: an introduction to distributed artificial intelligence. Addison-Wesley. Glover, F. (1989). Tabu search: Part 1. ORSA Journal on Computing 1(3), 190-206. Glover, F. (1990). Tabu search: Part 2. ORSA Journal on Computing 2(1), 4-32. Goldberg, D. (1989). Genetic algorithms: in search, optimization and machine learning. Addison Wesley. Hajela, P. and J. Yoo (1999). Immune network modeling in design optimization. In D. Corne, M. Dorigo, and F. Glover (Eds.), New ideas in optimization, pp. 203-216. McGraw-Hill. Holland, J. (1998). Adaptation in natural and artificial systems. MIT Press. Jong, K. D. (1975). An analysis of the behavior of a class of genetic adaptive systems. PhD thesis, University of Michigan. Kirkpatrick, S., D. Gelatt, and M. Vecchi (1983). Optimization by simulated annealing. Science 22, 671-680.

From Evolution to Immune to Swarm to ... 21

Laidlaw, H. and R. Page (1986). Mating Designs. In T. Rinderer (Ed.), Bee Genetics and Breeding, pp. 323-341. Academic Press, Inc. Maniezzo, V. (1998). Exact and approximate nondeterministic tree-search procedures for the quadratic assignment problem. Technical Report CSR 98-1, Corso di Laurea in Scienze dell’Informazione, Universit di Bologna, Sede di Cesena, Italy. Metropolis, N., A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller (1953). Equations of state calculations by fast computing machines. Chemical Physics 21, 1087–1092. Mühlenbein, H. (1991). Evolution in time and space: the parallel genetic algorithm. In G. Rawlins (Ed.), Foundations of Genetic Algorithms, pp. 316-337. San Mateo, CA: Morgan-Kaufman. Mühlenbein, H., M. Gorges-Schleuter, and O. Krämer (1988). Evolutionary algorithms in combinatorial optimization. Parallel Computing 7, 65–88. Mühlenbein, H. and D. Schlierkamp-Voosen (1993). Predictive models for the breeder genetic algorithms: continuous parameter optimization. Evolutionary Computation 1(1), 25–49. Mühlenbein, H. and D. Schlierkamp-Voosen (1994). The science of breeding and its application to the breeder genetic algorithm bga. Evolutionary Computation 1 (4), 335– 360. Rodrigues, M. and A. Anjo (1993). On simulating thermodynamics. In R. Vidal (Ed.), Applied Simulated annealing. Springer-Verlag. Ross, P. (1996). Genetic algorithms and genetic programming: Lecturer Notes. University of Edinburgh, Department of Artificial Intelligence. Schwefel, H. (1981). Numerical optimization of computer models. Wiler, Chichester. Simon, H. (1960). The new science of management decisions. Harper and Row, New York. Storn, R. and K. Price (1995). Differential evolution: a simple and efficient adaptive scheme for global optimization over continuous spaces. Technical Report TR-95-012, International Computer Science Institute, Berkeley. Turban, E. (1990). Decision support and expert systems: management support systems. Macmillan series in information systems. Vidal, R. (1993). Applied simulated annealing. Springer-Verlag. Wetzel, A. (1983). Evaluation of the effectiveness of genetic algorithms in combinatorial optimization. Technical report, University of Pittsburgh. Whitley, D. (1994). A genetic algorithm tutorial. Statistics and Computing 4, 65–85.

22 Estivill-Castro and Houle

Chapter II

Approximating Proximity for Fast and Robust Distance-Based Clustering
Vladimir Estivill-Castro, University of Newcastle, Australia Michael E. Houle, University of Sydney, Australia

Distance-based clustering results in optimization problems that typically are NP-hard or NP-complete and for which only approximate solutions are obtained. For the large instances emerging in data mining applications, the search for high-quality approximate solutions in the presence of noise and outliers is even more challenging. We exhibit fast and robust clustering methods that rely on the careful collection of proximity information for use by hill-climbing search strategies. The proximity information gathered approximates the nearest neighbor information produced using traditional, exact, but expensive methods. The proximity information is then used to produce fast approximations of robust objective optimization functions, and/or rapid comparison of two feasible solutions. These methods have been successfully applied for spatial and categorical data to surpass well-established methods such as k-MEANS in terms of the trade-off between quality and complexity.

INTRODUCTION
A central problem in data mining is that of automatically summarizing vast amounts of information into simpler, fewer and more comprehensible categories. The most common and well-studied way in which this categorizing is done is by
Copyright © 2002, Idea Group Publishing.

Approximating Proximity for Fast and Robust Distance-Based Clustering 23

partitioning the data elements into groups called clusters, in such a way that members of the same cluster are as similar as possible, and points from different clusters are as dissimilar as possible. By examining the properties of elements from a common cluster, practitioners hope to discover rules and concepts that allow them to characterize and categorize the data. The applications of clustering to knowledge discovery and data mining (KDDM) (Fayyad, Reina, & Bradley, 1998; Ng & Han, 1994; Wang, Yang, & Muntz, 1997) are recent developments in a history going back more than 30 years. In machine learning classical techniques for unsupervised learning are essentially those of clustering (Cheeseman et al, 1988; Fisher, 1987; Michalski & Stepp, 1983). In statistics, clustering arises in the analysis of mixture models, where the goal is to obtain statistical parameters of the individual populations (Titterington, Smith & Makov, 1985; Wallace & Freeman, 1987). Clustering methods appear in the literature of dimensionality reduction and vector quantization. Many textbooks have large sections devoted to clustering (Berry & Linoff, 1997; Berson & Smith, 1998; Cherkassky & Muller, 1998; Duda & Hart, 1973; Han & Kamber, 2000; Mitchell, 1997), and several are entirely devoted to the topic (Aldenderfer & Blashfield, 1984; Anderberg, 1973; Everitt, 1980; Jain & Dubes, 1998). Although different contexts give rise to several clustering methods, there is a great deal of commonality among methods themselves. However, not all methods are appropriate for all contexts. Here, we will concentrate only on clustering methods that are suitable for the exploratory and early stages of a KDDM exercise. Such methods should be: • Generic: Virtually every clustering method may be described as having two components: a search mechanism that generates candidate clusters, and an evaluation function that measures the quality of these candidates. In turn, an evaluation function may make use of a function that measures the similarity (or dissimilarity) between a pair of data points. Such methods can be considered generic if they can be applied in a variety of domains simply by substituting one measure of similarity for another. • Scalable: In order to handle the huge data sets that arise in KDDM applications, clustering methods must be as efficient as possible in terms of their execution time and storage requirements. Given a data set consisting of n records on D attributes, the time and space complexity of any clustering method for the set should be sub-quadratic in n, and as low as possible in D (ideally linear). In particular, the number of evaluations of the similarity function must be kept as small as possible. Clustering methods proposed in other areas are completely unsuitable for data mining applications, due to their quadratic time complexities. • Incremental: Even if the chosen clustering method is scalable, long execution times must be expected when the data sets are very large. For this reason, it is desirable to use methods that attempt to improve their solutions in an incremental fashion. Incremental methods allow the user to monitor their progress, and to terminate the execution early whenever a clustering of

24 Estivill-Castro and Houle

sufficient quality is found, or when it is clear that no suitable clustering will be found. • Robust: A clustering method must be robust with respect to noise and outliers. No method is immune to the effects of erroneous data, but it is a feature of good clustering methods that the presence of noise does not greatly affect the result. Finding clustering methods that satisfy all of these desiderata remains one main challenge in data mining today. In particular, very few of the existing methods are scalable to large databases of records having many attributes, and those that are scalable are not robust. In this work, we will investigate the trade-offs between scalability and robustness for a family of hill-climbing search strategies known to be both generic and incremental. We shall propose clustering methods that seek to achieve both scalability and robustness by mimicking the behavior of existing robust methods to the greatest possible extent, while respecting a limit on the number of evaluations of similarity between data elements. The functions that measure similarity between data points typically satisfy the conditions of a metric. For this reason, it is convenient to think of the evaluation of these functions in terms of nearest-neighbor calculations in an appropriate metric space. We will see how the problem of efficiently finding a robust clustering can essentially be reduced to that of efficiently gathering proximity information. We will propose new heuristics that gather approximate but useful nearest-neighbor information while still keeping to a budget on the number of distance calculations performed. Although these heuristics are developed with data mining and interchange hillclimbers in mind, they are sufficiently general that they can be incorporated into other search strategies. Our nearest-neighbor heuristics will be illustrated in examples involving both spatial data and categorical data. We shall now briefly review some of the existing clustering methods and search strategies.

Overview of Clustering Methods
For exploratory data mining exercises, clustering methods typically fall into two main categories, agglomerative and partition-based.

Agglomerative clustering methods
Agglomerative clustering methods begin with each item in its own cluster, and then, in a bottom-up fashion, repeatedly merge the two closest groups to form a new cluster. To support this merge process, nearest-neighbor searches are conducted. Agglomerative clustering methods are often referred to as hierarchical methods for this reason. A classical example of agglomerative clustering is the iterative determination of the closest pair of points belonging to different clusters, followed by the merging of their corresponding clusters. This process results in the minimum spanning tree (MST) structure. Computing an MST can be performed very quickly. However, because the decision to merge two clusters is based only on information provided

Approximating Proximity for Fast and Robust Distance-Based Clustering 25

by a single pair of points, the MST generally provides clusters of poor quality. The first agglomerative algorithm to require sub-quadratic expected time, albeit in low-dimensional settings, is DBSCAN (Ester, Kriegel, Sander, & Xu, 1996). The algorithm is regulated by two parameters, which specify the density of the clusters to be retrieved. The algorithm achieves its claimed performance in an amortized sense, by placing the points in an R*-tree, and using the tree to perform u-nearest-neighbor queries, u is typically 4. Additional effort is made in helping the users determine the density parameters, by presenting the user with a profile of the distances between data points and their 4-nearest neighbors. It is the responsibility of the user to find a valley in the distribution of these distances; the position of this valley determines the boundaries of the clusters. Overall, the method requires Q(n log n) time, given n data points of fixed dimension. Another subfamily of clustering methods impose a grid structure on the data (Chiu, Wong & Cheung, 1991; Schikuta, 1996; Wang et al, 1997; Zhang, Ramakrishnan, & Livny, 1996). The idea is a natural one: grid boxes containing a large number of points would indicate good candidates for clusters. The difficulty is in determining an appropriate granularity. Maximum entropy discretization (Chiu et al., 1991) allows for the automatic determination of the grid granularity, but the size of the grid generally grows quadratically in the number of data points. Later, the BIRCH method saw the introduction of a hierarchical structure for the economical storage of grid information, called a Clustering Feature Tree (CF-Tree) (Zhang et al., 1996). The recent STING method (Wang et al., 1997) combines aspects of these two approaches, again in low-dimensional spatial settings. STING constructs a hierarchical data structure whose root covers the region of analysis. The structure is a variant of a quadtree (Samet, 1989). However, in STING, all leaves are at equal depth in the structure, and represent areas of equal size in the data domain. The structure is built by finding information at the leaves and propagating it to the parents according to arithmetic formulae. STING’s data structure is similar to that of a multidimensional database, and thus can be queried by OLAP users using an SQLlike language. When used for clustering, the query proceeds from the root down, using information about the distribution to eliminate branches from consideration. As only those leaves that are reached are relevant, the data points under these leaves can be agglomerated. It is claimed that once the search structure is in place, the time taken by STING to produce a clustering will be sub-linear. However, determining the depth of the structure is problematic. STING is a statistical parametric method, and as such can only be used in limited applications. It assumes the data is a mixture model and works best with knowledge of the distributions involved. However, under these conditions, nonagglomerative methods such as EM (Dempster, Laird & Rubin, 1977), AutoClass (Cheeseman et al, 1988), MML (Wallace & Freeman, 1987) and Gibb’s sampling are perhaps more effective. For clustering two-dimensional points, O(n log n) time is possible (Krznaric & Levcopoulos, 1998), based on a data structure called a dendrogram or proximity

26 Estivill-Castro and Houle

tree, which can be regarded as capturing the history of a merge process based on nearest-neighbor information. Unfortunately, such hierarchical approaches had generally been disregarded for knowledge discovery in spatial databases, since it is often unclear how to use the proximity tree to obtain associations (Ester et al, 1996). While variants emerge from the different ways in which the distance between items is extended to a distance between groups, the agglomerative approach as a whole has three fundamental drawbacks. First, agglomeration does not provide clusters naturally; some other criterion must be introduced in order to halt the merge process and to interpret the results. Second, for large data sets, the shapes of clusters formed via agglomeration may be very irregular, so much so that they defy any attempts to derive characterizations of their member data points. Third, and perhaps the most serious for data mining applications, hierarchical methods usually require quadratic time when applied in general dimensions. This is essentially because agglomerative algorithms must repeatedly extract the smallest distance from a dynamic set that originally has a quadratic number of values.

Partition-based clustering methods
The other main family of clustering methods searches for a partition of the data that best satisfies an evaluation function based on a given set of optimization criteria. Using the evaluation function as a guide, a search mechanism is used to generate good candidate clusters. The search mechanisms of most partition-based clustering methods are variants of a general strategy called hill-climbing. The essential differences among partition-based clustering methods lie in their choice of optimization criteria. The optimization criteria of all partition-based methods make assumptions, either implicitly or explicitly, regarding the distribution of the data. Nevertheless, some methods are more generally applicable than others in the assumptions they make, and others may be guided by optimization criteria that allow for more efficient evaluation. One particularly general optimization strategy is that of expectation maximization (EM) (Dempster et al., 1977), a form of inference with maximum likelihood. At each step, EM methods search for a representative point for each cluster in a candidate cluster. The distances from the representatives to the data elements in their clusters are used as estimates of the error in associating the data elements with this representative. In the next section, we shall focus on two variants of EM, the first being the well-known and widely used k-MEANS heuristic (MacQueen, 1967). This algorithm exhibits linear behavior and is simple to implement; however, it typically produces poor results, requiring complex procedures for initialization (Aldenderfer & Blashfield, 1984; Bradley, Fayyad, & Reina, 1998; Fayyad et al., 1998). The second variant is k-MEDOIDS, which produces clusters of much higher quality, but requires quadratic time. Another partition-based clustering method makes more assumptions regarding the underlying distribution of the data. AutoClass (Cheeseman et al., 1998) partitions the data set into classes using a Bayesian statistical technique. It requires

Approximating Proximity for Fast and Robust Distance-Based Clustering 27

an explicit declaration of how members of a class should be distributed in order to form a probabilistic class model. AutoClass uses a variant of EM, and thus is a randomized hill-climber similar to k-MEANS, with additional techniques for escaping local maxima. It also has the capability of identifying some data points as noise. Similarly, minimum message length (MML) methods (Wallace & Freeman, 1987) require the declaration of a model. The declaration allows an encoding of parameters of a statistical mixture model; the second part of the message is an encoding of the data given these statistical parameters. There is a trade-off between the complexity of the MML model and the quality of fit to the data. There are also difficult optimization problems that must be solved heuristically when encoding parameters in the fewest number of bits. One of the advantages of partition-based clustering is that the optimization criteria lend themselves well to interpretation of the results. However, the family of partition-based clustering strategies includes members that require linear time as well as other members that require more than quadratic time. The main reason for this variation lies in the complexity of the optimization criteria. The more complex criteria tend to be more robust to noise and outliers, but also more expensive to compute. Simpler criteria, on the other hand, may have more local optima where the hill-climber can become trapped.

Nearest-neighbor searching
As we can see, many if not most clustering methods have at their core the computation of nearest neighbors with respect to some distance metric d. To conclude this section, we will formalize the notion of distance and nearest neighbors, and give a brief overview of existing methods for computing nearest neighbors. Let us assume that we have been given a set S={s1,…,sn} of n objects to be clustered into k groups, drawn from some universal set of objects X. Let us also assume that we have been given a function d:X×X→ℜ for measuring the pairwise similarity between objects of X. If the objects of X are records having D attributes (numeric or otherwise), the time taken to compute d would be independent of n, but dependent on D. The function d is said to be a metric if it satisfies the following conditions: 1. Non-negativity: x,y∈X, d(x,y)>0 whenever x≠y, and d(x,y)=0 whenever x=y. 2. Symmetry: x,y∈X, d(x,y)=d(y,x). 3. Triangular inequality: x,y,z∈X, d(x,z)≤d(x,y)+d(y,z). Metrics are sometimes called distance functions or simply distances. Wellknown metrics include the usual Euclidean distance and Manhattan distances in spatial settings (both special cases of the Lagrange metric), and the Hamming distance in categorical settings. Formally, a nearest neighbor of s∈S is an element a∈S such that d(s,a)≤d(s,b) for all b∈X, a≠b. The notion can be extended to that of a u-nearest-neighbor set

28 Estivill-Castro and Houle

NNu(s)={a1,a2,…,au}, where d(s,ai)≤d(s,b) for all b∈S\NNu(s). Computation of nearest and u-nearest neighbors are well-studied problems, with applications in such areas as pattern recognition, content-based retrieval of text and images, and video compression, as well as data mining. In two-dimensional spatial settings, very efficient solutions based on the Delaunay triangulation (Aurenhammer, 1991) have been devised, typically requiring O(log n) time to process nearest-neighbor queries after O(n log n) preprocessing time. However, the size of Delaunay structures can be quadratic in dimensions higher than two. For higher-dimensional vector spaces, again many structures have been proposed for nearest-neighbor and range queries, the most prominent ones being kdtrees (Bentley, 1975, 1979), quad-trees (Samet, 1989), R-trees (Guttmann, 1984), R*-trees (Beckmann, Kriegel, Schneider & Seeger, 1990), and X-trees (Berchtold, Keim, & Kriegel, 1996). All use the coordinate information to partition the space into a hierarchy of regions. In processing a query, if there is any possibility of a solution element lying in a particular region, then that region must be searched. Consequently, the number of points accessed may greatly exceed the number of elements sought. This effect worsens as the number of dimensions increases, so much so that the methods become totally impractical for high-dimensional data mining applications. In their excellent survey on searching within metric spaces, Chávez, Navarro, Baeza-Yates and Marroquín (1999) introduce the notion of intrinsic dimension, which is the smallest number of dimensions in which the points may be embedded so as to preserve distances among them. They claim that none of these techniques can cope with intrinsic dimension more than 20. Another drawback of these search structures is that the Lagrange similarity metrics they employ cannot take into account any correlation or ‘cross-talk’ among the attribute values. The M-tree search structure (Ciaccia, Patella & Zezula, 1997) addresses this by organizing the data strictly according to the values of the metric d. This generic structure is also designed to reduce the number of distance computations and page I/O operations, making it more scalable than structures that rely on coordinate information. However, the M-tree still suffers from the ‘curse of dimensionality’ that prevents all these methods from being effective for higherdimensional data mining. If one were to insist (as one should) on using only generic clustering methods that were both scalable and robust, a reasonable starting point would be to look at the optimization criteria of robust methods, and attempt to approximate the choices and behaviors of these methods while still respecting limits on the amount of computational resources used. This is the approach we take in the upcoming sections.

Optimization Criteria
Some of the most popular clustering strategies are based on optimization criteria whose origins can be traced back to induction principles from classical statistics. Such methods appeal to the user community because their goals and

Approximating Proximity for Fast and Robust Distance-Based Clustering 29

choices can be explained in light of these principles, because the methods are largely easy to implement and understand, and often because the optimization functions can be evaluated quickly. However, the optimization criteria generally have not been designed with robustness in mind, and typically sacrifice robustness for the sake of simplicity and efficiency. In this section, we will look at some optimization criteria derived from statistical induction principles, and show how the adoption of some of these criteria has led to problems with robustness. We begin by examining a classical distance-based criterion for representativebased clustering. Assuming the data is a set of attribute-vectors S={s1,…,sn}, the statistical theory of multivariate analysis of variance suggests the use of the total scatter matrix T (Duda & Hart, 1963) for evaluating homogeneity, based on the use of the mean as an estimator of location. Formally, the matrix is T = Σi=1,..,n (si-µ)(siµ)T, where µ is the total observed mean vector; that is, µ =Si=1,..,n si/n. Similarly, the scatter matrix TCj of a cluster Cj is simply TCj =Ssi∈Cj (si-µj)(si-µj)T, where µj is the observed mean vector of Cj . Each cluster scatter matrix captures the variance – or dissimilarity – of the cluster with respect to its representative, the mean. One can thus use as a clustering goal the minimization of the sum of some function of the cluster scatter matrices, where the function attempts to capture the overall magnitude of the matrix elements. Although one is tempted to take into account all entries of the matrix, this would result in a quadratic number of computations, too high for data mining purposes. A traditional and less costly measure of the magnitude is the trace, which for a symmetric matrix is simply the sum of the elements along its diagonal. The sum of the traces of the cluster scatter matrices is exactly the least sum of squares loss function (known in the statistics literature as L2 [Rousseeuw & Leroy, 1987]): (1) L2(C) = Σi=1,..,n Euclid2 (si, rep[si,C]) where Euclid (x,y)=[(x--y)(x--y)T]1/2 is the Euclidean metric C={c1,...,ck} is a set of k centers, or representative points of ℜD; and i=1,&\...,n, rep[si,C] is the closest representative point in C to si. The optimization problem is then to minimize L2(C). Note that Equation (1) measures the quality of a set C of k cluster representatives, according to the partition into clusters defined by assigning each si to its rep[si,C]. The minimum value is achieved when the cluster representatives coincide with the cluster means. It is interesting that seeking to minimize the variance within a cluster leads to the evaluation of Euclidean distances. While the proponents of robust statistics (Rousseeuw and Leroy,1987) attribute this to the relationship of the Euclidean distance to the standard normal distribution, others point to the fact that Equation (1) corresponds to minimizing the sum of the average squared Euclidean distance between cluster points and their representatives (Duda & Hart, 1973): that is, if S1,…,Sk denotes a partition of S, then the problem of minimizing Equation (1) is equivalent to minimize L2(S1,…,Sk) = Σj=1,..,k 1// ||Sj || Σsi∈Sj Σsi’∈Sj Euclid2(si,si’). (2) Note that this last criterion does not explicitly rely on the notion of a representative point. Thus, when the metric is the Euclidean distance, we find that

30 Estivill-Castro and Houle

minimizing the intra-cluster pairwise squared dissimilarity is equivalent to minimizing the expected squared dissimilarity between items and their cluster representative. This property seems to grant special status to the use of sums of squares of the Euclidean metric, and to heuristics such k-MEANS that are based upon them. This relationship does not hold for general metrics. The literature has proposed many iterative heuristics for computing approximate solutions to Equation (1), and to Equation (2) (Anderberg, 1973; Duda & Hart, 1973; Hartigan, 1975; Späth, 1980). All can be considered variants of the k-MEANS heuristic (MacQueen, 1967), which is in turn a form of expectation maximization (EM) (Dempster et al., 1977). The generic maximization step in EM involves estimating the distance of each data point to a representative, and using this estimate to approximate the probability of being a member of that cluster. In each iteration of k-MEANS, this is done by: 1. Given a set C of k representatives, assigning each data point to its closest representative in C. 2. For each cluster Sj in the resulting partition, replacing its representative in C by the arithmetic mean of its elements, s = Σsi∈Sj si/ / ||Sj||. One point of concern is that the Euclidean metric is biased towards spherical clusters. Of more concern is that using the squares of Euclidean distances, rather than (say) the unsquared distances, renders the algorithms far more sensitive to noise and outliers, as their contribution to the sum is proportionally much higher. For exploratory data mining, it is more important that the clustering method be robust and generic, than for the cluster representatives to be generated by strict adherence to statistical principles. It stands to reason that effective clustering methods can be devised by reworking existing optimization criteria to be more generic and more robust. Still, it is not immediately clear that these methods can compete in computational efficiency with k-MEANS.

Problems and Solutions
We will investigate two optimization criteria related to Equations (1) and (2), one representative-based and the other non-representative-based. After formally defining the problems and their relationship with k-MEANS, we discuss heuristic solutions. Although the heuristics are inherently more generic and robust than kMEANS, the straightforward use of hill-climbers leads to quadratic-time performance. We then show how scalability can be achieved with little loss of robustness by restricting the number of distance computations performed. The first optimization criterion we will study follows the form of Equation (1), but with three important differences: (1) unsquared distance is used instead of squared distance; (2) metrics other than the Euclidean distance may be used; and (3) cluster representatives are restricted to be elements of the data set. This third condition ensures that each representative can be interpreted as a valid, ‘typical’ element of its cluster. It also allows the method to be applied to categorical data as well as spatial data. With this restriction on the representatives, the problem is no

Approximating Proximity for Fast and Robust Distance-Based Clustering 31

longer one of continuous optimization (where solutions may not even be computable (Estivill-Castro & Yang, 2000)), but rather one of discrete optimization. From the perspective of spatial statistics, the formulation below is simply a replacement of means by medians (a much more robust estimator of location), and the L2 loss function by the L1 loss function (Rousseeuw & Leroy, 1987). Definition 1 Let S={s1,s2,…,sn}⊆X be a set of n objects and let d:X×X→ℜ≥0 be a metric on X. The L1-problem is: = Σi=1,..,n wi d(si, rep[si,C]), (3) minimize L1(C) = Σj=1,..,n Σsi∈Si wi d(si,cj), where C={c1,…,ck}⊂S is a set of k centers in S, wi is a weight for the relevance of si, the point rep[si,C] is the closest point in C to si, and Sj is the set of elements having cj as its closest representative; that is Sj={si∈S | rep[si,C]=cj}. The problem was first introduced to the data mining literature by Ng and Han (1994) as medoid clustering, although it was in fact already well known to researchers in facility location as the p-median problem (Densham & Rushton, 1992; Rosing, ReVelle & Rosing-Voyelaar, 1979). It can also be viewed as a generalization of other representative-based EM variants for the Euclidean and other metrics. Examples include the Generalized Lloyd Algorithm (GLA) [Cherkassky & Muller, 1998], fuzzy-c-clustering (Cherkassky & Muller, 1998; Hall, Özyurt & Bezdek, 1999) and k-C-L1-MEDIANS (Bradley, Mangasarian, & Street, 1997; Estivill-Castro & Yang, 2000). The second optimization criterion we will investigate attempts to minimize the total pairwise dissimilarity within clusters in the same fashion as Equation (2), but again with the metric values unsquared. This criterion has been studied by researchers since the 1960s, under such names as the Grouping (Vinod, 1969), the FullExchange (Rosing & ReVelle, 1986) the Interaction (Murray and Estivill-Castro, 1998), and the Total Within-Group Distance(TWGD) (Rao, 1971). Here we will refer to this criterion as TWGD, as this latter term seems to be the best description of the measure. Definition 2 Let S={s1,s2,…,sn} be a set of n objects and d:X×X→ℜ≥0 be a metric (which is symmetric). The TWGD problem is: (4) minimize TWGD(P) = Σm=1,..,k Σi<j∧ si,sj∈Sm wi wj d(si,sj), where P= Si|…|Sk is a partition of S and wi is a weight for the relevance of si, but which may have other specific interpretations. Intuitively, this criterion not only minimizes the dissimilarity between items in a group, but also uses all interactions between items in a group to assess cohesiveness, (thus, uses all the available information). Also, it implicitly maximizes the distance between groups (and thereby minimizes coupling), since the terms d(si, sj) not included in the sum are those for which the items belong to different groups. However, the TWGD problem is NP-hard (Brucker, 1978; Krivánek, 1986). One interesting aspect of TWGD is that, even in Euclidean space, the optimal solution can be a partition where the convex hulls of the groups overlap. This is sometimes used to suggest the number k of groups.

32 Estivill-Castro and Houle

Hill-climbing strategies
Both the L1-problem (Def. 1) and the TWGD problem (Def. 2) are NP-hard discrete optimization problems. The techniques to be described are widely applicable to other loss functions. Thus, we will refer to a generic loss function L(P) based on a partition P of the data. Note that claims regarding L(P) will apply to L1(C) and TWGD(P). The minimization of L(P) is typically solved approximately using interchange heuristics based on a hill-climbing search strategy (Densham & Rushton,1992; Horn, 1996; Murray & Church, 1996; Murray, 2000; Teitz & Bart, 1968). Hillclimbers search the space of all partitions P=S1|…|Sk of S by treating the space as if it were a graph. Every node of the graph can be thought to correspond to a unique partition of the data; an edge exists between two nodes if the corresponding two partitions differ slightly. Typically, the difference involves the interchange or promotion of one item. For L1, two solutions (sets of k representatives) C and C’ are adjacent if they differ in exactly one representative (that is, ||C∩C’||=k—1). For the TWGD problem, two nodes P and P’ are adjacent if and only if their corresponding partitions coincide in all but one data point (clearly, the resulting graphs are connected). Interchange heuristics start at a randomly chosen solution P0, and explore by moving from the current solution to one of its neighbors. Letting Pt be the current solution at time step t, the heuristic examines a set N(Pt) of solutions neighboring Pt, and considers the best alternative to Pt in this neighborhood: the node for which L(Pt+1)= min P∈N(Pt) L(P). Provided that the new node Pt+1 is an improvement over the old (that is, if L(Pt+1)<L(Pt)), Pt+1 becomes the current node for time step t+1. Hillclimbers define the neighborhood set N(Pt) in varying ways (Kaufman & Rousseuw, 1990; Murray & Church, 1996; Ng & Han, 1994; Rolland, Schilling & Current, 1996). One general interchange heuristic, originally proposed for the L1-problem by Teitz and Bart (1968), is a hill-climber that is regarded as the best known benchmark (Horn, 1996). It has been remarkably successful in finding local optima of high quality in applications to facility location problems (Murray & Church, 1996; Rolland, et al, 1996), and very accurate for the clustering of large sets of lowdimensional spatial data (Estivill-Castro & Murray, 1998), even in the presence of noise or outliers. We refer to this heuristic as TAB. When searching for a profitable interchange, TAB considers the points in turn, according to a circular ordering (s1,s2,…,sn) of the data. Whenever the turn belonging to a point si comes up, it is used to determine a number of neighboring solutions. In the case of L1, provided that si is not already a representative, the feasible solutions in N(Pt) are constructed by swapping si with each of the k current representatives of CT. For TWGD, the data point si is considered for changing its group. The most advantageous interchange Pj of these alternatives is determined, and if it is an improvement over Pt, then Pj becomes the new current solution Pt+1; otherwise, Pt++1=Pt. In either case, the turn then passes to the next point in the circular list, si+1 (or s1 if i=n). If a full cycle through the data set yields no improvement, a local

Approximating Proximity for Fast and Robust Distance-Based Clustering 33

optimum has been reached, and the search halts. The TAB heuristic forbids the reconsideration of si for inclusion until all other data points have been considered as well. The heuristic can, therefore, be regarded as a local variant of Tabu search (Glover, 1986), whose design balances the need to explore possible interchanges against the ‘greedy’ desire to improve the solution as quickly as possible. We now begin our discussion of the computational complexity of interchange heuristics. First, in the case of TWGD, we note that given a current partition Pt and one of its k--1 neighbors Pj, a naive approach would compute TWGD(Pj) and TWGD(Pt) explicitly in order to decide whether TWGD(Pj)<TWGD(Pt). However, this would potentially require Θ(kn2) time, simply because Equation (4) shows that each cluster involves the sum of distances between all pairs. A more efficient way is to compute the discrete gradient ∇(Pt,Pj)=TWGD(Pt) - TWGD(Pj) for Pj∈N(Pt). since only si is changing its cluster membership. TWGD(Pt) and TWGD(Pj) differ only in O(n) terms, and therefore only O(n) evaluations of the distance metric are required to compute ∇(Pt,Pj). Therefore, the number of evaluations of the distance metric required to test all interchanges suggested by si is in O(kn). This bound is easily seen to hold for L1 as well. The generic TAB heuristic thus requires Ω(n2) time per complete scan through the list. At least one complete scan is needed for the heuristic to terminate, although empirical evidence suggests that the total number of scans is constant.

Limiting the number of distance computations
We have just presented a generic local search heuristic for two versions of distance-based clustering. Although the methods are robust, they require quadratic time. By limiting the total number of distance evaluations, the time cost can be substantially reduced. The first fundamental idea is to allow modifications to the objective functions that result in scalable new functions that still respect the optimization goals of the originals. As long as the approximation is sufficiently accurate for the operation of the hill-climber to be effective, the results will be satisfactory. To achieve this approximation, we note that the distance-based criteria attempt to evaluate the total weighted discrepancies in each cluster and then add them together. The L1 objective function measures the discrepancy between cluster items and their representatives, whereas the TWGD function can be seen as an assessment of the expected variance within a cluster. For the purposes of the hill-climber, it is enough to assess these functions approximately. The purpose of clustering is to identify subsets, each of whose records are highly similar to one another. Loss functions implicitly or explicitly assess whether near neighbors of points have been assigned to the same cluster: the more points grouped in the same cluster as its near neighbors, the better the clustering. However, the greatest individual contributions to that portion of the loss function L(P) associated with a cluster Sj are made by outliers assigned to Sj, records which exhibit the least similarities to other records, and which often should not be considered to

34 Estivill-Castro and Houle

be part of any cluster. To eliminate the inappropriate contributions of outliers towards the expected discrepancy within clusters, the strategy we adopt is to estimate the expected discrepancy among non-outlier points only. Instead of finding a clustering which best summarizes the entire set of points S, we propose that clusterings be found that best represent the sets of points in their own vicinities. In order to be able to efficiently determine the set of those points in the vicinity of a given data item, we preprocess the full set of n records as follows: 1. For each si∈S, we find u records that rank highly among the nearest neighbors of si. 2. We construct a proximity directed graph PD(S) of regular out-degree u, with the s1,…,sn as nodes. Two records si and si’ in the proximity digraph are adjacent if si’ is one of the u records found to be close to si in the previous step. The adjacency representation of this regular graph has O(un) size. 3. In order to avoid a potential bias from the use of local information, we also construct a random influence graph RI(S) of regular degree r having node set S. The r nodes adjacent to si in RI(S) are chosen randomly from S. During the hill-climbing process, whenever the hill-climber evaluates a candidate solution si, the computation of distances will ordinarily be restricted to those with the nodes in its adjacency lists in PD(S) and RI(S). However, since two data items may share neighbors PD(S), the situation may arise where fewer than uk+ρk nearby records may be evaluated. In order for the hill-climber not to be attracted simply to sets with fewer neighbors in the proximity digraph, two strategies can be applied to pad the number of evaluations out to exactly uk+ρk: 1. Fill the quota of uk+ρk items by randomly selecting from the remaining items. 2. Fill the quota from among the records of the proximity graph by repeatedly adding the largest distance contribution as many times as is necessary. In our implementations, we have opted for the latter strategy to assure convergence. Unlike the former strategy, the latter is deterministic, and preserves the hill-climbing nature of TAB. The time required by the hill-climber is typically much less than the time required to build the graphs PD(S) and RI(S) in high-dimensional settings, where the cost of distance computation dominates. The total number of distances needed would be at most un++ρn, and if the graphs are pre-computed, no distance would be evaluated more than once. Nevertheless, it can be advantageous to generating the random influence graph during the hill-climbing process, as continual sampling can result in a clustering of better quality. However, care must be taken to control any oscillations that would prevent convergence. One way would be to gradually reduce the effect of RI(S) by reducing the value of ρ in later iterations of the algorithm, in a manner similar to simulated annealing. In what follows, we assume that ρ is chosen to be commensurate with u. We are now left with the problem of efficiently computing a list of near neighbors for each of the data elements. To complete the description of our

Approximating Proximity for Fast and Robust Distance-Based Clustering 35

approach, we will examine how this can be accomplished in three different contexts: two-dimensional spatial data, categorical data in low dimensions and generic data sets in higher dimensions.

Low-dimensional spatial data
In the two-dimensional spatial setting, we need only be concerned with the scalability of clustering methods with respect to n, the number of records. Still, care must be taken to avoid paying quadratic time in computing the approximate nearneighbor information required for the hill-climber methods we have just seen. For this exercise, we will consider only the L1-problem. Given a set of data points S={s1,…,sn} in the two-dimensional Euclidean space ℜ2, the Voronoi region of si∈S is the locus of points of ℜ2 that have si as a nearest neighbor; that is {x∈ℜ2 |∀. i’≠i, d(x,si) ≤ d(x,si’)}. Taken together, the n Voronoi regions of S form the Voronoi diagram of S (also called the Dirichlet tessellation or the proximity map). The regions are (possibly unbounded) convex polygons, and their interiors are disjoint. The Delaunay triangulation D(S) of S is a planar embedding of a graph defined as follows: the nodes of D(S) consist of the data points of S, and two nodes si and si’ are joined by an edge if the boundaries of the corresponding Voronoi regions share a line segment. Delaunay triangulations capture in a very compact form the proximity relationships among the points of S. They have many useful properties (Okabe, Boots, & Sugihara, 1992; O’Rourke, 1994), some of which are: 1. The 1-nearest neighbor digraph is a subgraph of the Delaunay triangulation. 2. The number of edges in D(S) is at most 3n-6. 3. The triangulation D(S) can be robustly computed in O(n log n) time. 4. The minimum spanning tree is a subgraph of the Delaunay triangulation. Under the Euclidean distance, the u nearest neighbors of a point si can be found via a search in D(S) in O(u log u) expected time (Dickerson, Drysdale, & Sack, 1992). The algorithm is simple and practical. Place the Delaunay neighbors of si∈S in a priority queue using Euclidean distances to si as key values. Repeatedly extract the item with smallest key and insert its yet-unexamined Delaunay neighbors into the priority queue. When u items have been extracted, then terminate; these are the u-nearest neighbors. The construction of PD(S) can be accomplished in sub-quadratic time. The total time required to generate u neighbors for each data point si is in O(un log u), and Θ(n log n) time is required for computing a Delaunay triangulation. Choosing u to be in Θ(log n / log log n) allows the proximity directed graph PD(S) to be constructed in O(n log n) total time. Thereafter, each evaluation of L(C) would take Θ(k log n / log log n) time. The total time bound simplifies to O(kn log n) per complete scan of TAB, and since the number of complete scans is typically constant, the overall observed complexity is O(kn log n). Of course, the user is free to choose larger or smaller values of u. The larger the value of u, the closer the performance becomes to that of the original TAB heuristic,

36 Estivill-Castro and Houle

and the more time is taken. Small choices of u result in very fast execution times, at the cost of a degradation in quality. In practice, the user could base the choice of u according to a time budget. Even when u is chosen to be very small, experimental evaluation of the implementation of this hill-climber variant shows that the method is much more robust to noise and outliers than k-MEANS, even if k-MEANS is given the advantage of an initial clustering based on the MST (Estivill-Castro & Houle, forthcoming).

Categorical data with Hamming distance
We next consider the situation for categorical data, where the dimension D of the set is relatively low. For this example, we will assume the use of the Hamming distance as the metric, defined as follows: Hamming(x,y) = Σj=1,..,D χ(xj,yj), where χ(xj,yj) equals 1 if xj≠yj, and equals 0 otherwise. The method we shall present scales well in terms of the number n of records, but less so with respect to D. The proximity digraph PD(S) will be built up in several stages, with the help of several auxiliary graphs. The first auxiliary graph we consider is the nearestneighbor digraph, defined as follows: the arc (si,si’) is in the digraph if there exists no record s distinct from si and si’ such that d(si,s)<d(si,si’). For each item si of S, we include in PD(S) at least one nearest-neighbor digraph arc from si. The second auxiliary graph is the ∆-graph, where 1 ≤ ∆ ≤ m is a density parameter. For the Hamming distance in low dimensions (less than 20), we suggest that ∆ be set to 2. The edge (si,si’) is in the ∆-graph if and only if the distance d(si,si’) is at most ∆. An edge (si,si’) of the ∆-graph will cause the insertion of (si,si’) and (si’, si) into the proximity digraph, provided that the resulting out-degree of si and si’ does not exceed u. Third, the digraph that results from the union of edges chosen from the nearestneighbor digraph and the ∆-graph is extended by transitive closure, in such a way that each node has out-degree no more than u. Using breadth-first search initialized with si (for i=1,…,n), and stopping when u nodes have been found, requires O(Du2n) time overall. Note that we are using the fact that if sa is the nearest neighbor of sb, and sb is the nearest neighbor of sc, then sc usually ranks highly among the u nearest neighbors of sa. Intuitively speaking, the ‘nearness’ relationship tends to be transitive along short paths in the nearest-neighbor digraph. As soon as we find u outgoing edges for each si, we have the desired edges for si in the proximity graph. Unfortunately, breadth-first search may find less than u outgoing edges for some si, if the graph is not strongly connected. This happens whenever a strongly connected component has less than u records (such connected components are in essence small isolated clusters). However, connected components of size less than u are identified as a byproduct of the search. The situation may be remedied by joining the connected components into one, by adding carefully chosen edges to the graph. This can be done by computing a spanning tree and a representative node for each component, in total time in O(Dun). As a representative node of a component, we may choose its (graph) 1-median, since

Approximating Proximity for Fast and Robust Distance-Based Clustering 37

the 1-median problem in a tree can be solved in linear time. Once representatives of strongly connected components are selected, the process of adding arcs into the proximity graph is resumed by computing nearest neighbors among the representatives of components. Every nearest-neighbor edge generated, when added to the proximity graph, serves to merge two of the connected components. As the number of connected components after the merge is at most half the original number, repeating this process until all components are connected will take linear time in n. Once the graph is connected, resumption of the breadth-first transitive closure computation will complete the list of u out-going arcs for each record si. We now describe how to find the nearest neighbor, and the list of neighbors at distance at most ∆, for each of the n data records. We insert all records in linked lists at the leaves of a digital tree (or trie) (Gonnet & Baeza-Yates, 1991), a variant of the well-known kd-tree search structure. The root of a standard tree discriminates according to the first attribute, and has a child for every possible categorical value of the attribute in the domain. Nodes at depth i discriminate by the values of the i-th attribute. The leaf nodes store a linked list of labels for data records arriving at that node. Although this trial can have a path of depth equal to the number of attributes — that is, D – in practice, the number of nodes of the trie is bounded by Dn. Moreover, a path from the root to a leaf may terminate before all attributes are tested if only one data record reaches that leaf. The trie is constructed by incremental insertions, in O(Dn) time. The records at distance ∆ from a given record si are then found in time independent of n, by appending the lists at those leafs whose path from the root differs in at most ∆ links to the path from the root to the leaf holding si (however, as this requires O(∆D) time, the choice of ∆≤2 is strongly advised). Finding neighbors at distance at most ∆ is repeated for each data record si whose nearest neighbor is again at distance no more than ∆, for a total time in ∪(∆D++1n). Note that, because the digital tree has depth dependent only on D, a nearest neighbor for every node can be found in time proportional to D2n. Thus, the total complexity of the preprocessing step that constructs the proximity graph is O((D∆+u2)Dn) time. At first, it may seem that if D is not small, this preprocessing is costly. However, O(Dn) time is also required by adaptations of k-MEANS to categorical data. Thus, the preprocessing step of our approach requires time of an order of magnitude comparable to that of k-MEANS, provided that u and ∆ are chosen to be small. Experimental evaluation of this implementation on categorical data again shows that the hill-climber exhibits more robustness to noise and outliers and is scalable in the number n of records (Estivill-Castro & Houle, 1999).

Generic data using random sampling
In the previous two examples, we showed how approximate near-neighbor information could be gathered in low-dimensional settings to support a robust

38 Estivill-Castro and Houle

clustering algorithm, while still scaling well in terms of n. For our third example, we will aim for a method that scales very well with respect to the dimension, but still achieves sub-quadratic time. The method makes no assumptions on the distance metric used; however, since the dimension is presumed to be relatively high, the number of distance calculations will dominate the time complexity. Accordingly, we will measure the complexity of the method in terms of the number of these distance calculations. The method relies on a random sampling to reduce the number of distance computations. The idea is that if a sample R of sufficient size is chosen from the points of S, then most points of S would have a point of R among its near neighbors. Two data points si and si’ that are both close to the same element of R are more likely to be near neighbors of one another; conversely, two near neighbors are more likely to have a common point of R near to them. The sample points can serve the role of intermediaries, informing pairs of points of S that they lie close to one another. In order to allow the user some control of the trade-offs between scalability and robustness, Algorithm NNSampler (stated below) allows two parameters: the size r of the sample, and the number m of sample points that can serve as intermediates for a given data point of S. The algorithm produces a proximity PD(S) as defined earlier, with each adjacency list containing u elements. After stating the basic algorithm, we will discuss modifications that will further improve the performance of the method.

Algorithm NNSampler
1. Select a subset R={y1,…,yr} uniformly at random from among all subsets of S of size r. This requires O(r) time. 2. For each s∈S, find its m nearest elements in R. Let Ci = {y∈R | y is one of the m nearest elements of R to si}. 3. For each yj∈R, construct a list or ‘bucket’ Bj of the elements S for yj∈Ci. 4. For each si∈S, compute the union Ui of the m buckets to which it belongs (that is Ui=Ó˛si∈Bj Bj). 5. For each si∈S, find the u closest points of Ui to si, and use them to form the adjacency list of si in PD(S). Note that the distance between any pair of data points need be computed no more than twice. Consequently, the total number of distance computations required by the basic method is in O(rn+Σi=1,..,n |Ui|). If the points of S are distributed evenly among the r buckets, the number of distance calculations simplifies to O(rn++mn2/ /r). This is minimized when r is chosen to be (mn)1//2, yielding O(n(mn)1//2) distance calculations. However, in practice, some buckets could receive more elements than others; if any one bucket were to receive a linear number of elements, the number of distance computations would become quadratic. On the other hand, any bucket that receives a disproportionately large number of elements immediately indicates a cluster in the data, as it would have been chosen as one of the m near neighbors of many data points. If the user is unwilling or unable to declare the existence of a cluster based

Approximating Proximity for Fast and Robust Distance-Based Clustering 39

on this sample point, the overfull bucket can simply be discarded, and a new random point selected to replace it. By managing the process carefully, it is not hard to see that a replacement bucket can be generated using n distance computations. Another complication that can arise in practice is when the Ui contains fewer than u points. In this case, it is a simple matter to expand the number of buckets contributing to Ui until it contains at least u points. If this is done carefully, no additional distance computations are required for this. Algorithm NNSampler was implemented and tested on the Reuters data set, which has previously been used in the analysis of several data mining applications (Bradley & Fayyad, 1998; Fayyad 1998). The Reuters set consists of records of categorical data coded as integers, each record having 302 attributes. Two sets of runs were performed, one set with n=1000 records, and the other with n=10,000. The sample sizes were chosen to be roughly n1//2: r=32 for the first set, and r=100 for the second. For each set, the number of near neighbors computed was u=10 and u=20. To test the accuracy of the near-neighbor generation, the full set of distances was calculated, and the true u nearest neighbor lists were compared with the approximate lists. The accuracy of the approximate lists are shown in Table 1, along with the time needed to compute the lists, in CPU seconds (the confidence intervals shown are at 95%). In the case where u=20, the accuracy rate of the closest 10 elements on the approximate list are compared with the 10 elements on the exact list. The lower accuracy rate in the case of n=10,000 and u=10 is due to the high number of neighbors having identical distances—in cases of an overabundance of near neighbors with the same distance to a given data point, the selection of u near neighbors is performed arbitrarily.

Random partitioning for the TWGD-problem
We now illustrate a general non-representative randomized clustering strategy, based on a two-phase enhanced version of the interchange heuristic for the TWGDproblem. The strategy is divide-and-conquer: in the first phase, we partition the set of points randomly, and compute a clustering of each partition set. For the merge step, we perform an aggregation of the elements based on the clusters generated in the first phase. Before giving the details of the method, we require some terminology and notation. The assignment of a data element to a cluster can be viewed as a labeling of that data element with the index associated with that cluster. Each modification perTable 1: Testing algorithm NNSampler versus brute force calculation
Execution Time n=1000 n=10,000 Brute Force 38.5 s 3765.9 s NNSampler (u=10) 12.6 s 360 ± 20 s NNSampler (u=20) 18.6 s 720 ± 35 s Precision n=1000 100% 91% 98%

n=10,000 100% 73 ± 3% 90 ± 4%

40 Estivill-Castro and Houle

formed by an interchange heuristic would thus result in a re-labeling of one of the data elements. The cluster to which si belongs in Pt will be denoted by Ct[si]. Conversely, the elements of j-th cluster at time t will be denoted by Ct,j. We also evaluate si for its quality as a discrete representative of the j-th cluster in Pt, using the L1 loss function: L1(si,t,j) = Σ si’∈Ct,j wi’ d(si,si’). In the preprocessing step of the first phase, data structures are constructed that maintain information about the partition in a feasible solution Pt, and the sum of distances of each point to items of a cluster. A linear array of indices is used to maintain Ct[si], the assignment of data elements to clusters for the current solution Pt. A table M[i,j] of k columns and n rows will be used to store the set of loss function values L1(si,t,j). Since the initialization Lsi requires O(n) distance calculations, initializing the entire table would require Θ(n2) calculations, but only O(kn) space. The matrix M facilitates the implementation of the heuristics for the TWGD(P)problem. That is, for the interchange at time t for item si, we find the index jmin that is the smallest value in the row for si in M; that is, L1(si,t,jmin) = min j=1,..,k L1(si,t,j). This clearly can be done in O(k) time. If jmin=Ct[si], the point si does not change cluster membership, and Pt+1=Pt. However, if jmin≠Ct[si], we have found an improvement over the current partition Pt, with si assigned to cluster jmin. We let jold←Ct[si] and Ct+1[si]←jmin. We also update the information in the matrix M. For all si’, we update its column Mi’,* by setting Mi’jold ← Mi’jold - wi d(si,si’), Mi’jmin ←Mi’jmin + wi d(si,si’).In either case, the total number of distance calculations in one interchange is in O(n). Clearly, the clustering computed is the same as for the standard TWGD interchange heuristic. This matrix-based variant (referred to as TWGD-median) is apparently more complex than the standard interchange heuristic. But TWGDmedian will allow us to develop a faster approximation algorithm for the TWGDproblem. The algorithm starts by first randomly partitioning S into smaller Y1,…,Yr. This can be achieved by generating a permutation S’ of S uniformly at random (in O(n) time). We let r∈{1,…,n} be an integer parameter and determine the random partition by dividing the sequence S’ into r consecutive blocks Y1,...,Yr, each containing roughly n/r elements. We will operate the interchange heuristic separately for each of the blocks Yb, b=1,...,r. The result will be a collection of r clusters, each consisting of k clusters. In the second phase, this collection of clusters C1b,…,Ckb of the blocks Yb, b=1,…,r, are used in turn to influence the construction of a clustering for the entire set S. The execution proceeds as if we were using the TWGD interchange on the whole set, except that the distance calculations to arbitrary points are replaced by calculations to their representative discrete medians, defined below. The first step of the second phase is the extraction of the discrete median of each cluster Cjb of each block (j=1,…,k and b=1,…,r). Formally, the discrete median cjb is a point si ∈Tb⊂S belonging to cluster Cjb such that L1(cjb,t,j) ≤ L1(s,t,j) for all data points s in Cjb. Computing the discrete median can be done simply by finding the smallest value in the j-th column for matrix Mb of the block Yb, and identifying the row where that occurs. Since cjb will be used to represent all points in Cjb, we will

Approximating Proximity for Fast and Robust Distance-Based Clustering 41

assign to it the aggregation of weights in Cjb ; that is, w(cjb)=Σ si’∈Cjb wi’. Next, on the collection of rk discrete medians obtained, a TWGD-style kclustering is performed. The k groups of medians indicate which block clusters Cjb could be merged to produce the best clustering of S into k groups. The aggregation interchange heuristic uses this information as follows. When a point si in group j is being assessed for migration to group j’, we consider whether the contribution Σ si≠ si’ ∧ si’∈ cluster j w(si) w(si’) d(si,si’)is larger than Σ si≠ si’ ∧ si’∈ cluster j’ w(si) w(si’) d(si,si’). In the case that the former is larger than the latter, si is migrated from cluster j to group j’. This new gradient is one where the sum of all pairs of distances between points represented by si and points represented by si’ are approximated by the aggregated information from the matrices Mb. Since the blocks have size Θ(n/r), the application of the aggregation version of TWGD-median to all blocks Yb requires O(rn2/r2)=O(n2/r) distance computations. The aggregation version of the hill-climber integrating these results will work with rk items per data element, and thus will require O(rkn) distance computations per complete scan through S. The overall number of distance computations is therefore in O((rk++n/r)n). This is minimized when r is chosen to be O((n/k)1/2), yielding O(n3/ 2 1/2 k ) computations. To illustrate the scalability of our methods, we implemented the three algorithms discussed here, namely the original interchange method for TWGD (which we will call TWGD-quadratic), then our enhanced version TWGD-median and finally, our final randomized approximation algorithm (which we will call TWGDrandom). We used synthetic data, generated as a mixture of 10 probability distributions in 2D. We generated data sets of different sizes, from n=4000 data items to n=1,000,000. The results are displayed graphically in Figure 1. Data in Figure 1 is on a logarithmic scale. Algorithm TWGD-median is 4 to 5 times faster than TWGDFigure 1: Illustration of CPU-time requirements of TWGD-quadratic, TWGDmedian and TWGD-random
CPU time comparison CPU time comparison
2500 2000 1500 1000 500 0 Interchange MedianTb Randomized

number of 2D data items

0 60 00 0 10 00 00 40 00 00 80 00 00

43 00

75 00

0 11 00

22 00

42 Estivill-Castro and Houle

quadratic, and for n=5000 it requires only 48s, while TWGD-quadratic requires 207s. However, both have quadratic time complexity. Our divide-and-conquer TWGD-random is radically faster, being able to cluster 1,000,000 points in the same CPU time that TWGD-median takes for only slightly more than 20,000, and the original TWGD-quadratic takes for just over 11,000. Both TWGD-quadratic and TWGD-median exhibit quadratic time complexity. An example illustrating clustering of mixture models for 3D data appears in Estivill-Castro & Houle (2001).

CONCLUSION AND FUTURE TRENDS
In this work, we have put forward a case for approximation of objective criteria and of proximity information as keys to the development of generic, scalable and robust methods for clustering for data mining applications. In particular, randomized sampling and partition techniques seem to hold the greatest promise for pushing back the barrier of scalability for these important problems. Although some of the solutions we have presented are specific to certain problem settings, others can be applied in a wide variety of settings, both inside and beyond the field of data mining clustering. The idea of using approximations to full proximity information is a very general one, and there is much potential for the application of these ideas in other settings. The underlying spirit of these solutions is the same: obtain the highest quality possible subject to a rigid observation of time constraints. There are other settings in which approximation to the full proximity information has been used to good effect. In physics, researchers applied simulated annealing to predict the motion of particles in 2D and 3D used a hierarchical structure to aggregate distance computations (Carrier, Greengard & Rokhlin, 1988; Barnes & Hut, 1986), reducing the cost of an iteration of the simulation from Θ(n2) to O(n log n). These structures have been taken up and extended to the area of graph drawing, where graphs are treated as linkages of stretchable springs between nodes with repulsive charges. Layouts of these graphs are generated by simulating the effect of forces along springs and between nodes, also using simulated annealing (Quigley & Eades, 2000). Similar structures have also been used in facility location (Belbin, 1987). Although scalability with respect to dimension is not an issue in these fields, the techniques presented here provide yet more opportunities for the development of fast and robust algorithms. Our techniques contribute to the area of robust statistics. We showed (EstivillCastro & Houle, 2000) that robust estimators of location could be computed in subquadratic time using random sampling and partitioning. Even though the statistic itself is a random variable, its robustness can be proved according to several standards. Finally, there is great potential for our techniques to be hybridized with other search strategies, such as genetic algorithms (Estivill-Castro, 2000; Estivill-Castro & Torres-Velázquez, 1998; Estivill-Castro & Murray, 2000; and references) and

Approximating Proximity for Fast and Robust Distance-Based Clustering 43

simulated annealing [Murray & Church, 1996]. Genetic algorithms and simulated annealing have extended the power of local search hill-climbers due to their ability to escape from and improve over local optima, at the cost of an increase in the computation time. These areas can also benefit from a stricter management of the distance computations performed.

REFERENCES
Aldenderfer, M.S. and R.K. Blashfield (1973.) Cluster Analysis. Sage, Beverly Hills, 1984. M.R. Anderberg. Cluster Analysis with Applications. Academic Press, NY. Aurenhammer, F. (1991). Voronoi diagrams: A survey of a fundamental geometric data structure. ACM Comput. Surv., 23(3):345-405. Barnes, J. and P. Hut (1986). A hierarchical O(n log n) force-calculation algorithm. Nature, 324(4), 446-449. Beckmann, N., H.-P. Kriegel, R. Schneider, and B. Seeger (1990). The R*-tree: An efficient and robust access method for points and rectangles. In Proc. ACM SIGMOD Conf. on Management of Data, 322-331. Belbin, L. (1987). The use of non-hierarchical allocation methods for clustering large sets of data. The Australian Computer Journal, 19(1), 32-41. Bentley, J.L. (1975). A survey of techniques for fixed radius near neighbor searching. Report STAN-CS-78-513, Dept. Comput. Sci., Stanford Univ., Stanford, CA. Bentley, J.L. (1979). Decomposable searching problems. Information Processing Letters, 8, 244-251. Berchtold, S. D.A. Keim, and H.-P. Kriegel(1996).. The X-tree: An index structure for higher dimensional data. In Proc. 22nd VLDB Conference, 28-39. Berry, M.J.A. and G. Linoff (1997). Data Mining Techniques - for Marketing, Sales and Customer Support. John Wiley & Sons, NY, USA. Berson, A. and S.J. Smith (1998). Data Warehousing, Data Mining, & OLAP. Series on Data Warehousing and Data Management. McGraw-Hill, NY, USA. Bradley, P.S. and U. Fayyad (1998). Refining the initial points in k-means clustering. In Proc. of the 15th Int. Con.e on Machine Learning,Morgan Kaufmann, 91-99. Bradley, P.S., U. Fayyad, and C. Reina (1998). Scaling clustering algorithms to large databases. In R. Agrawal and P. Stolorz, eds., Proc. of the 4th Int. Conference on Knowledge Discovery and Data Mining, AAAI Press, 9-15. Bradley, P.S., O.L. Mangasarian, and W.N. Street (1997). Clustering via concave minimization. Advances in neural information processing systems, 9:368. Brucker, P. (1978). On the complexity of clustering problems. In R. Henn, B.H.B. Korte, and W.W. Oetti, eds., Optimization and Operations Research: Proceedings of the workshop held at the University of Bonn, Berlin. Springer Verlag Lecture Notes in Economics and Mathematical Systems. Carrier, J., L. Greengard, and V. Rokhlin (1988). A fast adaptive multipode algorithm for particle simulation. SIAM J. of Science and Statistical Computing, 9:669-686. Chávez, E., G. Navarro, R. Baeza-Yates, and J. Marroquín (1999). Searching in metric spaces. Report TR/DCC-99-3, Dept. of Comp. Science, U. of Chile, Santiago. Cheeseman, P., M. Self, J. Kelly, W. Taylor, D. Freeman, and J. Stutz (1988). Bayesian classification. In Proc. Seventh National Conference on Artificial Intelligence, 607-611, Palo Alto, CA, AAAI, Morgan Kaufmann.

44 Estivill-Castro and Houle

Cherkassky, V., and F. Muller (1998). Learning from Data - Concept, Theory and Methods. John Wiley & Sons, NY, USA. Chiu, D.K.Y., A.K.C. Wong, and B. Cheung (1991). Information discovery through hierarchical maximum entropy discretization and synthesis. In G. Piatetsky-Shapiro and W.J. Frawley, eds., Knowledge Discovery in Databases, pages 125-140, Menlo Park, CA. AAAI, AAAI Press. Ciaccia, P., M. Patella, and P. Zezula (1997). M-tree: an efficient access method for similarity search in metric spaces. In Proc. 23rd VLDB Conference, pages 426-435. Dempster, A.P., N.M. Laird, and D.B. Rubin (1977). Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society B, 39:1-38. Densham, P. and G. Rushton (1992). A more efficient heuristic for solving large p-median problems. Papers in Regional Science, 71:307-329. Dickerson, M.T., R.L.S. Drysdale, and J.-R. Sack (1992). Simple algorithms for enumerating interpoint distances and finding k nearest neighbours. International Journal of Computational Geometry & Applications, 2(3):221-239, 1992. Duda, R.O. and P.E. Hart (1973). Pattern Classification and Scene Analysis. John Wiley & Sons, NY, USA. Ester, M., H.P. Kriegel, S. Sander, and X. Xu (1996). A density-based algorithm for discovering clusters in large spatial databases with noise. E. Simoudis, J. Han, and U. Fayyad, eds., Proc. 2nd Int. Conf. Knowledge Discovery and Data Mining 226-231, Menlo Park, CA, AAAI, AAAI Press. Estivill-Castro, V. (2000). Hybrid genetic algorithms are better for spatial clustering. In R. Mizoguchi and J. Slaney, eds., Proc. 6th Pacific Rim Int. Conf. on Artificial Intelligence, 424-434, Melbourne, Australia,Springer-Verlag LNAI 1886. Estivill-Castro, V. and M.E. Houle (forthcoming). Robust distance-based clustering with applications to spatial data mining. Algorithmica. In press - Special Issue on Algorithms for Geographic Information. Estivill-Castro, V. and M.E. Houle (1999). Robust clustering of large data sets with categorical attributes. In J. Roddick, editor, Database Systems - Australian Computer Science Communications, 21(2), 165-176, Springer Verlag, Singapore. Estivill-Castro, V. and M.E. Houle (2000). Fast randomized algorithms for robust estimation of location. In J. Roddick and K. Hornsby, eds., Proc. Int. Workshop on Temporal, Spatial and Spatio-Temporal Data Mining, in conjunction with the 4th European Conf. on Principles and Practices of Knowledge Discovery and Databases, 74-85, Lyon, France, 2000. Springer-Verlag LNAI 2007. Estivill-Castro, V. and M.E. Houle (2001). Fast minimization of total within-group distance. M. Ng, ed., Proc. Int. Workshop Spatio-Temporal Data Mining in conjunction with 5th Pacific-Asia Conf. Knowledge Discovery and Data Mining, Hong Kong 2001. Estivill-Castro, V. and A.T. Murray (1998). Discovering associations in spatial data - an efficient medoid based approach. In X. Wu, R. Kotagiri, and K.K. Korb, eds., Proc. 2nd Pacific-Asia Conf. on Knowledge Discovery and Data Mining, 110-121, Melbourne, Australia, Springer-Verlag LNAI 1394. Estivill-Castro, V. and A.T. Murray (2000). Weighted facility location and clustering via hybrid optimization. In F. Naghdy, F. Kurfess, H. Ogata, E. Szczerbicki, and H. Bothe, eds., Proc. Int. Conf. on Intelligent Systems and Applications (ISA-2000), Paper 1514079, Canada, 2000. ICSC, ICSC Academic Press. CD-ROM version. Estivill-Castro, V. and R. Torres-Velázquez (1999). Hybrid genetic algorithm for solving the p-median problem. In A Yao, R.I. McKay, C.S. Newton, J.-H Kim, and T. Furuhashi,

Approximating Proximity for Fast and Robust Distance-Based Clustering 45

eds., Proc. of Second Asia Pacific Conference On Simulated Evolution and Learning SEAL-98, 18-25. Springer Verlag LNAI 1585. Estivill-Castro, V. and J. Yang (2000).. A fast and robust general purpose clustering algorithm. R. Mizoguchi & J. Slaney, eds, Proc. 6th Pacific Rim Int. Conf. Artificial Intelligence, 208-218, Melbourne, Australia, 2000. Springer-Verlag LNAI 1886. Everitt,B. (1980). Cluster Analysis. Halsted Press, New York, USA, 2nd. edition, 1980. Fayyad, U., C. Reina, and P.S. Bradley (1998). Initialization of iterative refinement clustering algorithms. R. Agrawal and P. Stolorz, eds., Proc. 4th Int. Conf. on Knowledge Discovery and Data Mining, 194-198. AAAI Press. Fisher, D.H.(1987). Knowledge acquisition via incremental conceptual clustering. Machine Learning, 2(2):139-172. Glover, F. (1986). Future paths for integer programming and links to artificial intelligence. Computers and Operations Research, 5:533-549. Gonnet, G.H. and R. Baeza-Yates (1991). Handbook of Algorithms and Data Structures, 2nd edition. Addison-Wesley Publishing Co., Don Mills, Ontario. Guttmann, A. (1984). R-trees: a dynamic index structure for spatial searching. In Proc. ACM SIGMOD International Conference on Management of Data, pages 47-57, 1984. Hall, I.B. (1999). L.O. Özyurt and J.C. Bezdek. Clustering with a genetically optimized approach. IEEE Transactions on Evolutionary Computation, 3(2):103-112, July 1999. Han, J. and M. Kamber (2000). Data Mining: Concepts and Techniques. Morgan Kaufmann Publishers, San Mateo, CA. Hartigan, J.A. (1975). Clustering Algorithms. Wiley, NY. Horn, M. (1996). Analysis and computation schemes for p-median heuristics. Environment and Planning A, 28:1699-1708. Jain, A.K. and R.C. Dubes (1998). Algorithms for Clustering Data. Prentice-Hall, Inc., Englewood Cliffs, NJ, Advanced Reference Series: Computer Science. Kaufman, L. and P.J. Rousseuw (1990).. Finding Groups in Data: An Introduction to Cluster Analysis. John Wiley & Sons, NY, USA. Krivánek, M. (1986). Hexagonal unit network — a tool for proving the NP-completeness results of geometric problems. Information Processing Letters, 22:37-41. Krznaric, D. and C. Levcopoulos (1998). Fast algorithms for complete linkage clustering. Discrete & Computational Geometry, 19:131-145. MacQueen, J.(1967). Some methods for classification and analysis of multivariate observations. L. Le Cam and J. Neyman, eds., 5th Berkley Symposium on Mathematical Statistics and Probability, volume 1, 281-297. Michalski, R.S. and R.E. Stepp (1983). Automated construction of classifications: clustering versus numerical taxonomy. IEEE Tran. on Pattern Analysis and Machine Intelligence, 5:683-690. Mitchell, T.M. (1997). Machine Learning. McGraw-Hill, Boston, MA, 1997. Murray, A.T. (2000). Spatial characteristics and comparisons of interaction and median clustering models. Geographical Analysis, 32(1):1-. Murray, A.T. and R.L. Church (1996). Applying simulated annealing to location-planning models. Journal of Heuristics, 2:31-53, 1996. Murra, A.T. and V. Estivill-Castro (1998). Cluster discovery techniques for exploratory spatial data analysis. Int. J. of Geographic Information Systems, 12(5):431-443. Ng, R.T. and J. Han (1994). Efficient and effective clustering methods for spatial data mining. In J. Bocca, M. Jarke, and C. Zaniolo, eds., Proc. 20th VLDB Conference, 144155, San Francisco, CA, Santiago, Chile, Morgan Kaufmann.

46 Estivill-Castro and Houle

Okabe,A., B. Boots, and K. Sugihara (1992). Spatial Tesselations - Concepts and applications of Voronoi diagrams. John Wiley & Sons, NY, USA. O’Rourke, J. (1994). Computational Geometry in C. Cambridge University Press, UK. Quigley, A.J. and P. Eades (1984). FADE: Graph drawing, clustering and visual abstraction. In J. Marks, editor, Proc. 8ht Int. Symposium on Graph Drawing, Williamsburg Virginia, USA, 2000. Springer Verlag Lecture Notes in Computer Science. Rao, M. (1971). Cluster analysis and mathematical programming. Journal of the American Statistical Association, 66:622-626. Rolland, D., E. Schilling and J. Current (1996). An efficient Tabu search procedure for the p-median problem. European Journal of Operations Research, 96:329-342. Rosing, K. and C. ReVelle (1986). Optimal clustering. Environment and Planning A, 18:1463-1476. Rosing, K.E., C.S. ReVelle, and H. Rosing-Voyelaar (1979). The p-median and its linear programming relaxation: An approach to large problems. Journal of the Operational Research Society, 30:815-823. Rousseeuw, P.J. and A.M. Leroy (1987). Robust regression and outlier detection. John Wiley & Sons, NY, USA. Samet, H. (1989). The Design and Analysis of Spatial Data Structures. Addison-Wesley Publishing Co., Reading, MA. Schikuta, E. (1996). Grid-clustering: an efficient hierarchical clustering method for very large data sets. In Proc. 13th Int. Conf. on Pattern Recognition, vol. 2, 101-105. Späth, H. (1980). Cluster Analysis Algorithms for data reduction and classification of objects. Ellis Horwood Limited, Chinchester, UK. Teitz, M.B. and P. Bart (1968). Heuristic methods for estimating the generalized vertex median of a weighted graph. Operations Research, 16, 955-961. Titterington, D.M., A.F.M. Smith, and U.E. Makov (1985). Statistical Analysis of Finite Mixture Distributions. John Wiley & Sons, UK. Vinod, H.(1969). Integer programming and the theory of grouping. Journal of the American Statistical Association, 64, 506-517. Wallace, C.S. and P.R. Freeman (1987). Estimation and inference by compact coding. Journal of the Royal Statistical Society, Series B, 49(3), 240-265, 1987. Wang, W., J. Yang, and R. Muntz (1997). STING: a statistical information grid approach to spatial data mining. In M. Jarke, editor, Proc. 23rd VLDB Conference, pages 186-195, Athens, Greece. VLDB, Morgan Kaufmann Publishers. Zhang, T., R. Ramakrishnan, and M. Livny (1996). BIRCH: an efficient data clustering method for very large databases. SIGMOD Record, 25(2),103-114.

PART TWO: EVOLUTIONARY ALGORITHMS

48 Cantú-Paz and Kamath

Chapter III

On the Use of Evolutionary Algorithms in Data Mining
Erick Cantú-Paz and Chandrika Kamath Center for Applied Scientific Computing Lawrence Livermore National Laboratory, USA

With computers becoming more pervasive, disks becoming cheaper, and sensors becoming ubiquitous, we are collecting data at an ever-increasing pace. However, it is far easier to collect the data than to extract useful information from it. Sophisticated techniques, such as those developed in the multi-disciplinary field of data mining, are increasingly being applied to the analysis of these datasets in commercial and scientific domains. As the problems become larger and more complex, researchers are turning to heuristic techniques to complement existing approaches. This survey chapter examines the role that evolutionary algorithms (EAs) can play in various stages of data mining. We consider data mining as the end-to-end process of finding patterns starting with raw data. The chapter focuses on the topics of feature extraction, feature selection, classification, and clustering, and surveys the state of the art in the application of evolutionary algorithms to these areas. We examine the use of evolutionary algorithms both in isolation and in combination with other algorithms including neural networks, and decision trees. The chapter concludes with a summary of open research problems and opportunities for the future.

INTRODUCTION
Data mining is increasingly being accepted as a viable means of analyzing massive data sets. With commercial and scientific datasets approaching the terabyte
Copyright © 2002, Idea Group Publishing.

Evolutionary Algorithms in Data Mining 49

and even petabyte range, it is no longer possible to manually find useful information in this data. As the semi-automated techniques of data mining are applied in various domains, it is becoming clear that methods from statistics, artificial intelligence, optimization, etc., that comprise data mining, are no longer sufficient to address this problem of data overload. Often, the data is noisy and has a high level of uncertainty. It could also be dynamic, with the patterns in the data evolving in space and time. To address these aspects of data analysis, we need to incorporate heuristic techniques to complement the existing approaches. In this chapter, we survey the role that one category of heuristic algorithms, namely, evolutionary algorithms (EAs), plays in the various steps of the data mining process. After a brief definition of both the data mining process and evolutionary algorithms, we focus on the many ways in which these algorithms are being used in data mining. This survey is by no means exhaustive. Rather, it is meant to illustrate the diverse ways in which the power of evolutionary algorithms can be used to improve the techniques being applied to the analysis of massive data sets. Following a survey of current work in the use of EAs for data mining tasks such as feature extraction, feature selection, classification, and clustering, we describe some challenges encountered in applying these techniques. We conclude with the exciting opportunities that await future researchers in the field.

AN OVERVIEW OF DATA MINING
Data mining is a process concerned with uncovering patterns, associations, anomalies and statistically significant structures in data (Fayyad et al., 1996). It typically refers to the case where the data is too large or too complex to allow either a manual analysis or analysis by means of simple queries. Data mining consists of two main steps, data pre-processing, during which relevant high-level features or attributes are extracted from the low level data, and pattern recognition, in which a pattern in the data is recognized using these features (see Figure 1). Pre-processing the data is often a time-consuming, yet critical, first step. To ensure the success of the data-mining process, it is important that the features extracted from the data are Figure 1: Data mining—An iterative and interactive process

50 Cantú-Paz and Kamath

relevant to the problem and representative of the data. Depending on the type of data being mined, the pre-processing step may consist of several sub-tasks. If the raw data is very large, we could use sampling and work with fewer instances, or use multi-resolution techniques and work with data at a coarser resolution. Next, noise in the data is removed to the extent possible, and relevant features are extracted. In some cases, where data from different sources or sensors are available, data fusion may be required to allow the miner to exploit all the data available for a problem. At the end of this first step, we have a feature vector for each data instance. Depending on the problem and the data, we may need to reduce the number of features using feature selection or dimension reduction techniques such as principal component analysis (PCA) (Jackson, 1991) or its nonlinear versions. After this pre-processing, the data is ready for the detection of patterns through the use of algorithms such as classification, clustering, regression, etc. These patterns are then displayed to the user for validation. Data mining is an iterative and interactive process. The output of any step, or feedback from the domain experts, could result in an iterative refinement of any, or all, of the sub-tasks. While there is some debate about the exact definition of data mining (Kamath 2001), most practitioners and proponents agree that data mining is a multidisciplinary field, borrowing ideas from machine learning and artificial intelligence, statistics, high performance computing, signal and image processing, mathematical optimization, pattern recognition, etc. What is new is the confluence of the mature offshoots of these technologies at a time when we can exploit them for the analysis of massive data sets. As data mining has been applied to new problem domains, this technology mix has grown as well. For example, the growth of the Internet and the World Wide Web has resulted in tasks such as clustering text documents, multimedia searches, or mining a user’s Web surfing patterns to predict what page they are likely to visit next or to target the advertising on a Web page. This has added natural language processing and privacy issues to the technological mix that comprises data mining. Data mining techniques are being applied for the analysis of data in a variety of fields including remote sensing, bio-informatics, medical imaging, astronomy, Web mining, text mining, customer relationship management, and market-basket analysis. While much of the focus in the data mining process tends to be on pattern recognition algorithms, the data pre-processing steps are more influential in the success of the data mining endeavor (Langley and Simon, 1995; Burl et al., 1998). Unfortunately, the pre-processing steps often depend on the domain and problem. As a result, given the space limitations of this chapter, any discussion of the role of evolutionary algorithms in data pre-processing is likely to be limited in scope. Rather than ignore this important subject altogether, we will discuss aspects of this subject that are broadly applicable to several problem domains.

Evolutionary Algorithms in Data Mining 51

AN OVERVIEW OF EVOLUTIONARY ALGORITHMS
Evolutionary algorithms are randomized search procedures inspired by the mechanics of genetics and natural selection. EAs are often used as optimization algorithms, and this is the role that they play in most data mining applications. EAs work on a population of individuals that represent possible solutions to a problem in their chromosomes. Each individual can be as simple as a string of zeroes and ones, or as complex as a computer program. The initial population of individuals may be created entirely at random, or some knowledge about previously known solutions may be used to seed the population. The algorithm evaluates the individuals to determine how well they solve the problem at hand with an objective function, which is unique to each problem and must be supplied by the user. The individuals with better performance are selected to serve as parents of the next generation. Evolutionary algorithms create new individuals using simple randomized operators that are similar to sexual recombination and mutation in natural organisms. The new solutions are evaluated, and the cycle of selection and creation of new individuals is repeated until a satisfactory solution is found or a predetermined time limit has elapsed. There are several major types of evolutionary algorithms: genetic algorithms (GAs), genetic programming (GP), evolution strategies (ES), and evolutionary programming (EP). All evolutionary algorithms share the same basic concepts, but differ in the way they encode the solutions and on the operators they use to create the next generation. Evolutionary algorithms are controlled by several inputs, such as the size of the population, and the rates that control how often mutation and crossover are used. In general, there is no guarantee that the evolutionary algorithm will find the optimal solution to an arbitrary problem, but a careful manipulation of the inputs and choosing a representation that is adequate to the problem increase the chances of success. There are many ways to encode a potential solution as a chromosome, and there are many variations of selection methods, crossover, and mutation operators. Some of these choices are better suited to a particular problem than others, and no single choice is the best for all problems. Traditionally, genetic algorithms use chromosomes composed of zeroes and ones, but other encodings may be more natural to the problem and may facilitate the search for good solutions. Genetic programming encodes solutions as computer programs. ES and EP use floating-point numbers, which may be more suitable for function optimization problems where the parameters to optimize are real numbers, but may be an awkward match to a problem of finding the shortest route between multiple cities. The choice of encoding is related to the operators that are used to produce new solutions from the selected ones. The simplest operator is mutation, and it acts by randomly changing a short piece of the chromosome. For example, when applied to

52 Cantú-Paz and Kamath

strings of binary digits, it randomly chooses a location in the chromosome of an individual and flips a bit from zero to one or vice-versa. ES and EP use more sophisticated mutation operators. Taking a cue from nature, genetic algorithms do not use mutation very often. The primary mechanism in GAs to create new individuals is crossover. In its simplest form, crossover randomly chooses two individuals from the pool that were selected to be parents, and exchanges segments of their two chromosomes around a single randomly chosen point. The result is two new individuals, each with a segment of chromosome from each parent. Other variants of crossover exchange material around more than one point, and some researchers have experimented with recombining chromosomes from more than two parents. Some of the new solutions will be more fit than the parents, but others will be less fit. Evolutionary algorithms cannot avoid creating solutions that turn out to be unfit, but the selection process eliminates the bad solutions and keeps the best. The selection of the parents can occur in many ways, but all selection methods have the same objective of preserving good individuals and discarding the less fit ones. Roughly, there are two kinds of selection: hard and soft. Soft selection methods assign to each individual a probability of survival based on their fitness, so that individuals with high fitness are more likely to be selected than individuals with low fitness. The soft selection methods then use the probabilities to select the parents. The hard methods do not involve any probabilities; they choose deterministically a fixed number of the best solutions available.

THE ROLE OF EVOLUTIONARY ALGORITHMS IN DATA MINING
After the brief overview of data mining and evolutionary algorithms, we next discuss the important role these algorithms can play in the various steps of data mining. In the following sections, we discuss how evolutionary algorithms can be used to improve the robustness and accuracy of the more traditional techniques used in feature extraction, feature selection, classification, and clustering. In our survey, we view data mining as a multi-step process, focusing on the role that EAs can play in each step. However, we would be remiss if we did not include the work of those authors who blur the separation between the different steps and use EAs to perform data mining as a whole on the input data. For example, in an early paper, Tackett (1993) identifies targets in a cluttered image by combining simple features extracted from the segmented image through linear and non-linear operations. If the resulting single value at the root of the tree is greater than zero, the object is classified as a target. Stanhope and Daida (1998) use a similar approach in their work on target classification using Synthetic Aperture Radar (SAR) images. Sherrah, Bogner, and Bouzerdoum (1996) also use non-linear pre-processing functions to create new features from primitive features. In addition, they associate one of three simple classifiers with each individual. The objective function is to

Evolutionary Algorithms in Data Mining 53

minimize the number of errors made by each individual (a parse tree + a classifier) on the training data, with smaller trees being favored as a tie-breaker. In the process, the classifier is selected automatically.

EVOLUTIONARY ALGORITHMS IN FEATURE EXTRACTION
The process of extracting features that are relevant to the problem being addressed in data mining is very problem- and data-dependent. In some types of data, the features are relatively easy to identify. For example, in text data, the features are the words in the text, and in market-basket analysis, the features are the items bought in a transaction. In each case, some processing of these raw features may be required. In text mining, words that do not represent the content of the text (e.g., articles) are removed and stemming of words performed so that similar words such as “computers” and “computing” are not considered as different (Frakes and Baeza-Yates, 1992). In market-basket analysis, we may need to convert the units so that all items bought by weight are measured in ounces. While some types of data lend themselves easily to feature extraction, this task is more difficult in other cases. A typical example is image data, where feature extraction is far more challenging. In the past, image data was restricted to a few domains such as astronomy and remote sensing; however, it is now becoming more pervasive. With data mining being applied to domains such as medical imaging, multimedia on the Web, and video images, it is important that we have robust techniques to identify features representing an image. Since images tend to vary widely, even within a domain, the adaptive nature of evolutionary algorithms can be exploited very effectively to address this important and difficult problem of feature extraction in image data. An image is a rectangular array of pixels, where each pixel has either a grayscale value, or a real value representing some physical quantity. In image mining, the first task is to identify an object in the image, followed by extraction of features that represent the object. Object identification is often the more difficult of these two tasks, as it involves the conversion of the low-level representation (i.e., pixels) into a higher-level representation (i.e., objects). It is here that evolutionary algorithms can be used very efficiently and effectively. Two techniques that are traditionally used to identify an object in an image are segmentation, where the image is separated into several regions based on some desired criteria, and edge detection, where edges or contours in an image are identified (Weeks, 1996). Several authors have exploited the use of evolutionary algorithms for image segmentation to deal with large and complex search spaces where limited information is available about the objective function. As Bhanu, Lee, and Ming (1995) point out, a key challenge in image segmentation is that most algorithms require the selection of several control parameters for optimal performance. This results in a high-dimensional search space, where the interactions between the parameters are

54 Cantú-Paz and Kamath

complex and non-linear. Further, variations between images could cause the objective function representing the quality of segmentation to vary from one image to another. The problem is worsened by the fact that there is no single, universally accepted measure of the quality of the segmented image. To address these problems, Bhanu and Lee (1994) have explored the use of genetic algorithms to adaptively find the optimal set of control parameters for the Phoenix segmentation algorithm. The genetic algorithm selects an initial set of parameters based on the statistics of an image along with the conditions under which the image was obtained (time of day, cloud cover, etc.). The performance is evaluated using multiple measures of segmentation quality that include both global characteristics of the image and local features of the object. The system is adaptive as a global population of images, their associated characteristics, and the optimal control parameters. It is maintained and used to seed the population each time a new image is analyzed. This global population is also constantly updated with higher strength individuals. Using scene images, Bhanu, Lee, and Ming (1995) show that their approach provides high quality results in a minimal number of cycles. Another approach to segmentation using genetic algorithms is the work done in three-dimensional medical imaging by Cagnoni, Dobrzeniecki, Poli, and Yanch (1997). They too observe that the extreme variability of the features in biological structures causes the solutions generated by general-purpose algorithms to be unacceptable. As a result, some degree of adaptivity is required when segmenting medical images. Their approach identifies the contours of an object by first identifying the edge points using a filter whose parameters are optimized by a GA. These edge points are then used to seed an interpolation process, where the interpolation parameters are also generated by a GA. The fitness function is proportional to the degree of similarity between the contours generated by the GA and the contours identified in manually generated training examples. These filter and interpolation parameters are obtained for each new class of problems. Results on three-dimensional MRI images show that the GA-based techniques are insensitive to significant changes in shape across a sequence of images as well as the interand intra-slice variability in the contours, thus illustrating the power of these techniques. The task of edge detection can also benefit from the use of evolutionary algorithms. Most edge detectors use simple first- and second-order derivatives to identify an edge. However, these operators are sensitive to noise and are not very general. In addition, they identify a pixel as an edge pixel based on the response of the edge detector at that pixel, ignoring the edge structure around the pixel. To overcome this disadvantage, several authors, including Tan, Gelfand, and Delp (1989) and Bhandarkar, Zhang, and Potter (1994) have proposed an approach based on cost minimization, where the cost takes into account issues such as local edge structure, continuity of the edge, and fragmentation. This lends itself very naturally to the use of genetic algorithms for minimizing the cost. Bhandarkar et al. (1994) first define edge pixels as those that satisfy certain constraints, and then define the corresponding cost functions based on the local edge structure. Since the data is an

Evolutionary Algorithms in Data Mining 55

image, the most natural representation of a chromosome is a two dimensional sequence of zeroes and ones, where an edge pixel is a one, and a non-edge pixel is a zero. The crossover operator is defined in two dimensions, with two-dimensional sub-images swapped between individuals. Their results show that both simulated annealing and an integrated GA (which includes elitism, intelligent mutation, etc.) are better at detecting edges than a local search or a simple GA for both noisy and noise-free images. This idea of using evolutionary algorithms to find an optimal set of parameters has also been used for image registration, where points in one image are mapped to corresponding points in another image of the same scene taken under different conditions. For example, Mandava, Fitzpatrick, and Pickens (1989) use GAs to find the parameters of a non-linear transformation that warps the four corners of one subimage and maps them to another sub-image. To reduce the time, the quality of the transformation is evaluated using only a select sample of pixels in the sub-image. In addition to genetic algorithms, several authors have used genetic programming to address image-processing problems. In particular, GP is often used for constructing image-processing operators for specific tasks. The idea is to start with a set of basic primitive functions such as a median filter applied to an image or the square of an image, and use GP to create a new operation. The fitness of the parse tree is usually evaluated by comparison with training examples, where the task to be achieved has been performed manually. Ebner and Zell (1999) describe how this approach can be used to measure optical flow, which requires the establishment of corresponding points between one image and the next. Brumby et al. (1999) use a similar approach for finding open water, such as rivers and lakes, amidst vegetation in remote sensing images. Their approach implements several checks to reduce unnecessary computation, and also gives credit for finding the anti-feature, that is, everything but the open water. Poli (1996) illustrates how GP can be used to find effective filters for medical images. He considers several ways of specifying the fitness function to account for the fact that any algorithm that uses filters for tasks such as image segmentation will give rise to false positives and false negatives. Depending on the application, the fitness function could assign weights to each, thus emphasizing appropriately the costs associated with either the false positives or the false negatives.

EVOLUTIONARY ALGORITHMS IN FEATURE SELECTION
Once the relevant features representing the data items have been extracted, it is often helpful to reduce this set of features. There are several reasons for this. In many situations, it is not possible to know a priori which features extracted from the data will be relevant to the problem at hand. Including features that are irrelevant not only increases the time complexity of many algorithms, but also increases the time needed to extract the features. Further, as the number of examples needed for

56 Cantú-Paz and Kamath

learning a concept is proportional to the dimension of the feature space, fewer training examples will be required if the number of features is reduced. In addition, some features may have costs or risks associated with them, and these should be weighted accordingly during the process of data mining. This leads to the problem of feature subset selection which is the task of identifying and selecting a useful subset of features to be used to represent patterns from a larger set of often mutually redundant, possibly irrelevant, features with different associated measurement costs and risks (Yang and Honavar, 1997). Note that we use the term feature to indicate the attributes that represent an object or a data instance—these may be obtained directly from the original data, or derived by processing the original data. The simplest way to remove irrelevant features is to apply domain knowledge. For example, if we are interested in clustering text documents, it is obvious that articles, such as “a,” “an” and “the” are irrelevant variables (Frakes and BaezaYates, 1992). However, this approach is feasible only when a domain scientist can easily identify irrelevant attributes, which is rarely the case. More complex techniques such as principal component analysis can also be used to obtain linear combinations of attributes by projecting them along the directions of the greatest variance. We next discuss the ways in which evolutionary algorithms can be used to address the problem of feature selection. The evolutionary approach most often used for feature selection is to combine the selection with the learning algorithm, in what is referred to as the wrapper approach. In this approach, the fitness of the feature subsets obtained during the evolutionary computation is evaluated using the learning algorithm itself. While this is more computationally intensive than selecting the features independent of the learning algorithm, it preserves any inductive and representational biases of the learning algorithm. Early work by Siedlecki and Sklansky (1989) with genetic algorithms identified an individual in the population as a series of zeros and ones, where a one indicated that a feature was included in the classification, and a zero indicated that it was not. The k-nearest-neighbor algorithm was chosen to evaluate how good each individual was based on its classification accuracy and the number of the features (i.e., ones) used. Others have applied the same basic binary encoding to select features in classification problems using neural networks (Brill, Brown and Martin, 1990; Brotherton and Simpson, 1995) Punch et al. (1993) extended the simple binary feature selection idea by representing an individual by a series of weights between zero and ten, thus weighting some features as more important than others. They found that their extension appeared to work better than the zero/one approach of Siedlecki and Sklansky (1989) on noisy real-world datasets. Vafaie and DeJong (1998) also investigated a similar approach to feature selection using decision trees for classification. However, in their work, instead of just weighting each feature, they allowed the combination of existing features to form new features through simple operations such as add, subtract, multiply, and divide. This adaptive feature-space transformation led to a significant reduction in the number of features and improved

Evolutionary Algorithms in Data Mining 57

the classification accuracy. Other related work in this area is that of Yang and Honavar (1997) who used neural networks as the classifier and a simple zero/one strategy for weighting each feature. A very different use of genetic algorithms in feature selection is in the generation of ensembles of classifiers. Recent work by several authors (see, for example, Dietterich, 2000) has shown that it is possible to improve classification accuracy by combining the prediction of multiple classifiers. These ensembles of classifiers differ in the ways in which the classifiers are generated and their results are combined. Early work of Ho (1998), which used a random selection of features to create an ensemble, was extended by Guerra-Salcedo and Whitley (1999). They replaced the random selection with a more intelligent approach using genetic algorithms, and showed empirically that their idea was more accurate.

EVOLUTIONARY ALGORITHMS IN CLASSIFICATION
In this section, we describe how evolutionary algorithms can be used in conjunction with classification algorithms such as rule-based systems, neural networks, and decision trees.

Rule-Based Systems
Representing concepts as sets of rules has long been popular in machine learning, because, among other properties, rules are easy to represent and humans can interpret them easily. In EAs there are two main ways to represent rule sets. In the “Michigan” approach (Holland, 1975; Booker, Goldberg and Holland 1989), each individual in the population represents one fixed-length rule, and the entire population represents the target concept. In contrast, in the “Pittsburgh” approach (Smith, 1980, 1983; DeJong, Spears and Gordon, 1993), each variable-sized individual represents an entire set of rules. The two representations have their merits and drawbacks and have been used successfully in classifier systems, which are rule-based systems that combine reinforcement learning and evolutionary algorithms. The basic loop in a classifier system is that the system is presented with inputs from the environment, the inputs are transformed into messages that are added into a message list, and the strongest rules that match any message in the list are fired (possibly adding more messages to the list or acting on the environment). Rules are assigned a fitness value based on a reward returned by the environment. A genetic algorithm is used as the discovery component of the system, creating new rules based on the current best. This is not the place to describe classic classifier systems or their relatives in detail. The interested reader should consult the book by Goldberg (1989) for a good introduction to classic CS, or the papers by Wilson (1995; 2000a) that describe some

58 Cantú-Paz and Kamath

extensions. Wilson and Goldberg (1989) present an early critical review of classifier systems, and Wilson (2000b) presents a summary and outlook of research on XCS. Classifier systems are commonly used as control systems in changing or uncertain environments, where there may not be sufficient or clear expert knowledge to produce a more conventional control (e.g., Goldberg, 1983). Closer to our interests in data mining, classifier systems have been used to learn Boolean functions (Wilson, 1995), which are of significance because they illustrate the ability of the system to learn complex non-linear concepts. Other applications include the classification of letters (Frey, 1991), and breast cancer diagnosis (Wilson, 2000a). In classifier systems, the left side of rules is a conjunctive expression. This limits the descriptive power of the rules compared to, for example, first-order logic statements. First-order logic is important because it permits expression of relationships between entities in databases. As Augier et al. (1995) noted, most of the machine learning algorithms that use first-order logic discover new rules using deterministic or heuristic approaches that can get trapped in local optima. To address this problem one can try to use EAs. A critical problem is to represent the rules, so that the evolutionary operators can act on them effectively and produce rules that make sense. Giordana and Neri (1995) proposed to use a user-defined template to specify the predicates. The EA finds the specific values that will be used in the rules. Their scheme has the advantage that the EA does not require modifications, because chromosomes are of fixed length and all combinations form valid rules. They also proposed two specialized crossover operators that are designed to promote specialization and generalization. Another advantage of Giordana and Neri’s system is also one of its main disadvantages: the dependence on the user to supply a template for the rules. Although this permits the incorporation of domain knowledge into the algorithm, the user must have a rough idea of the desired result. Augier et al. (1995) proposed an algorithm that addresses this issue by manipulating both the predicates and their values. The algorithm begins with a single rule that matches a single example. Specialized evolutionary operators modify the rule and create offspring that are added to the population until a limit is reached. The best rule after the execution of the EA is selected to form part of the final rule set, and the examples covered by the rule are deleted from the training set. The algorithm is repeated until there are no examples left.

Evolutionary Algorithms and Neural Networks
Genetic algorithms and artificial neural networks (ANNs) have been used together in two major ways. First, EAs have been used to train or to aid in the training of ANNs. In particular, EAs have been used to search for the weights of the network, to search for appropriate learning parameters, or to reduce the size of the training set by selecting the most relevant features. The second major type of collaboration has been to use EAs to design the structure of the network. The structure largely determines the efficiency of the network and the problems that it can solve. It is well

Evolutionary Algorithms in Data Mining 59

known that to solve non–linearly separable problems, the network must have at least one layer between the inputs and outputs; but determining the number and the size of the hidden layers is mostly a matter of trial and error. EAs have been used to search for these parameters, as well as for the pattern of connections and for developmental instructions for the network. The interested reader may consult the reviews by Branke (1995), Whitley (1995) or Yao (1999). Training an ANN is an optimization task with the goal of finding a set of weights that minimizes some error measure. The search space has many dimensions and it is likely to contain multiple local optima. Some traditional network training algorithms, such as backpropagation, use some form of gradient search, and may get trapped in local optima. In contrast, EAs do not use any gradient information, and are likely to avoid getting trapped in a local optimum by sampling simultaneously multiple regions of the space. A straightforward combination of evolutionary algorithms and neural networks is to use the EAs to search for weights that make the network perform as desired. In this approach, each individual in the EA is a vector with all the weights of the network. Assessing the fitness of each network involves measuring the accuracy of classification or regression on the training set, so for each fitness evaluation, the training set is passed through the network. This can be inefficient if the training set is large, but the fitness may be estimated using a sample of the training set. Although the fitness would change over different samples, EAs are known to search well using such noisy evaluations. There are three main variants of the training method: • Start from a random population and use the weights found by the EA in the network without any further refinement (Caudell and Dolan,1989; Montana and Davis, 1989; Whitley and Hanson, 1989). This method may be particularly useful when the activation function of the neurons is non-differentiable. • Use backpropagation or other methods to refine the weights found by the EA (Kitano, 1990; Skinner and Broughton, 1995). The motivation for this approach is that EAs quickly identify promising regions of the search space, but they do not fine-tune parameters very fast. So, EAs are used to find a promising set of initial weights from which a gradient-based method can quickly reach an optimum. This involves additional passes through the training data (for each epoch of backpropagation, for example), extending the processing time per individual, but sometimes the overall training time can be reduced because fewer individuals may need to be processed. • Use the EA to refine results found by an NN learning algorithm. Although EAs do not refine solutions very fast, there have been some attempts to seed the initial population of the EA with solutions found with backpropagation (Kadaba and Nygard, 1990). These approaches suffer from several problems. First, the length of the individuals grows rapidly with the size of the network. Since adjacent layers in a network are usually fully connected, the total number of weights that need to be represented is O(n2) (where n is the number of neurons). Longer individuals usually

60 Cantú-Paz and Kamath

require larger populations, which in turn result in higher computational costs. For small networks, EAs can be used to search for good weights efficiently, but this method may not scale up to larger networks. Another drawback is the so-called permutations problem (Radcliffe, 1990). The problem is that if the order of the hidden nodes is permuted, the representation of the weights would be different, so functionally equivalent networks can be represented in various ways. Some orderings may not be very suitable for EAs that use recombination because it might disrupt some favorable combinations of weights. To ameliorate this problem, Thierens et al. (1991) suggest that incoming and outgoing weights of a hidden node should be encoded next to each other. Hancock (1992) has done some analysis that suggests that the permutation problem is not as hard as it is often presented. Later, Thierens (1995) presented an encoding that completely avoids the permutations problem. There are two basic approaches to using EAs to design the topology of an ANN: use a direct encoding to specify each connection of the network or evolve an indirect specification of the connectivity. The resulting network may be trained with a traditional learning algorithm (e.g., backpropagation), or the EA may be used to search the configuration and the weights simultaneously. The key idea behind direct encodings is that a neural network may be regarded as a directed graph where each node represents a neuron and each edge is a connection. A common method of representing directed graphs is with a binary connectivity matrix: the (i, j)-th element of the matrix is one if there is an edge between nodes i and j, and zero otherwise. The connectivity matrix can be represented in the EA simply by concatenating its rows or columns. Several researchers have used this approach successfully (e.g., Miller, Todd, and Hegde 1989; and Belew, McInerney, and Schraudolph, 1990). Using this method, Whitley, Starkweather, and Bogart (1990) showed that the EA could find topologies that learn faster than the typical fully connected feedforward network. The EA can be explicitly biased to favor smaller networks, which can be trained faster. However, since each connection is explicitly coded, the length of the individuals is O(n2), and the algorithm may not scale up to large problems. Although direct encoding is straightforward to implement, it is not a good analogy of the way things work in nature. The genome of an animal does not specify every connection in its nervous system. Instead, the genome contains instructions that—in conjunction with environmental factors—determine the final structure of the network. Many interesting combinations of EAs with NNs imitate nature’s indirect specification of nervous systems, and use a developmental approach to construct the networks. A simple method to avoid specifying all the connections is to commit to a particular topology (feedforward, recurrent, etc.) and a particular learning algorithm, and then use the EA to set the parameters that complete the network specification. For example, with a fully connected feedforward topology, the EA may be used to search for the number of layers and the number of neurons per layer. Another example would be to code the parameters of a particular learning algorithm

Evolutionary Algorithms in Data Mining 61

such as the momentum and learning rate for backpropagation (Belew, McInerney, and Schraudolph, 1990; Marshall and Harrison, 1991). By specifying only the parameters for a given topology, the coding is very compact and well suited for a evolutionary algorithm, but this method is constrained by the initial choice of topology and learning algorithm. A more sophisticated approach to indirect representations is to use a grammar to encode rules that govern the development of a network. Kitano (1990) introduced the earliest grammar-based approach. He used a connectivity matrix to represent the network, but instead of coding the matrix directly in the chromosome, he used a graph rewriting grammar to generate the matrix. The chromosomes contain rules that rewrite scalar matrix elements into 2 x 2 matrices. To evaluate the fitness, the rules are decoded from the chromosomes, and the connectivity matrix is created applying all the rules that match non-terminal symbols. Then, the connectivity matrix is interpreted to build a network, which is trained by backpropagation, and the fitness is measured. Perhaps the major drawback in this approach is that the size of the network must be 2i (where i is any non-negative integer that represents the number of rewriting steps), because after each rewriting step the size of the matrix doubles in each dimension. Another example of a grammar-based developmental system is the work of Boers and Kuiper (1992). Each individual contains the rules for one Lindenmayer system (L-system), which are parallel string rewriting grammars (every applicable rule is used at each derivation step). L-systems have been used to model the development of living organisms. To evaluate the fitness, the system uses the rules of the L-system to generate a string that represents the structure of a neural network. Then, the network is trained using backpropagation and the fitness is determined by combining the accuracy of the classifications on separate training and testing sets. Gruau (1992) invented a “cellular encoding” method to evolve the topology and the weights of the network simultaneously. His objective was to produce a coding for modular networks that would scale up to large and interesting problems naturally. Gruau (1994) proved that cellular encoding has many desirable properties for a neural network representation. For example, all possible networks are representable, and only valid networks result after applying the genetic operators. Each cell in the network has a copy of a grammar tree (a grammar encoded as a tree), a read head, and some internal registers. The development of the network starts with a single cell. The grammar tree contains instructions that make the cell divide, increment or decrement its bias or some weights, cut a connection, and stop reading the tree. At each step, every cell executes the instruction pointed to by its head, and the development finishes when all the cells reach stop instructions. Gruau solved large parity and symmetry problems, and his approach compares favorably to direct encoding (Gruau, Whitley and Pyeatt, 1996). Nolfi, Elman, and Parisi (1994) developed another grammar-based encoding. Their objective was to simulate cell growth, migration and differentiation, three processes involved in the development of natural neural networks. Their networks may contain up to 16 types of cells, and for each type there is a rule that governs how

62 Cantú-Paz and Kamath

the cell reproduces. The rules are encoded in the chromosome, and they specify the types of the daughter cells and their relative spatial locations. After a fixed number of divisions, the cells grow artificial axons to reach other cells. Cells live in a twodimensional space that is partitioned into three regions. The developmental process begins with a cell placed near the center. The neurons that end up in the lower and upper regions serve as the inputs and outputs, respectively. The cells in the middle region function as hidden units. The grammar-based methods share several properties. First, the developmental process begins with a single cell, just as in nature. Second, all the methods are very sensitive to changes in parts of the genome that govern early development (e.g., the initial cell’s type or the first rule to be applied).

Decision Trees and Evolutionary Algorithms
Decision trees are a popular classification method because they are easy to build and experts can interpret them easily. The internal nodes represent tests on the features that describe the data, and the leaf nodes represent the class labels. A path from the root node to one of the leaves represents a conjunction of tests. Since genetic programming traditionally uses trees to represent solutions, it seems well suited for the task of finding decision trees. Koza (1992) offered an early example of this use of GP in classification, where the fitness of each decision tree is based on its accuracy on a training set. Nicolaev and Slavov (1997) extended the fitness measure to include terms related to the tree size, and determined that GP could find small trees that were comparable in accuracy to those found by C4.5 in several test cases. Folino, Spizzuti, and Spezzano (2000) demonstrate that a fine-grained GP system can find trees that are smaller and comparatively accurate to those found with C4.5 on several test problems. Their system was designed with the intention of implementing it on a parallel computer to shorten the computation time. The trees considered above used tests on a single attribute of the data. These tests are equivalent to hyperplanes that are parallel to one of the axes in the attribute space, and therefore the resulting trees are called axis-parallel. Axis-parallel trees are easy to interpret, but may be complex and inaccurate if the data is partitioned best by hyperplanes that are not axis-parallel. Oblique decision trees use linear combinations of attributes in the tests in each of the internal nodes. Cantú-Paz and Kamath (2000) used evolution strategies and genetic algorithms to find the coefficients for the tests. They used the traditional top-down construction method, where the algorithm determines the test of each node, splits the data according to the test, and applies itself recursively to each of the resulting subsets. Cantú-Paz and Kamath compared their methods against axis-parallel and other oblique tree algorithms. They found that when the data was best split by oblique hyperplanes, the evolutionary methods were in general faster and more accurate than the existing oblique algorithms, but when the target concepts were well represented by axis-parallel hyperplanes, the existing methods were superior. Other approaches to build oblique decision trees consider the entire tree at a time, just as Koza’s original method. Bot and Langdon (2000) use traditional GP

Evolutionary Algorithms in Data Mining 63

complemented with a multi-objective selection method that attempts to minimize the tree size and the classification errors simultaneously. When compared to other algorithms, the classification accuracy results were mixed, but GP was consistently slower. Venturini et al. (1997) presented an interactive evolutionary algorithm that permits the user to evaluate combinations of the attributes that describe the data. The objective of the system is to find new variables that can describe the data concisely and that can be used in a traditional classification algorithm afterwards. Each individual in the algorithm uses two GP trees to represent new variables that are a transformation of the original attributes. The two new variables can be regarded as new axes on which the training set is projected and the result is displayed as a scatter plot. All the individuals are processed in this way and presented to the user who decides which projections show some interesting structures. The selected individuals undergo crossover and mutation, and the cycle is repeated. Venturini et al. (1997) present mixed results on several data sets from the UCI repository, but suggest several interesting extensions of their system, such as allowing the user to create rules directly by specifying thresholds on the screen.

EVOLUTIONARY ALGORITHMS IN CLUSTERING
We can distinguish two major methods to apply evolutionary algorithms to clustering problems. In the first method, each position in the chromosome represents an item in the training set. The task of the EA is to find the right cluster for each data item. If the number of clusters, k, is known a priori, each position in the chromosomes can take a value in [1,k]. This method is somewhat analogous to the direct encoding of neural nets. It is easy to implement, as there is no need for special evolutionary operators, but it suffers from a severe scalability problem: the length of the individuals is exactly the size of the training set, and for large problems this option may not be practical. Examples of this approach include the work by Murthy and Chowdhury (1996). Park and Song (1998) created a variation of the direct representation. They recognized that the clustering problem could be cast as a graph-partitioning problem. The objective is to consider the items in the data set as nodes in a graph and the objective is to use a GA to find connected sub-graphs that represent clusters. Each data item has a corresponding position in the chromosomes, but the alleles are not the cluster labels, but the indices of other data items. So if position i contains the value j, there is a link in the graph between the nodes that represent items i and j. The values for each position are limited to the nearest neighbors of each data item, and the number of neighbors is an input parameter to the algorithm. Park and Song tested their algorithm on the problem of generating a thesaurus of word meanings and compared their results to other clustering algorithms. An advantage of their algorithm is that the number of clusters does not have to be specified in advance. The

64 Cantú-Paz and Kamath

problem of scalability is still present as the individual’s length is the size of the data set, and since this algorithm computes the nearest neighbors of all the data items, the algorithm may not be very efficient on data sets with many dimensions. Another use of EAs in clustering is to identify the cluster centroids. Hall, Ozyurt and Bezdek (1999) described an evolutionary approach where the individuals represent the coordinates of the centers of the k desired clusters. They used a standard genetic algorithm, trying both floating point and binary representations, but did not observe a clear advantage to either approach. Their study considered both fuzzy and hard clustering, and their fitness functions included terms to penalize degenerate solutions (with fewer than k clusters). Hall et al. compared their algorithm to conventional clustering algorithms (FCM/HCM) and observed that their evolutionary approach usually found solutions as good as the other methods, and avoided degenerate solutions when the other methods did not. They experimented with adaptive methods to set the parameters of the algorithm and found the results encouraging. This is important because it facilitates the use of the evolutionary algorithm in practice. However, Hall et al. also reported that the execution time of the evolutionary method can take up to two orders of magnitude more than FCM/ HCM. Despite the efficiency problem, Hall et al. noted that the evolutionary approach could be useful to evaluate other clustering fitness functions for which no optimization method has been devised. A similar approach is to use the EA to search for the optimal initial seed values for the cluster centroids and then run a clustering algorithm (Babu and Murty, 1993). As in other problems, in clustering we can use domain knowledge in several ways to try to improve the performance of the algorithm. For example, we could design specialized evolutionary operators or we can hybridize the evolutionary algorithm with a conventional clustering algorithm. Fränti et al. (1997) tried both approaches. Their clustering algorithm represented the coordinates of the centroids. They used five different crossover methods (three of their own invention) and after crossover each new individual underwent two iterations of the k-means clustering algorithm. Later they extended the algorithm to include self-adaptation of parameters and automatic choice of operators (Kivijärvi, 2000). Fränti et al. (1997) observed that adding the k-means iterations was critical for obtaining good results, and although there can be a considerable increase of the computation time if many iterations are used, their experiments suggest that only a few iterations are needed. Along these lines, Krishna and Murty (1999) used a single k-means iteration. The hybridization raises the question of how to allocate the computing time: should we use many generations of the EA and a few iterations of the local methods, or run the EAs for a few generations and use the local methods to improve the solutions considerably? As we saw in the neural networks section, another way to use domain knowledge in GAs is to initialize the population with good known solutions. One way to do this in clustering problems would be to use the output of independent runs of the k-means algorithm to create at least part of the initial population (Murthy and Chowdhury, 1996).

Evolutionary Algorithms in Data Mining 65

In principle, the centroid-based representation has the advantage that the individuals are shorter, because they only need to represent the coordinates of the k centroids. This means that the length of the individuals is proportional to the dimensionality of the problem and not to the size of the training set as in the partitioning-based encoding. In addition, using the GA to assign the right cluster labels to each data item allows more flexibility in the shape of the clusters. For example, nonadjacent regions of the data space can belong to the same cluster.

PERFORMANCE OF EVOLUTIONARY ALGORITHMS
Evolutionary algorithms are proving themselves in solving real problems in data mining, especially in cases where the data is noisy, or requires the solution of a multi-objective optimization problem. However, they are not without their drawbacks. A key concern expressed by several authors is that evolutionary algorithms can be very time consuming. For example, Poli (1996) comments that the tremendous computational demands of fitness evaluations in the use of genetic programming for image processing has prevented researchers from doing an extensive study of the behavior of these algorithms in solving real problems. A similar sentiment is expressed by Ebner and Zell (1999) who observe that the evolution of an image processing operator typically takes several days to complete on a single PC, making it difficult to use their algorithm in an adaptive vision system that adapts to changing environmental conditions. Several approaches have been proposed to address this need for enormous computational resources. For example, Mandava, Fitzpatrick, and Pickens (1989) and Poli (1996) suggest that, in image processing, instead of using all pixels in an image to evaluate the fitness of an operator, only a small sample of pixels could be used in order to reduce the time required. Other authors, such as Bhanu, Lee, and Ming (1995) keep a global population of fit individuals, which can be used to seed the genetic algorithm for each image. This not only makes the system adaptive, but also reduces the computation time. Bhandarkar, Zhang, and Potter (1994) propose exploiting the inherent parallelism in genetic algorithms to reduce the time for edge detection operators in image analysis. Researchers using evolutionary algorithms for feature selection also echo this need for extensive computer resources. Since the approach requires the classification step to be performed for each fitness evaluation, it can be time consuming. A common solution in this case is the use of parallel processing (Punch et al., 1993). Of course, sampling and parallel processing can also aid in classification and clustering problems. In addition, in previous sections we also hinted that using representations that are more appropriate for the problems at hand or designing custom operators could result in a more scalable algorithm. For example, directly encoding each weight in a neural network or each possible assignment of a data item to a cluster will not scale up to large and interesting problems.

66 Cantú-Paz and Kamath

RESOURCES FOR EVOLUTIONARY ALGORITHMS IN DATA MINING
With evolutionary algorithms rapidly gaining acceptance in data mining, there are a variety of resources that the interested researcher can refer to for the most recent advances in the field. There are several conferences held on the various topics covered in this chapter, including the EvoIASP conferences organized by the Working Group on Evolutionary Algorithms in Image Analysis and Signal Processing (2001), Knowledge Discovery and Data Mining (KDD), International Conference on Machine Learning (ICML), and the Genetic and Evolutionary Computation Conference (GECCO). The journals Evolutionary Computation, Genetic Programming and Evolvable Machines, IEEE Transactions on Systems, Man, and Cybernetics, and the IEEE Transactions on Evolutionary Computation are also excellent resources. There are several resources available on the Internet as well. A comprehensive bibliography on genetic algorithms by Alander (2000) includes their use in classifier systems, image processing, signal processing, neural networks, etc.

SUMMARY
In this survey chapter, we have shown that evolutionary algorithms can complement many existing data mining algorithms. They can extract and select features, train neural networks, find classification rules, and build decision trees. Evolutionary algorithms are particularly useful when the problems involve the optimization of functions that are not smooth and differentiable, or functions where the objective value changes over time, which can happen in data mining as more data becomes available or if sampling is used to reduce the computation time. While evolutionary algorithms enable us to solve some difficult problems, they come at a price, namely a need for high computational resources. However, with processors becoming faster and the increasing acceptance of parallel systems, we hope that this problem will be minimized in the future.

ACKNOWLEDGMENTS
We would like to thank the anonymous reviewers and the editors for their constructive comments on an earlier draft of this chapter. UCRL-JC-141872. This work was performed under the auspices of the U.S. Department of Energy by the University of California Lawrence Livermore National Laboratory under contract No. W-7405-Eng-48.

Evolutionary Algorithms in Data Mining 67

REFERENCES
Alander, J. (2000). Indexed bibliography of genetic algorithms and artificial intelligence. Technical Report No. 94-1-AI. University of Vaasa, Department of Information Technology and Production Economics. ftp://ftp.vaasa.fi/cs/report94-1/gaAIbib.ps.Z. Augier, S., Venturini, G., Kodratoff, Y. (1995). Learning first order rules with a genetic algorithm. In Proceedings of the First International Conference on Knowledge Discovery in Databases. (pp. 21-26). Menlo Park, CA: AAAI Press. Babu, G. P., & Murty, M. N. (1993). Clustering with evolution strategies. Pattern Recognition, 27 (2), 321-329. Belew, R., McInerney, J., & Schraudolph, N. (1990). Evolving networks: Using the genetic algorithm with connectionist learning (Tech. Rep. No. CS90-174). San Diego: University of California, Computer Science and Engineering Department. Bhandarkar, S., Zhang, Y., & Potter, W. (1994). An edge detection technique using genetic algorithm based optimization. Pattern Recognition 27, 1159-1180. Bhanu, B. & Lee, S. (1994). Genetic learning for adaptive image segmentation. Boston, MA: Kluwer Academic Publishers. Bhanu, B., Lee, S. & Ming, J. (1995). Adaptive image segmentation using a genetic algorithm. IEEE Transactions on Systems, Man, and Cybernetics, 25, 1543-1567. Boers, J. W., & Kuiper, H. (1992). Biological metaphors and the design of modular artificial neural networks. Unpublished Master’s Thesis, Leiden University, The Netherlands. Booker, L. B., Goldberg, D. E., & Holland, J. H. (1989). Classifier systems and genetic algorithms. Artificial Intelligence, 40 (1/3), 235-282. Bot, M.C.J. & Langdon, W.B. Application of genetic programming to induction of linear classification trees. In European Conference on Genetic Programming, (pp. 247-258). Berlin: Springer-Verlag. Branke, J. (1995). Evolutionary algorithms for neural network design and training (Technical Report). Karlsruhe, Germany: Institute AIFB, University of Karlsruhe. Brill, F.Z., Brown, D.E., & Martin, W.N. (1990) Genetic algorithms for feature selection for counterpropagation networks. (Tech. Rep. No. IPC-TR-90-004). Charlottesville, VA: University of Virginia, Institute of Parallel Computation. Brotherton, T.W., & Simpson, P.K. (1995). Dynamic feature set training of neural nets for classification. In McDonnell, J.R., Reynolds, R.G., & Fogel, D.B. (Eds.). Evolutionary Programming IV (pp. 83-94). Cambridge, MA: MIT Press. Brumby, S., Theiler, J., Perkins, S., Harvey, N., Szymanski, J., Bloch, J. and Mitchell, M., (1999). Investigation of image feature extraction by a genetic algorithm. Bellingham, WA: Procedings of the International Society for Optical Engineering, vol. 3812, 24-31 Burl, M., Asker, L., Smyth, P., Fayyad, U., Perona, P., Crumpler, L, & Aubele, J. (1998). Learning to recognize volcanoes on Venus. Machine Learning, 30, 165-195. Cagnoni S., Dobrzeniecki, A., Poli, R., & Yanch, J. (1997). Segmentation of 3D medical images through genetically-optimized contour-tracking algorithms. Univ. of Birmingham School of Computer Science Tech. Report CSRP-97-28. Cantú-Paz, E., & Kamath, C. (2000). Using evolutionary algorithms to induce oblique decision trees. In Whitley, D., Goldberg, D. E., Cantú-Paz, E., Spector, L., Parmee, L., & Beyer, H.-G. (Eds.), Proceedings of the Genetic and Evolutionary Computation Conference 2000 (pp. 1053-1060). San Francisco, CA: Morgan Kaufmann Publishers.

68 Cantú-Paz and Kamath

Caudell, T. P., & Dolan, C. P. (1989). Parametric connectivity: Training of constrained networks using genetic algorithms. In Schaffer, J. D. (Ed.), Proceedings of the Third International Conference on Genetic Algorithms (pp. 370-374). San Mateo, CA: Morgan Kaufmann. De Jong, K. A., Spears, W. M., & Gordon, D. F. (1993). Using genetic algorithms for concept learning. Machine Learning, 13, 161-188. Dietterich, T., (2000). An experimental comparison of three methods for constructing ensembles of decision trees: bagging, boosting, and randomization. Machine Learning, 40 (2), 139-158. Ebner, M. & Zell, A. (1999). Evolving a task specific image operator. In Poli, R. et al. (ed.), Evolutionary Image Analysis, Signal Processing and Telecommunications, First European Workshop (pp.74-89). Berlin: Springer-Verlag. Fayyad, U., Piatetsky-Shapiro, G., Smyth, P. & Uthurusamy, R. (1996). Advances in knowledge discovery and data mining. Menlo Park, CA: AAAI Press/ The MIT Press. Folino, G., Pizzuti, C. & Spezzano, G. (2000). Genetic programming and simulated annealing: A hybrid method to evolve decision trees. In Poli, R., Banzhaf, W., Langdon, W. B., Miller, J., Nordin, P., & Fogarty, T. C. (Eds.), Genetic Programming: Third European Conference (pp. 294-303). Berlin: Springer-Verlag. Frakes, W.B. & Baeza-Yates, R. (1992). Information Retrieval: Data Structures and Algorithms. Englewood Cliffs, NJ: Prentice Hall. Fränti, P., Kivijärvi, J., Kaukoranta, T., & Nevalainen, O. (1997). Genetic algorithms for large-scale clustering problems. The Computer Journal, 40 (9), 547-554. Frey, P. W., & Slate, D. J. (1991). Letter recognition using Holland-style adaptive classifiers. Machine Learning, 6 , 161-182. Giordana, A., & Neri, F. (1995). Search-intensive concept induction. Evolutionary Computation, 3 (4), 375-416. Goldberg, D. E. (1983). Computer-aided gas pipeline operation using genetic algorithms and rule learning. Dissertation Abstracts International, 44 (10), 3174B. Doctoral dissertation, University of Michigan. Goldberg, D. E. (1989). Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley. Gruau, F. (1992). Cellular encoding of genetic neural networks (Tech. Rep. No. 92-21). Lyon Cedex, France: Ecole Normale Superieure de Lyon. Gruau, F. (1994). Neural network synthesis using cellular encoding and the genetic algorithm. Unpublished doctoral dissertation, L’Universite Claude Bernard-Lyon I. Gruau, F., Whitley, D., & Pyeatt, L. (1996). A comparison between cellular encoding and direct encoding for genetic neural networks. In Proceedings of the First Annual Conference on Genetic Programming (pp. 81-89). Cambridge, MA: MIT Press. Guerra-Salcedo, C. & Whitley, D. (1999). Genetic approach to feature selection for ensemble creation. Proceedings of the Genetic and Evolutionary Computation Conference, 236-243. Hall, L., Ozyurt, B., & Bezdek, J. (1999). Clustering with a genetically optimized approach. IEEE Transactions on Evolutionary Computation, 3(2), 103-112. Hancock, P. J. B. (1992). Recombination operators for the design of neural nets by genetic algorithm. In Männer, R., & Manderick, B. (Eds.), Parallel Problem Solving from Nature, 2 (pp. 441-450). Amsterdam: Elsevier Science. Ho, T. (1998). The random subspace method for constructing decision forests. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(8), 832-844.

Evolutionary Algorithms in Data Mining 69

Holland, J. H. (1975). Adaptation in natural and artificial systems. Ann Arbor, MI: University of Michigan Press. Jackson, J. E. (1991). A user’s guide to principal components. New York, NY: John Wiley & Sons. Kadaba, N., & Nygard, K. E. (1990). Improving the performance of genetic algorithms in automated discovery of parameters. Machine Learning: Proceedings of the Seventh International Conference, 140-148. Kamath, C. (2001). On mining scientific data sets. To appear in Data Mining in Scientific and Engineering Applications, Norwell, MA: Kluwer Academic Publishers. Kitano, H. (1990). Designing neural networks using genetic algorithms with graph generation system. Complex Systems, 4 (4), 461-476. Kivijärvi, J., Fränti, P., & Nevalainen, O. (2000). Efficient clustering with a self-adaptive genetic algorithm. In Whitley, D., Goldberg, D. E., Cantú-Paz, E., Spector, L., Parmee, L., & Beyer, H.-G. (Eds.), Proceedings of the Genetic and Evolutionary Computation Conference 2000 (pp. 377). San Francisco, CA: Morgan Kaufmann Publishers. Koza, J. R. (1992). Genetic programming: on the programming of computers by means of natural selection. Cambridge, MA: The MIT Press. Krishna, K., & Murty, M. N. (1999). Genetic k-means algorithm. IEEE Transactions on Systems, Man, and Cybernetics-Part B , 29 (3), 433-439. Langley, P. & Simon, H. A. (1995). Applications of machine learning and rule induction. Communications of the ACM, 38 (11), 55-64. Mandava, V., Fitzpatrick, J. & Pickens, D. (1989). Adaptive search space scaling in digital image registration. IEEE Transactions on Medical Imaging, 8, 251-262. Marshall, S.J., & Harrison, R.F. (1991) Optimization and training of feedforward neural networks by genetic algorithms. In Proceedings of the Second International Conference on Artificial Neural Networks and Genetic Algorithms (pp. 39-43). Berlin: SpringerVerlag. Miller, G. F., Todd, P. M., & Hegde, S. U. (1989). Designing neural networks using genetic algorithms. In Schaffer, J. D. (Ed.), Proceedings of the Third International Conference on Genetic Algorithms (pp. 379-384). San Mateo, CA: Morgan Kaufmann. Montana, D. J., & Davis, L. (1989). Training feedforward neural networks using genetic algorithms. In Proceedings 11th International Joint Conference on Artificial Intelligence (pp. 762—767). San Mateo, CA: Morgan Kaufmann. Murthy, C. A., & Chowdhury, N. (1996). In search of optimal clusters using genetic algorithms. Pattern Recognition Letters, 17, 825-832. Nikolaev, N. I., & Slavov, V. (1998). Inductive genetic programming with decision trees. Intelligent Data Analysis, 2 (1). Nolfi, S., Elman, J. L., & Parisi, D. (1994). Learning and evolution in neural networks (Tech. Rep. No. 94-08). Rome, Italy: Institute of Psychology, National Research Council. Park, Y., & Song, M. (1998). A genetic algorithm for clustering problems. In Koza, J. R., Banzhaf, W., Chellapilla, K., Deb, K., Dorigo, M., Fogel, D. B., Garzon, M. H., Goldberg, D. E., Iba, H., & Riolo, R. L. (Eds.). Genetic Programming 98 (pp. 568-575). San Francisco: Morgan Kaufmann Publishers. Poli, R., (1996). Genetic programming for feature detection and image segmentation. In Fogarty, T. (ed.), Evolutionary Computing, in Lecture Notes in Computer Science, number 1143, pp 110—125. Springer-Verlag. Punch, W., Goodman, E., Pei, M., Lai, C., Hovland, P. & Enbody, R. (1993). Further research on feature selection and classification using genetic algorithms, In Proceedings

70 Cantú-Paz and Kamath

of the Fifth International Conference on Genetic Algorithms, 557-564. Radcliffe, N. J. (1990). Genetic neural networks on MIMD computers. Unpublished doctoral dissertation, University of Edinburgh, Scotland. Sherrah, J., Bogner, R. & Bouzerdoum, B. (1996). Automatic selection of features for classification using genetic programming. In Proceedings of the 1996 Australian New Zealand Conference on Intelligent Information Systems, Adelaide, Australia, November 1996, 284 - 287. Siedlecki, W. & Sklansky, J. (1989). A note on genetic algorithms for large-scale feature selection. Pattern Recognition Letters (10), pp 335-347. Skinner, A., & Broughton, J.Q. (1995). Neural networks in computational material science: training algorithms. Modeling and Simulation in Material Science and Engineering, 3, 371-390. Smith, S. F. (1980). A learning system based on genetic adaptive algorithms. Dissertation Abstracts International, 41 , 4582B. (University Microfilms No. 81-12638). Smith, S. F. (1983). Flexible learning of problem solving heuristics through adaptive search. In Proceedings of the 8th International Joint Conference on Artificial Intelligence (pp. 422-425). Stanhope, S. & Daida, J. (1998). Genetic programming for automatic target classification and recognition in synthetic aperture radar imagery. In Evolutionary Programming VII: Proceedings of the Seventh Annual Conference on Evolutionary Programming, V.W. Porto, N. Saravan, D. Waagen, and A.E. Eiben (Eds.). Berlin: Springer-Verlag, pp. 735744. Tackett, W. (1993). Genetic Programming for Feature Discovery and Image Discrimination, In Proceedings of the Fifth International Conference on Genetic Algorithms, Morgan Kaufmann Publishers, 303 – 309. Tan, H., Gelfand, S. & Delp, E. (1989). A comparative cost function approach to edge detection. IEEE Transactions on Sytems, Man, and Cybernetics 19, 1337-1349. Thierens, D., Suykens, J., Vanderwalle, J., & Moor, B.D. (1991). Genetic weight optimization of a feedforward neural network controller. In Proceedings of the Second International Conference on Artificial Neural Networks and Genetic Algorithms (pp. 658-663). Berlin: Springer-Verlag. Thierens, D. (1995). Analysis and design of genetic algorithms. Unpublished doctoral dissertation. Leuven, Belgium: Katholieke Universiteit Leuven. Vafaie, H. and DeJong, K. (1998). Feature space transformation using genetic algorithms. IEEE Intelligent Systems and their Applications, 13(2), 57-65. Venturini, G., Slimane, M., Morin, F., & Asselin de Beauville, J.-P. (1997). On using interactive genetic algorithms for knowledge discovery in databases. In Bäck, T. (Ed.), Proceedings of the Seventh International Conference on Genetic Algorithms (pp. 696703). San Francisco: Morgan Kaufmann. Weeks, A. (1996). Fundamentals of electronic image processing. Bellingham, WA: The International Society for Optical Engineering Press. Whitley, D. (1995). Genetic algorithms and neural networks. In Winter, G., Periaux, J., Galan, M., & Cuesta, P. (Eds.), Genetic Algorithms in Engineering and Computer Science (Chapter 11, pp. 203-221). Chichester: John Wiley and Sons. Whitley, D., & Hanson, T. (1989). Optimizing neural networks using faster, more accurate genetic search. In Schaffer, J. D. (Ed.), Proceedings of the Third International Conference on Genetic Algorithms (pp. 391-397). San Mateo, CA: Morgan Kaufmann. Whitley, D., Starkweather, T., & Bogart, C. (1990). Genetic algorithms and neural

Evolutionary Algorithms in Data Mining 71

networks: Optimizing connections and connectivity. Parallel Computing, 14 , 347-361. Wilson, S. W., & Goldberg, D. E. (1989). A critical review of classifier systems. In Schaffer, J. D. (Ed.), Proceedings of the Third International Conference on Genetic Algorithms (pp. 244-255). San Mateo, CA: Morgan Kaufmann. Wilson, S. W. (1995). Classifier fitness based on accuracy. Evolutionary Computation, 3 (2), 149-175. Wilson, S. W. (2000a). Mining oblique data with XCS. IlliGAL Technical Report No 2000028, University of Illinois at Urbana-Champaign. Wilson, S. W. (2000b). State of XCS classifier system research. In Lanzi, P., Stolzmann, W., & Wilson, S. W. (Eds.), Learning Classifier Systems: From Foundations to Applications. Berlin: Springer-Verlag. Yang, J. and Honavar, V. (1997). Feature subset selection using a genetic algorithm, Proceedings of the Second Annual Conference on Genetic Programming, pp 380-385. Yao, X. (1999). Evolving artificial neural networks. Proceedings of the IEEE, 87 (9), 14231447.

72 de la Iglesia and Rayward-Smith

Chapter IV

The Discovery of Interesting Nuggets Using Heuristic Techniques
Beatriz de la Iglesia Victor J. Rayward-Smith University of East Anglia, UK Knowledge Discovery in Databases (KDD) is an iterative and interactive process involving many steps (Debuse, de la Iglesia, Howard & Rayward-Smith, 2000). Data mining (DM) is defined as one of the steps in the KDD process. According to Fayyad, Piatetsky-Shapiro, Smyth and Uthurusamy (1996), there are various data mining tasks including: classification, clustering, regression, summarisation, dependency modeling, and change and deviation detection. However, there is a very important data mining problem identified previously by Riddle, Segal and Etzioni (1994) and very relevant in the context of commercial databases, which is not properly addressed by any of those tasks: nugget discovery. This task has also been identified as partial classification (Ali, Manganaris & Srikant, 1997). Nugget discovery can be defined as the search for relatively rare, but potentially important, patterns or anomalies relating to some pre-determined class or classes. Patterns of this type are called nuggets. This chapter will present and justify the use of heuristic algorithms, namely Genetic Algorithms (GAs), Simulated Annealing (SA) and Tabu Search (TS), on the data mining task of nugget discovery. First, the concept of nugget discovery will be introduced. Then the concept of the interest of a nugget will be discussed. The necessary properties of an interest measure for nugget discovery will be presented. This will include a partial ordering of nuggets based on those properties. Some of the existing measures for nugget discovery will be reviewed in light of the properties established, and it will be shown that they do not display the required properties. A suitable evaluation function for nugget discovery, the fitness measure, will then be discussed and justified according to the required properties.
Copyright © 2002, Idea Group Publishing.

Interesting Nuggets Using Heuristic Techniques 73

A number of algorithms, including the heuristic algorithms, will be introduced briefly. Experiments using those algorithms on some of the UCI repository databases (Merz & Murphy, 1998) will be reported. Conclusions about the suitability of the different algorithms on datasets with different characteristics can be drawn from these experiments. The three heuristics–Genetic Algorithms, Simulated Annealing and Tabu Search–will also be compared in terms of their implementation, results and performance.

THE DATA MINING TASK OF NUGGET DISCOVERY
In any KDD project, one of the first decisions that has to be made is what is the primary task that the user wants to achieve. The “high level” primary tasks of the KDD process are defined in the literature (Fayyad, Piatetsky-Shapiro & Smyth, 1996) as prediction and description. Prediction involves using some variables or fields in the database to predict unknown or future values of other variables of interest. Description focuses on finding human-interpretable patterns describing the data. The main distinction between prediction and description is who interprets the discovered knowledge. In prediction the system interprets the knowledge, whereas in description, it is the analyst or the user that interprets it. Once the high-level goal of the process is established, the particular data mining task to be undertaken has to be chosen. This is known as the “low-level” task. As mentioned in the previous section, the most commonly recognised tasks are: classification, clustering, regression, summarisation, dependency modeling, and change and deviation detection. We will focus on the task of classification. The type of data used for classification contains a pre-defined class assignment for each case or record in the database. This type of data is often encountered in commercial databases. The high-level goal of the user, when analysing this type of data, is sometimes prediction. This is when the user wants to infer a model that will allow him/her to assign a class to new data. For a predictive goal, a complete classification (that is, a complete model that assigns a class to each case or record in the database) may be necessary and appropriate. This would definitely fall under the heading of a classification task. An example of a classification task may be to build a decision tree (Quinlan, 1986) to differentiate between those customers that represent a good credit risk and those that do not, based on a database of financial information. The database must contain some classification of customers into good and bad credit risks, based on their past performance. When the high-level goal is descriptive, it is not always necessary to provide a complete classification. This may indeed be detrimental to obtaining interesting and understandable patterns. The objective in many cases is to identify relatively rare, but potentially important, patterns or anomalies relating to some class or classes. We will call this type of pattern a nugget, and hence we will call this task nugget discovery. For instance, in the previous example, the bank may be

74 de la Iglesia and Rayward-Smith

particularly interested in understanding what characterises the worst type of loan defaulters, and they may be a minority in the database. In that case, building a complete classifier could seriously obscure the nuggets that we are looking for. Of course, a decision tree, for example, will contain nuggets but, as Quinlan (1987) explains, algorithms that produce such models often produce very large and complex knowledge structures that are suitable for the goal of prediction, but cannot be easily interpreted by humans. For any sizeable database, a complete classification that is accurate will contain many specific patterns that describe noise, or uninteresting cases. Work is required to extract nuggets that are truly interesting (according to some pre-defined measure) for a particular class. We will have to look through the tree to extract a few good branches representing the knowledge in which we are interested. Furthermore, complete classifications are often assessed in terms of the overall accuracy on classifying new instances (those reserved for testing the model), and the metrics used to build the model are often biased towards overall accuracy. But high accuracy of a complete classification model does not guarantee accuracy in classifying all of the classes. Hence a complete classification may not contain interesting nuggets for all classes, and complete classification algorithms may guide the search towards an overall good classification, and not towards interesting nuggets. Nugget discovery and complete classification are different tasks, with different goals. It is worth noting here that there is another class of algorithms that may also be used to deliver nuggets: association rule algorithms (Agrawal, Imielinski & Swami, 1993; Agrawal Mannila, Srikant, Toivonen & Verkamo, 1996). They were developed for transaction data (also known as basket data). This type of data contains information on transactions, for example, showing items that have been purchased together. Association rule mining algorithms deliver a set of association rules, often containing all associations between items above certain support and confidence thresholds. The association rules are generally of the form “customers that purchase bread and butter also get milk, with 98 % confidence.” This type of rule is not constrained to have a particular value as output, or indeed to refer to any particular attribute. Delivering all association rules in transactional data is a suitable approach, since transactional data tends to contain few associations. Classification datasets, however, tend to contain many associations, so delivering all association rules for a classification dataset results in output of overwhelming size. Also classification datasets often contain many numeric continuous attributes, and association rule induction algorithms are not designed to cope with this type of data. Therefore, although association rules can be used for classification (Bayardo, 1997; Liu, Hsu & Ma, 1998), and even for partial classification or nugget discovery (Ali et al., 1997), work is required to adapt the association algorithms to cope with classification data, and with the problem of partial classification or nugget discovery.

Interesting Nuggets Using Heuristic Techniques 75

DEFINING A NUGGET
The type of nuggets that will be sought (Rayward-Smith, Debuse & de la Iglesia, 1995) are simple rules of the following format: α⇒β where α, the precondition, or antecedent, of the rule represents a conjunction or disjunction of tests on the attributes or fields of the database, D, and β, the postcondition, or consequent, of the rule, represents the class assignment. In the case of conjunctive rules, the antecedent is a conjunction of the following form: α1 ∧ α2 ∧ … ∧ αm. For a categorical attribute, a conjunct, αi, is a test that can take the following forms: • Simple value: ATj= v, where ATj represents the jth attribute, and v ∈ DomATj, 1≤ j ≤ n (n is the number of attributes in the database). A record x meets this test if x[ATj] = v. • Subset of values: ATj ∈ {v1,…, vk}, where {v1,…, vk} ∈ DomATj 1≤ j ≤ n. A , record x satisfy this test if x[ATj] ∈{v1,…, vk}. • Inequality test: ATj ≠v, 1≤ j ≤ n . A record x meets this test if x[ATj] ≠ v. For a numeric attribute a conjunct, αi, is a test that can take the following form: • Simple value: ATj = v, as for categorical attributes. • • Binary partition: ATj ≤ v or ATj ≥ v, v ∈ DomATj and 1≤ j ≤ n . A record x meets these tests if x[ATj] ≤ v or x[ATj] ≥ v respectively. Range of values: v1 ≤ ATj ≤ v2 or ATj ∈ [v1,v2], v1,v2 ∈ DomATj and 1≤ j ≤ n. A record x meets this test if v1 ≤ x[ATj] ≤ v2.

A record, x, meets a conjunction of tests, α1 ∧ α2 ∧ … ∧ αm, if x satisfies all the tests α1 α2, …, αm. In the case of disjunctive preconditions, x will have to satisfy , some (at least one) tests. The consequent of the rule is just the specification of the class that the rule is describing, chosen from a set of predefined classes. For the purpose of simplicity, we can assume that the problem to be solved is always a two-class problem. Any other problem with more than two classes can simply be transformed to the twoclass problem by labelling as positive examples any records that belong to the class of interest and as negative examples all other records. If the class of interest changes, then the labelling is changed to reflect this. This simplification is perfectly valid in nugget discovery, since the search is directed to find a good description of a class, so as long as the target class is distinguishable from other classes, a description of

76 de la Iglesia and Rayward-Smith

it can be found. Note that in nugget discovery, we are interested in describing the target class as accurately D B as possible, and so an accurate A description of the negative examples, C although interesting in some contexts, is not the required output. For the simple rule described, we can define some simple measures based on the cardinalities of the different sets defined by the rule. Each conjunct defines a set of data points (or records) for which the test specified by the conjunct is true, and the intersection of all those sets, or the set of points for which all the conjuncts are true is the support of the rule in the database. This is represented in Figure 1. We will refer to this set as A, and to its cardinality by |A| = a. The set of data points for which the consequent of the rule is true, or, in other words, the set of data points that belong to the class specified by the rule, will be referred to as B, and |B| = b. Finally, the set of points for which both the antecedent and consequent of the rule are true will be called C, and |C| = c. In summary, A = {x | α(x) }, B = {x | β(x) } and C = {x | α(x) ∧ β(x) }. Note that c ≤ a and c ≤ b , as C ⊆ A and C ⊆ B. Also, a ≤ d and b ≤ d, since A, B ⊆ D.
Figure 1: Venn diagram for simple rule

Properties of a Nugget
On the simple nuggets just introduced, we can define some important properties. The properties of a nugget can be expressed in terms of a, b, c and d. In fact, most of the interest measure that are described in the following section either use some of these properties on their own, or represent combinations of them. The fundamental properties of a nugget or rule, r, of the form α ⇒ β are:

Accuracy (Confidence): Acc(r ) =

c a

This measure represents the proportion of records for which the prediction of the rule (or model in the case of a complete classification) is correct, and it is one of the most widely quoted measures of quality, particularly in the context of complete classification.

Applicability (Support): App(r ) =

a d

This is the proportion of records of the whole database for which the rule applies. This measure is often quoted in conjunction with accuracy, to establish the quality of individual rules.

Interesting Nuggets Using Heuristic Techniques 77

Coverage: Cov (r ) =

c b

This measure is defined here as the proportion of the target class covered by the rule. When the target class represents a small proportion of the database, the coverage is more expressive than the applicability of a nugget because it gives a more accurate view of the worth of a nugget. In such case, high coverage of the class may be indicative of an interesting rule, which may still have very low applicability due to the size of the class under scrutiny.

Default Accuracy:

DefAcc(class) =

b d

This measure represents the proportion of the database that belongs to the target class, or class of interest, and it is equivalent to the accuracy of the default rule for the given class (that is, the rule that has no pre-conditions and predicts the target class). The accuracy of the default rule gives a yardstick by which to measure other rules predicting the same class. We expect a nugget to be of interest for a given class if the accuracy is considerably higher than that of the default rule for that class. This leads to the next measure.

Loading:

Load (r ) =

Acc(r ) − DefAcc(class ) 1 − DefAcc(class )

This measure is an alternative to the accuracy measure. It uses the default accuracy of the target class to “normalise” accuracy in terms of it. It is sometimes used as an alternative to accuracy because it can be more representative than a simple accuracy measure when the target class accounts for a small proportion of the database. For example, a rule that has low accuracy may be interesting if the loading is high. In order to assess the quality of a nugget some of the above properties may be examined. Accuracy and coverage are commonly used in the literature. If the accuracy and coverage of a nugget are known, as the default accuracy of the class is also normally known, it is not difficult to calculate the applicability or loading of the same nugget. So once results are presented using one set of measures, it would be a matter of some simple calculations to present them in the alternative way. The presentation below therefore uses accuracy and coverage to order rules.

A PARTIAL ORDERING OF NUGGETS
The accuracy and coverage properties of a rule are very important. In fact, they are fundamental properties of a nugget, because they allow us to establish a partial ordering, ≤ ca , of rules. The partial ordering ≤ ca can be defined as follows:
• Given rules r1 and r2, r1 < ca r2 if and only if Cov (r1) ≤ Cov (r2) and Acc (r1) < Acc(r2), or Cov (r1) < Cov (r2) and Acc (r1) ≤ Acc(r2)

78 de la Iglesia and Rayward-Smith

The partial ordering ≤ca, illustrated in Figure 2, was also proposed independently by Bayardo and Agrawal (1999). In this simple graph, the coverage of a rule is represented by the x-axis, and the accuracy is represented by the y-axis. Rules r 1 and r 2 have the same coverage with r 2 having higher accuracy. r is the “preferred” rule, 2 as it is higher in the partial ordering ≤ ca. Similarly, r 3 and r 4 have the same accuracy, but r 4 has higher coverage, so r 4 is higher in the partial ordering than r 3. r 5 has less accuracy and coverage than both r 2 and r4, and hence r 5 is lower in the partial ordering than both r 2 and r 4. This ordering is called partial because it cannot order all rules. In fact, each rule defines a rectangular area as marked by the dotted line in Figure 2, and a rule can only be ordered with respect to another if it falls within the perimeter of the other rule’s area. For example, rules r2 and r4cannot be ordered with respect to one another using ≤ca as they belong to different accuracy/coverage areas. The simple ordering of rules established by ≤ca may appear to be obvious. It seems safe to assume that with equal accuracy a rule of more coverage represents a more interesting concept. Similarly, with equal coverage, a rule of higher accuracy is a more interesting concept. The partial ordering ≤ca is therefore important and must be enforced by any measure of interest that is used to guide the search for nuggets. Surprisingly, many of the measures of interest proposed in the literature do not support this partial ordering. The partial ordering establishes that the more covering and the more accurate a rule is, the more interesting it is. However, there is often a trade-off in real-world datasets between accuracy and coverage. In commercial databases, a completely accurate description of a class can often not be found. The more general a pattern is (i.e., the higher the coverage), the lower the accuracy tends to be. Very specific patterns, capturing the behaviour of a few world entities, may achieve very high levels of accuracy. As the patterns become more general and capture the behaviour for a whole target class, we can expect the accuracy of those patterns to drop to reflect the levels of noise present in the real environment. Hence, when a completely
Figure 2: Partial rule ordering

• Also, r1 =ca r2 if and only if Cov (r1) = Cov (r2) and Acc (r1) = Acc(r2)

Acc

r3

r4 r2 r1

r5 0 r1 ≤ ca r2 r3 ≤ ca r4
Cov

r5 ≤ ca r2

r5 ≤ ca r4

r4

Interesting Nuggets Using Heuristic Techniques 79

covering and accurate description for a class cannot be found, the interest measure needs to balance the trade-off between both properties. In other words, it needs to be able to select one of the defined areas or accuracy/coverage as the target for the discovery. Interest measures should therefore contain some criteria for selecting one of the areas of accuracy/coverage as the more interesting area. Which then should be the criteria for selecting high accuracy areas or high coverage areas? The answer will vary from one application to another. For example, let us suppose that a medical database exists containing characteristics and history of patients with a particular disease. Let us also suppose that patients are divided into two classes: those that suffer the disease in its initial stages, and those that suffer it in an advanced stage. Let us assume that a drug is available, which may prevent the disease from spreading in the initial stages, but would have serious side effects for patients with the disease in an advanced stage. In this case, the description of the class “patient with disease in initial stage” to be used for the administration of the drug would have to be very accurate to be of use. In such a case, accuracy will be the most important property to be considered in an interest measure to guide the search for rules. If, however, the drug had no side effects for other patients, but was extremely effective at curing the disease if found in the initial stages, then it would be coverage of the class “patient with disease in initial stage” that should be the guiding force for nugget discovery. A measure of interest for nugget discovery must therefore have two fundamental qualities: • • It must establish the ≤ca partial ordering between any two nuggets that can be compared or ordered under such ordering. It must also allow the search to be geared towards accurate rules or highly covering rules, depending on the preferences of the user or the application needs.

MEASURES OF INTEREST
The measure of interest commonly used in algorithms to guide the search for rules are presented next. They are presented in terms of a,b,c and d, and are given for the two-class problem. The algorithms in which they are applied will be mentioned in this section, but they will be introduced in the next section: Accuracy (Confidence): Defined in the previous section, it often forms part of the rule extraction process in the form of a minimum accuracy constraint (Agrawal et al., 1996; Bayardo, Agrawal & Gunopulos, 1999), but sometimes it is used as the measure to be optimised (i.e., the measure of interest) (Fukuda, Morimoto, Morishita & Tokuyama, 1996; Rastogi & Shim, 1998). In terms of the algorithms presented later, Brute (Riddle et al., 1994) uses accuracy as a measure to rank rules (although Brute also provide other measures), 1R (Holte, 1993; NevillManning, Holmes & Witten, 1995), T2 (Auer, Holte & Maass, 1995) and Rise

80 de la Iglesia and Rayward-Smith

(Domingos, 1995, 1996) use it as a guiding criterion for the construction of a complete classification, and the Apriori algorithm (Agrawal et al., 1993, 1996) uses it in the form of a minimum accuracy constraint. Laplace Accuracy: Laplace Accuracy (Clark & Boswell, 1991) is a variation of accuracy used by CN2 (Clark & Boswell, 1991;Clark & Niblett, 1989) and other rule induction algorithms. It is defined as c +1 LapAcc (r ) = a+k where k is a number greater than 1, usually set to the number of classes in a classification problem. Conviction: This is a measure of interest defined by Brin, Rastogi and Shim (1999). It can be expressed in terms of a,b,c and d as
Conv(r ) = d −b a ( d − b) = d (1 − Acc( r )) d ( a − c)

Lift: This measure of interest is used by IBM Intelligent Miner (International Business Machines, 1997). It can be expressed as
Lift ( r ) = d Acc( r ) cd = b ab

Piatetsky-Shapiro: This measure has the name of its proposer, and was introduced by Piatetsky-Shapiro (1991). The measure can be defined as
PS (r ) = c − b a d

J Measure: The J measure was proposed by Smyth and Goodman (1992) as a theoretic measure of the information content of a rule, and it is used by the GRI algorithm. It can be defined in terms of a,b,c and d as
J (r ) =  d (a − c)   a c  cd   c  ×  × log  + 1 −  × log   a ( d − b)   a d   ab   a   

Gini Index: This measure, along with the next two measures (χ2 and entropy gain) are often used to indicate the extent to which a rule divides the data into segments whose target or class distribution is more skewed than that of the data as a whole. The Gini Index, used in the context of rule induction by Morimoto, Fukuda, Matsuzawa, Tokuyama and Yoda (1998), is also known as the Mean Squared Error(MSE). For the two-class problem, the Gini Index can be expressed in terms 2 of a,b,c and d as 2
 b   d − b   Gini ( r ) = 1 −    +   d   d    − −
2 2 a   c   a − c   × 1 −    +    d   a   a      2 2 d − a    b − c   d − a − b + c   × 1 −    +     d d −a      d − a  

Interesting Nuggets Using Heuristic Techniques 81

Entropy Gain: This measure, also known as Information Gain, behaves in an almost identical way to the Gini Index. It was the measure used initially by Quinlan (1993) in C4.5/C5. It is also used by the algorithms PART (Frank & Witten, 1998) and RIPPER (Cohen, 1995) in some of their rule building stages. The measure compares the mutual information gained by a rule, and for the two-class problem can be defined as
b b  d −b  d − b  × log Ent (r ) = − × log  +  d  d d   d   a c c a−c  a − c  + ×  × log  + × log  a  d  a a  a  + d −a  b−c  b−c  d −a−b+c  d − a − b + c  × × log    d − a × log d − a  + d d −a d −a     

χ2 (chi-square): This measure is a statistical measure often used to determine if hypothesized results are verified by an experiment. It is used to rank rules in the algorithm KnowledgeSEEKER (Biggs, de Ville & Suen, 1991; de Ville, 1990) and is provided as one of the choices in Brute. The χ2 test is again used to see whether the distribution of the classes for the records covered by a particular rule is significantly different to the overall distribution of classes in the database.
χ 2 (r ) = + d  b d d −b  × c − a  + ×  (a − c ) − a  b  d d −b  d 
2 2 2

d −b b d d   ×  (b − c ) − (d − a)  +   (d − a − b + c) − (d − a ) d  d b( d − a )  (d − a )(d − b) 

2

Of all the interest measures presented, only the Piatetsky-Shapiro measure establishes the ≤ca partial ordering under certain conditions. As this measure is closely related to the fitness measure presented later, the conditions under which the partial ordering is established for the PS measure will be discussed later. Proof of why the other measures do not establish the partial ordering is given by de la Iglesia (2001). None of the measures presented have any parameters or other means to allow the search to be directed towards more accurate or more general rules.

THE FITNESS MEASURE
The measure of interest proposed by Rayward-Smith et al. (1995), the fitness measure, is an individual quantity which displays the two important aspects of pattern quality: it establishes ≤ca partial ordering under certain conditions, and it also allows the search to be directed towards accuracy or generality for rules that cannot be compared under the ≤ ca partial ordering. This measure is used as the basis for the implementation of some heuristic-based algorithms for solving the nugget discovery problem. The simple measure that will be used to define the fitness of a rule is

82 de la Iglesia and Rayward-Smith

f(r)= λc - a, where λ is a positive real number. The fitness measure has a local maximum when c = a, and a global maximum when c = a = b. Note that an equivalent measure, the gain measure was proposed by Fukuda et al. (1996), after the proposal of our measure. The gain measure is defined as
Gain(r ) = c − θ a,

where the parameter θ performs an equivalent function to the λ parameter. The gain measure is also identical to the Piatetsky-Shapiro measure for a fixed value of θ,
θ=
b d .

Therefore, the following discussion regarding the fitness measure can equally be applied to the gain and to the Piatetsky-Shapiro measure by interpreting,

λ=

d . b

The parameter λ establishes an accuracy threshold above which the fitness measure orders rules correctly with respect to the ≤ca partial ordering. The accuracy threshold is defined by 1/λ, and is represented in Figure 3. The accuracy threshold is established by the following theorem: Theorem 1: For a given λ > 1, and for two rules r 1 and r 2, A1: if Acc(r 1 ) > r1 < r2 ⇒ f(r1 ) < f(r2), and r1 = r2 ⇒ f(r1 ) = f(r2);
ca ca

1 λ

and Acc(r 2) >

1 λ

then

A2: if Acc(r1) =

1 λ

then fr1) = 0;

A3: if Acc(r1) > 1 and Acc(r2) ≤ 1 then f(r1) > f(r2).
λ
λ

The proof of this theorem can be found in de la Iglesia (2001). A good approach to rule induction using the fitness measure is to start with a high threshold value, established by a λ value close to 1, in order to find very accurate rules. As all rules above the threshold accuracy are ordered correctly according to the ≤ca partial ordering, we should be able to find a rule of high accuracy and coverage, if one exists. If rules of positive fitness are not found, or if the rules found are too specific, then the threshold can be lowered by raising the value of λ, and the search restarted.

Interesting Nuggets Using Heuristic Techniques 83

Figure 3: Accuracy Threshold

Accuracy threshold

1 0.8

Accuracy %

0.6 0.4 0.2 0 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2 2.1 2.2 2.3 2.4 2.5

λ d=10,000 and b=5,000

We will then be searching a different accuracy/coverage area. Hence, apart from the threshold established, the λ parameter has another effect on accuracy/generality of rules. For low values of the parameter λ, accuracy will have a greater weight on the fitness value, whereas for high values of λ, coverage will have a greater weight. In other words, at low λ values, rules with high accuracy, even if they have low coverage, may appear to be fitter over rules of low accuracy and higher coverage. As the lambda parameter is increased in value this effect is reversed. For example, for a database of d = 10,000 and b = 5,000: a1 = 200, Acc(r1)=1, Cov(r1) = 0.04, r1 has c = 200, 1 r2 has c = 1000, a2 = 1085, Acc(r2)=0.92 Cov(r2) = 0.2.
2

We find that at λ = 1.1, f(r1) = 20 and f(r ) = 15, hence r1 is preferred. At λ 2 = 1.5, f(r1) = 100 and f(r2) = 415, hence r2 is preferred. The λ parameter allows the analyst to focus the search on general but possibly less accurate patterns, or on more accurate but possibly more specific patterns. Therefore, the fitness measure establishes the ≤ca partial ordering, and also can encourage the production of patterns that are of high coverage or of high accuracy, depending on the application needs.

HEURISTIC TECHNIQUES TO SOLVE THE NUGGET DISCOVERY PROBLEM
Three modern heuristic techniques were adapted for the solution of the nugget discovery problem: Genetic Algorithms (GAs), Simulated Annealing (SA) and Tabu Search (TS). The Genetic Algorithm for data mining was developed using a GA toolkit developed at the University of East Anglia. GAmeter (Smith & Mann, 1994) is an easy-to-use environment for the development of optimisation problems using GAs.

84 de la Iglesia and Rayward-Smith

The GAmeter toolkit consists of an intuitive interface including binary, integer and floating point representations, various selection and replacement mechanisms, different cross-over and mutation operators and other features. The main code in GAmeter is implemented in the C programming language. The simulated annealing toolkit, SAmson, developed in conjunction with GAmeter and described by Mann (1996), was used as the platform for the implementation of data mining using SA. SAmson shares most of the features of GAmeter, but uses a simulated annealing algorithm with its corresponding parameters to perform optimisation, instead of the genetic algorithm. The TAbasco toolkit, implementing a very simple and naive Tabu Search strategy, was modified to perform the data mining tasks of nugget discovery. The only tabu search features implemented in the toolkit at the time of the research were simple recency and frequency memory structures and aspiration criteria. Hence this can only be considered as a very initial attempt at using TS for the problem of nugget discovery. A more sophisticated implementation is necessary in the future to establish the worth of TS for this problem, and some additional work in this area, soon to receive publication, is taking place within our group.

Solution Representation
One of the most important decisions for the implementation of heuristic algorithms is how to represent a solution. In this case, the solution to be represented is a conjunctive rule or nugget. The three heuristics presented all share the same solution representation: a nugget is represented by a binary string. The first part of the string is used to represent the numeric fields or attributes. Each numeric attribute is represented by a set of gray-coded lower and upper limits, where each limit is allocated a user-defined number of bits, n (n=10 is the default). There is a scaling procedure that transforms any number in the range of possible values using n bits [0,2n-1] to a number in the range of values that the attribute can take. The procedure works as follows. When the data is loaded the maximum value, maxi, and minimum value, mini, for each attribute i is stored. A weight for each attribute is then calculated as max i − min i wi = 2n − 1 When the string representing a nugget is decoded, the upper and lower limit values for each attribute are calculated by limiti= (ss * w ) + min , i i where ss represents the decimal value of an n bit gray coded substring extracted from the binary string, which corresponds to one of the limits. The second part of the string represents categorical attributes, with each attribute having v number of bits, where v is the number of distinct values (usually very small in number) or the number of labels that the categorical attribute can take. If a bit assigned to a categorical attribute is set to 0 in the bit string representation, then the corresponding label is included as an inequality in one of the conjuncts. For

Interesting Nuggets Using Heuristic Techniques 85

example, if the bit for the value “blue” of an attribute “colour” is set to 0, then one of the conjuncts would be “Colour ≠ blue”. When a bit string is decoded as a nugget it will acquire the following format: IF (l1 ≤ AT1 ≤ u1) AND (l2 ≤ AT2≤ u2) AND…AND (li≤ ATi≤ ui) AND ATp≠ labela AND ATr ≠ labelb THEN Classj where l1, the lower limit for attribute 1, is given by the first n bits of the binary string, u1, the upper limit, is given by the following n bits, etc. We have assumed for simplicity that the first i attributes are numeric, with the categorical attributes following. If a lower limit or any attribute i is set to its lowest possible value for the attribute, mini, or the upper limit is set to its highest possible value, maxi, then there is no need to include that limit in the decoded nugget. If both limits are excluded in that way, then the attribute is obviously also excluded. Equally, if a categorical attribute has a value of 1 for all the bits allocated to its labels, then there is no need to include the attribute. Note that with this representation some solutions may translate to the empty rule, i.e., the rule that contains no records. This could happen, for example, if all the categorical labels are set to 0. Solutions of this kind were penalised with a very low fitness, to overcome the problem.

Other Details of the Nugget Discovery Implementation
Aside of the representation issues, the heuristic toolkits used (GAmeter, SAmson and TAbasco) handled the optimisation according to the chosen paradigm. The only implementation details left to be covered were the loading of a solution, the initialisation, the evaluation and the saving procedure. The details of the loading and saving operations will not be discussed here, as they are reasonably trivial. The initialisation was achieved, after some experimentation, by use of the default rule. The default rule is the rule in which all limits are maximally spaced and all labels are included. In the case of SA and TS, the initial solution was set to the default rule, whereas in the case of the GAs all solutions were initialised to the default rule. This worked surprisingly better, more so for the GAs, than initialising some or all rules at random. To evaluate a solution, the bit string is decoded, and the data is scanned through. For each record the values of the fields are compared against the nuggets, and the class is also compared. The counts of c and a are updated accordingly. Once all the data has been examined f(r) = λ c- a is calculated. It is also possible, especially in the early stages, to approximate this by sampling.

Parameters
For each heuristic algorithm, extensive experimentation was conducted to find an adequate set of parameters. ( The details of the experiments are given by de la Iglesia, 2001). The three algorithms were found fairly robust to parameter experimentation on the problem of nugget discovery tested, hence a set of

86 de la Iglesia and Rayward-Smith

parameters was chosen to run each algorithm in future exercises. Here is a summary of the parameters chosen for each algorithm:

For the GAs
− − A pool of 10 solutions (an increase to 500 was an option for more accurate runs). A roulette selection mechanism with replacement. The number of solutions that are selected to create new solutions is a random number between a minimum and maximum value established by the user (note that min. must be at least two and max. can be at most equal to the population size). Offspring are merged into the population using the “best fit” method, which sequentially replaces the worst solution in the population with the best of the offspring until there is no child better than the next candidate for replacement. Consecutive pairs of parents are selected for one-point crossover with 60% probability (and so consequently replication at 40%). If an odd number of parents is chosen and crossover is applied to the last parent from the mating pool, it is mated with a solution in the mating pool chosen at random. Mutation rate 1%. The stopping condition was 500 generations without improvement.

− −

− − − − − −

For the SA
A neighbourhood of a solution was generated by selecting a bit at random and inverting it. Initial temperature of 10, selected as an acceptable value after experimentation with different initial temperatures. Cooling schedule Lundy and Mees (1986), with a Beta value of 0.9 and 20 proposed moves spent at each temperature step. Non-monotonicity was introduced within the cooling schedule by means of a threshold parameter. This works by returning the temperature to half its value at the point of the last temperature rise when the threshold percentage of this value is reached. The temperature value at the point of the last temperature rise is considered to be the initial temperature if no rises have yet been performed. For example, if an initial temperature of 100 is used together with a threshold value of 10, the temperature will be raised to 50 ( 100 ÷2 ) once it reaches 10 (10% of 100). The temperature will next be raised to 25 ( 50 ÷2) when it falls to 5 (10% of 50) and so on. All experiments were halted once the temperature had fallen to 0.01.

− − − −

For the TS
A neighbourhood operator: flip one bit. Recency memory (implemented by recording whole solutions) with a tabu tenure of 10. Frequency memory (implemented by keeping a count of how many times each single bit of the solution representation had been changed) with a threshold of 20.

Interesting Nuggets Using Heuristic Techniques 87

− −

A subset of 20 neighbours generated. Stopping after 250 iterations without change in the best solution value.

OTHER ALGORITHMS FOR NUGGET DISCOVERY
In the following section we will present the results of applying the heuristic algorithms for nugget discovery to some problems. Other algorithms available for classification or for nugget discovery were applied to the same problems so that the suitability of different approaches to the task of nugget discovery could be assessed. The algorithms tested ranged from complete classification algorithms, to nugget discovery algorithms and association rule algorithms. A description of each algorithm is not possible here due to space constraints, hence the reader is referred to appropriate papers. For each algorithm, extensive parameter experimentation was carried out and a set of good parameters was chosen, but again this is not reported here; see de la Iglesia (2001) for details. The classification algorithms chosen were:

−

C5/C4.5: This is the most prominent decision tree induction algorithm, which also contains functionality to extract a non-mutually exclusive set of rules (Quinlan, 1986, 1993). Each rule is a nugget of the form described previously. For categorical attributes the type of tests contained in the nuggets formed by the C5 algorithm are either a single value or a subset of values. For numeric attributes, the tests contained are binary partitions. CN2: This is a rule induction algorithm for complete classification described by Clark and Boswell (1991) and Clark and Niblett (1989). If an unordered rule set is extracted, each of the rules is a nugget that can be assessed on its own. For categorical attributes, it uses single-value tests only, whereas for numerical attributes it uses tests containing a range of values. Brute: This is a nugget discovery algorithm (Riddle et al., 1994) which performs an exhaustive depth-bounded search for conjunctive rules, guided by a chosen interest measure (the choices include Laplace accuracy, χ2, and a weighted average of accuracy and coverage). The nuggets extracted use binary partitions for numeric attributes and either single value, subset of values or inequality tests for categorical attributes. RIPPER: Repeated Incremental Pruning to Produce Error Reduction (Cohen, 1995) is another rule induction algorithm that produces a complete classification. The rules that form part of the classification are conjunctive nuggets. The nuggets obtained have binary partitions for numeric attributes and either single value or inequality tests for categorical attributes. KnowledgeSEEKER: The commercial package KnowledgeSEEKER (Biggs et al., 1991; de Ville, 1994) is another tree induction algorithm which is based on

−

−

−

−

88 de la Iglesia and Rayward-Smith

the statistical approach to tree induction. Each branch (or even partial branch up to any node) of the tree can be considered as a nugget. For categorical attributes, the nuggets can contain single value or subsets of values, whereas for numerical attributes it uses tests containing a range of values.

−

1R: This is a rule induction algorithm that produces rules which base the classification of examples upon a single attribute. The algorithm (Holte, 1993; Nevill-Manning et al., 1995) assumes categorical attributes, but can handle numeric attributes as they are discretised as a preprocessing operation. The interpretation of the classification produced by 1R as a set of nuggets can be done in various ways. If the attribute chosen for the classification is categorical, then each value of the attribute can be interpreted as a conjunctive test, or a subset of values can be considered together. In the experiment that follows all possibilities of individual tests or subsets of tests were considered as nuggets for the attribute chosen in each case. For a numerical attribute, each interval produced by the discretisation can be considered individually, or various intervals can be considered together as a disjunction. In the experiments that follow, both individual ranges and disjunction of ranges were evaluated. T2: This is a tree induction algorithm which produces a decision tree containing at most two levels (Auer et al., 1995). In the first level the tree contains a test on a single attribute, with numeric attributes using a binary partition and discrete attributes using a simple value. If there is a second level, a test on a numeric attribute will test on range of values instead of a binary partition. Each branch or partial branch of a T2 tree can be interpreted as a nugget. PART: This algorithm (Frank & Witten, 1998) generates rule sets and combines concepts of C4.5 and RIPPER. Each rule of the rule set can be considered as a nugget, but they need to be re-evaluated individually as they form part of an ordered rule set. PART uses simple value tests for categorical attributes, and binary partitions for numerical attributes. RISE: This algorithm (Domingos, 1995, 1996) combines rule induction with Instance Based Learning (IBL). Since IBL explicitly memorises some or all of the examples and attempts to find the most similar cases to the target one, the resulting classifier is made up of some abstractions formed by the rule induction part of the algorithm and some individual examples. It is only worth considering the abstractions as nuggets, and this is what was done in the following experiments. The abstractions are rules using range of values for tests on numeric attributes and simple value tests for categorical attributes. Also, the following association rule algorithms were chosen: GRI: Generalised Rule Induction (Mallen & Bramer, 1995) is described as an association rule algorithm, although it could also be considered as a partial classification algorithm. It builds a table of the best N association rules, as

−

−

−

−

Interesting Nuggets Using Heuristic Techniques 89

ranked by the J measure, where N is a parameter set by the user. In GRI the output attribute can be chosen, and each rule produced can be used as a nugget describing that output. They contain binary partitions for numeric attributes and tests on a simple value for categorical attributes.

−

Apriori: The Apriori algorithm (Agrawal et al., 1993, 1996) is the most prominent association rule algorithm. Pre-discretisation of numeric attributes is necessary, since the algorithm can only handle categorical attributes. A simple equal width discretisation scheme was used for this. The output of this algorithm is not constraint to rules for a particular attribute, hence only the nuggets relating to the class under scrutiny need to be analysed for the task of nugget discovery. The Apriori rules contain simple value tests for categorical attributes.

EXPERIMENTS
The heuristic algorithms, as well as the 11 algorithms mentioned above, were applied to the problem of nugget discovery using four different databases extracted from the UCI repository of databases (Merz & Murphy, 1998). The databases chosen are briefly summarised in Table 1. Full details of all the experiments carried out, and more details on each database, are presented in de la Iglesia (2001). Here only a summary of the findings is presented. For the first three databases, patterns were sought for all the classes. For the last database, patterns were sought only for two of the classes, the majority class with 48.8% representative examples and the minority class with 0.5% representative examples. For the Adult database, records with missing values were removed, and for the mushroom database one of the attributes, which contains a high percentage of missing values, was also removed as a pre-processing step. The other datasets contained no missing values. Also, for the Apriori algorithm, numeric attributes were discretised using a simple equal-width bin scheme. In the case of the Forest Cover Type database, a balanced version of the data was produced for the extraction of nuggets for the minority class. This balanced version contained a reduced dataset, with records belonging to classes other than the minority class removed at random, until the minority class represented a higher percentage of the data (over 30%). Algorithms were tried on both the balanced and the complete data set, and the best
Table 1: Databases from the UCI repository chosen for nugget discovery
Name Adult Mushroom Contraception Forest Cover Type Records 45,222 8,124 1,473 581,012 Attrib. 14 21 9 54 Classes 2 2 3 7 Numeric Attributes 6 0 2 10 Categorical Attributes 8 21 7 14

90 de la Iglesia and Rayward-Smith

nuggets obtained by either were selected for comparison. The balanced version of the data was included because techniques such as C5 are known to give best results if balanced databases are used (de la Iglesia, Debuse and Rayward-Smith, 1996). The heuristics did not use the balanced dataset to induce the rules of best quality. The databases used posed different challenges for the algorithms: the Adult database can be considered large and has some strong patterns; the Mushroom database has very obvious and strong patterns; the Contraception database has very weak patterns in particular for some classes; the Forest Cover database is large and contains a very good example of a minority or exceptional class. The databases chosen have a mixture of categorical and numeric attributes. For each database, the data was partitioned into a train/test partition. Then the algorithms were applied using a set of parameters chosen previously as a result of parameter experimentation. For the algorithms that produce a complete classification, or a set of nuggets or rules, each rule was transformed into a fitness measure using a range of λ values. The λ values used were chosen to represent decreasing accuracy thresholds, and varied from dataset to dataset. At most six different λ values were experimented with for each dataset. Experimentation to find the right λ value for a particular problem is reasonably straightforward, and it involves starting with a high accuracy threshold (close to 100%) and decreasing it at approximately equal steps until the accuracy threshold is equal to the default accuracy for the class being targeted. The process of λ experimentation can be automated. From the set of rules, or individual rules obtained by each algorithm, the one with the highest fitness measure for each λ value was chosen for comparison to the rules produced by other algorithms. For illustrative purposes, one set of result tables is reproduced in Table 2. In this table, N/R means that no rule was obtained. For each algorithm, the fitness, accuracy and coverage of the best (highest fitness) nugget produced are recorded in the table. The figures in brackets represent the accuracy and coverage obtained by testing the nugget on the test partition. The highest fitness results obtained, corresponding in this case to the heuristics, are highlighted in bold. Similar tables are presented in de la Iglesia (2001) for each class examined in each database. All results cannot be reproduced here due to space constraints. As a summary, this is how algorithms performed on the different problems:

−

Adult database: For this dataset, the heuristic techniques, C5, GRI and Brute produced fit nuggets for both classes consistently at different levels of accuracy and generality. The algorithms 1R and KnowledgeSEEKER produced good results in some cases, but not as consistently. The other algorithms produced results of lower fitness in most cases. The nuggets obtained by the best algorithms were simple rules that represented good descriptions of the classes, with high accuracy and coverage. The measures of accuracy and coverage of the same rules when applied to the test datasets showed that the patterns were not overfitting the training data, as the properties of the nuggets remained stable

