720

IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 28, NO. 5, MAY 2009

A Uniﬁed Framework for Automated 3-D Segmentation of Surface-Stained Living Cells and a Comprehensive Segmentation Evaluation
Erlend Hodneland, Nickolay V. Bukoreshtliev, Tilo W. Eichler, Xue-Cheng Tai, Steffen Gurke, Arvid Lundervold*, Member, IEEE, and Hans-Hermann Gerdes

Abstract—This work presents a uniﬁed framework for whole cell segmentation of surface stained living cells from 3-D data sets of ﬂuorescent images. Every step of the process is described, image acquisition, preﬁltering, ridge enhancement, cell segmentation, and a segmentation evaluation. The segmentation results from two different automated approaches for segmentation are compared to manual segmentation of the same data using a rigorous evaluation scheme. This revealed that combination of the respective cell types with the most suitable microscopy method resulted in high success rates up to 97%. The described approach permits to automatically perform a statistical analysis of various parameters from living cells. Index Terms—Automated whole cell segmentation, level set, mathematical morphology, region differencing, segmentation evaluation, watershed.

[1]–[5], which permits the statistical analysis of various cell parameters and thereby has the potential to identify even subtle effects of drugs or toxins on cells. A. Fluorescent Labeling of Cells To fully beneﬁt from the advantages of automated segmentation, a suitable cell targeting method must be chosen. In this respect, at least four different approaches have been published. First, several studies describe applications to perform cell segmentation on phase contrast images [6]–[9]. However, such images suffer from low contrast and uneven illumination. Second, numerous studies report on the segmentation of stained cell nuclei [3], [10]–[16]. This approach is able to identify the nuclei but does not delineate the outer border of the cell. Third, segmentation algorithms have been applied to cytoplasmically stained cells [2], [11], [17]–[20]. Although these algorithms detect the area covered by the cells, they often fail to outline the exact boundaries between attached cells, especially in large clusters of cells. Fourth, methods for segmentation of surfacestained cells are able to combine the strength of the two formerly mentioned methods by determining both the number of cells and their boundaries. This enables in particular the calculation of various cell parameters for whole cells to be computed, such as shape, volume and metabolism of cells in conﬂuent cell cultures or tissue. To the best of our knowledge only very few studies have addressed the task of segmenting surface-stained cells. Notably, in these studies only ﬁxed cells were used [13], [21]–[23]. The work in [13] was also restricted to 2-D since antibodies against integrin receptor subunits were used as surface marker, only labeling the cell membrane attached to the substrate. To extend the existing methods toward a fully automated 3-D whole cell segmentation of surface stained living cells, we have developed versatile methods and also combined existing approaches which apply to images showing ﬂuorescently labeled cell borders. B. Preprocessing of Images As an introductory step, a background subtraction is required if the images exhibit slowly varying background signals, which can severely compromise with for instance thresholding techniques. Malpica [14] used 25 empty control matrices for adjustment and Adiga [11] corrected the background by a sliding window. A top-hat ﬁltering can also be used for background correction. In this work, the inhomogeneity of the background

I. INTRODUCTION HE study of organisms at the single-cell level has tremendously advanced our understanding of human physiology and pathology in recent years. In this respect, computer-assisted cell recognition obtained by image segmentation represents an important tool. Although humans are superior to computers in terms of shape detection and segmentation, they are inadequate to process vast amounts of data and to perform an objective evaluation of experiments. Therefore, automated cell segmentation is a growing ﬁeld of interest with a wide range of applications

T

Manuscript received June 21, 2008; revised November 12, 2008. First published January 06, 2009; current version published April 29, 2009. The work of N. V. Bukoreshtliev and T. W. Eichler was supported by a stipend from the University of Bergen. The work of S. Gurke was supported in part by the Marie Curie Training Site from the European Commission under Agreement QLK5-2001-60075 and in part by stipends from the fellowship program “Research Abroad” for young scientists from the Gottlieb Daimler Foundation and Karl Benz Foundation. The work of E. Hodneland was supported by The Norwegian Cancer Society under Project A05103/004. The work of H.-H. Gerdes was supported by The Norwegian Cancer Society, the University of Bergen, and the Research Council of Norway (NFR). Asterisk indicates corresponding author. E. Hodneland, N. V. Bukoreshtliev, T. W. Eichler, S. Gurke, and H.-H. Gerdes are with the Department of Biomedicine, University of Bergen, 5009 Bergen, Norway (e-mail: erlend.hodneland@biomed.uib.no). X.-C. Tai is with the Department of Mathematics, University of Bergen, Johs. Brunsgt. 12, N-5008 Bergen, Norway. *A. Lundervold is with the Department of Biomedicine, University of Bergen, 5009 Bergen, Norway (e-mail: arvid.lundervold@biomed.uib.no). Color versions of one or more of the ﬁgures in this paper are available online at http://ieeexplore.ieee.org. Digital Object Identiﬁer 10.1109/TMI.2008.2011522

0278-0062/$25.00 © 2009 IEEE

HODNELAND et al.: A UNIFIED FRAMEWORK FOR AUTOMATED 3-D SEGMENTATION OF SURFACE-STAINED LIVING CELLS

721

in the images was low, and we did not use background correction for the experimental part. Normally, the quality of ﬂuorescent images is reduced due to noise and other undesired inﬂuences. The undesired signals can be decreased but not fully excluded since they arise from normal cell processes like endo- and exocytosis, cell division, cell debris and accumulation of the ﬂuorescent dye in other compartments of the cell than those of interest. Therefore, a proper ﬁltering technique is advised prior to any image analysis, aiming at removing undesired signals and simultaneously preserving or even enhancing the signals from the objects of interest. In this work we have implemented and compared linear and nonlinear spatial ﬁlters such as the Gaussian, the median ﬁlter [24], and directional coherence enhancement ﬁlter [2], as well as iterative methods for ﬁltering based on partial differential equations [25]–[29]. Moreover, the surface stained cells shown in this work express the plasma membrane as ridges, therefore it is reasonable and also necessary to perform a ridge enhancement as an additional ﬁltering step prior to the segmentation. Existing methods include the Gabor ﬁlter banks [30] as well as the eigenvalue decomposition of the Hessian matrix [31]–[34]. The Hessian ridge enhancement takes advantage of the fact that the largest eigenvalue is signiﬁcantly larger than the smallest eigenvalue on a ridge. Lindeberg [35] describes how the second derivatives can be used for ridge detection. In this study, we have improved existing methods for ridge enhancement. C. Segmentation of Cells For the main step in the processing chain for segmentation of surface stained cells, several options are available. Baggett et al. [21] implemented a semi-automated cell segmentation which is related to ridge following (see Section II-D-3). This approach was extended to 3-D in [22]. To trace the extensions of neurons, the neurites, Dima et al. [20] used a ridge following method based on the gradient points along the thin neurites. Al-Kofahi et al. [36], [37] used directional correlation kernels to trace neurites and replaced the average template response by the median response. We have implemented their method to demonstrate that ridge following can be used for 2-D cell segmentation by tracing the ridges displaying the cell borders (Section II-D-3). We have chosen to thoroughly compare a marker controlled watershed segmentation with a level set model. The watershed method is widely described in the literature [18], [38]–[40]. Bengtsson et al. [17], [18], [41] obtained success rates of between 89% and 97% for segmentation of cells stained with calcein [17]. They used a labeling method to measure the amount of over- and under-segmented objects, but they were not able to measure the segmentation quality of the border lines between the watershed regions. Adiga [11] applied the watershed algorithm for segmentation of cell nuclei and an active surface model for further reﬁnement, obtaining a deviation between 2% and 5% from the manual solution. In Adiga et al. [2] an automated seeding and a watershed-like region growing technique was applied to segment nuclei, followed by an iterative, controlled dilation, where all regions were blown up with the constraint that they should not touch their neighbors. Their quality measure, the

percentage of symmetric difference, revealed high success rates between 87% and 95% and low false positive rates of between 5% and 16%. Malpica [14] describes the use of morphological watersheds for segmentation of clustered nuclei. They computed a distance transform to create markers for the watershed segmentation, resulting in success rates between 81.25% and 93.39% with an over-segmentation less than 4.67%. Dow [23] used a nucleus staining to obtain reliable markers for a watershed segmentation generating the boundaries of the nuclei. This approach for generating markers is very advantageous, but we have not followed this idea since the biological setup not always allows an additional nucleus staining. Our aim has therefore been to create a framework for segmentation only depending on a surface staining. The obtained boundaries in [23] represented an approximation to the cell surface and were used in the successive active contour to detect the cell surface. For the active contours, there are at least two different types of models, parameterized active contours and geometric active contours. Zamani et al. [16] used a gradient vector ﬂow (GVF) snake to segment the nuclei of white blood cells, and they report a high success rate of about 95% for the segmentation of 40 cells. Solorzano et al. [13] describe a geometric active contour, a level set approach, for a successfull segmentation of 19 lamin stained nuclei and a whole cell segmentation of 24 integrin lamin stained cultured cells and 23 integrin-stained cells in tissue. We have chosen to implement their level set segmentation as a comparative method to the watershed (Section II-D-2). The level set method is advantageous to watershed due to smoothing properties of the resulting segmentation. However, recent progress on the watershed approach has included a smoothing term into the models [38], [42]. Besides these improvements, the watershed algorithm is faster than the active contours, and in particular compared to the geometric active contours there is a signiﬁcant reduction in computational speed. D. Segmentation Evaluation Finally, a quality measure is necessary to evaluate the performance of different segmentation methods, also referred to as segmentation evaluation. For cell segmentation, evaluation was in the past rarely performed using comparative criteria [2], [11], [14], [16]–[18], [41], which makes an interstudy comparison difﬁcult. Therefore, we have in this work aimed at establishing a common framework for evaluation of cell segmentation, which takes into account over- and under segmentation as well as misplaced boundaries. Within the area of image segmentation, numerous studies on segmentation evaluation have been reported. The surveys by Zhang [43], [44] classify the evaluation methods for segmentation into three groups: analytical, empirical goodness, and empirical discrepancy methods. A region differencing [45] belongs to the empirical discrepancy methods by comparing segmented objects with a set of reference objects. This approach enables the use of reference objects created from manual delineation, which is probably the best available solution. Therefore, we have used this evaluation method as basis for our segmentation evaluation. A similar approach was applied to cell segmentation in [2], where a percentage of symmetric difference represents the overlap between two objects.

722

IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 28, NO. 5, MAY 2009

Fig. 1. The plasma membrane is a ridge-like structure. In (a) a focal plane from a 3-D image stack is shown, depicting two associated PC12 cells. In (b), the intensity proﬁle along the dashed line in (a) is ploted. Note that the plasma membrane of the cell is expressed as ridges.

The overall aim of the present work is to construct a uniﬁed framework for segmentation and quantiﬁcation of surface stained living cells in 3-D, together with a logically linked quality assessment procedure. We have achieved this by combining preﬁltering, ridge enhancement, automated marker construction, watershed segmentation, ridge following, level set segmentation, and a comprehensive segmentation evaluation. In particular, we have contributed in the development of a new methodological variant of ridge enhancement and segmentation evaluation. II. METHODS In this section, a uniﬁed framework for segmentation of surface stained cells is described. All compared methods except the ridge following method are applied to surface stained living cells in 3-D, displaying a pronounced signal of the plasma membrane. A. Preﬁltering A comprehensive ﬁltering method is designed to enhance edges and corners, thus preserving the boundaries of desired objects. However, the structures of interest in the images of this study have strong ridges rather than strong edges, highlighting the stained plasma membrane. Thus, the method of choice must aim at preserving ridges more than edges. In 3-D, the objects of interest are surfaces. Fig. 1(a) shows two associated PC12 cells, and the intensity proﬁle along the dashed line is plotted in Fig. 1(b) to emphasize the ridge property of the plasma membrane where the peaks of the ridges are indicated by arrows. Notably, inhomogeneous distribution of the dye in the membrane creates discontinuities. Inside the cells there are bright spots and regions, which derive from endocytosed membrane. Such effects represent more serious challenges to the segmentation protocol than the Gaussian white noise. To reduce the background a set of six ﬁlters were compared, among those three direct spatial ﬁlters and three partial differential equation (PDE)-based ﬁlters. All described ﬁlter techniques are implemented in true 3-D, is the local neighborhood, is the time step, and and the conductivites are taken as described in [46]. , and ) • Gaussian smoothing [24] (Fig. 2(b), is a traditional method for smoothing. is the standard deviation of the Gaussian distribution. • Median ﬁlter [24] (Fig. 2(c), ) is a powerful orderstatistic ﬁlter method which preserves edges efﬁciently. In

Fig. 2. Three-dimensional ﬁltering of a 3-D image stack (a shows selected focal planes). Three direct [Gaussian (b), median (c), directional coherence enhancement (d)] and three iterative [edge enhancing (e), coherence enhancement (f), inverse diffusion (g)] ﬁlters were implemented and compared for preprocessing of the images. Note that the ﬁltering in (d), (f), and (g) have the best ability to preserve the ridges.

the median ﬁlter, each output pixel contains the median of the image values within . For the 3-D implementation, we used bilinear interpolation to extract the image values at different positions. • Directional coherence enhancement ﬁlter [2] (Fig. 2(d), ) is a directional ﬁlter performing a texture analysis to remove noise. The method has a high noise tolerance due to a special averaging process called semi-Olympic averaging. Our 3-D implementation uses the principal and diagonal directions, and was adjusted to the width of the given ridges.

HODNELAND et al.: A UNIFIED FRAMEWORK FOR AUTOMATED 3-D SEGMENTATION OF SURFACE-STAINED LIVING CELLS

723

• PDE-based edge enhancing diffusion [26], [27] (Fig. 2(e), , 100 iterations, ) performs a stronger smoothing along the edges than across in regions with a high gradient. Given the image and the diffusion matrix , we solve (1) is a diagonal matrix with the conductivities , along the principal diffusion directions. is the rotation matrix constructed from an orthonormal set of vec, where . tors, • Coherence enhancing diffusion [27], [47] (Fig. 2(f), , 50 iterations, ) has proved to be successful for ﬁngerprint images. The cell images presented here and ﬁngerprint images have the common property that important structures are thin lines or ridges. The aim for both types of input image is to smooth along the ridges and not across them, and the diffusion is therefore directed along the eigenvectors of the structure tensor [27]. The eigenvectors were computed numerically in 3-D due to instability of the analytical approach. , 10 iterations, • Inverse diffusion [48] (Fig. 2(g), , ) is a method similar to coherence enhancing diffusion where the diffusion across the edge is reversed by reversing the sign of the conductivity along the principal variation. This is an inherently unstable process since the solution of the backward diffusion equation is normally ill-posed [49]. However, if the diffusion is limited to only a few iterations, the method can sharpen the ridges or edges of interest. For segmentation, it is always recommendable to acquire images of the highest possible quality. Despite this, a ﬁltering can be advised to perform to improve the image quality even further. In this case a straightforward Gaussian ﬁltering [Fig. 2(b)] can be sufﬁcient to further improve the image quality. However, more advanced ﬁlters like the directional coherence enhancement ﬁlter [Fig. 2(d)], the coherence diffusion ﬁlter [Fig. 2(f)] or inverse diffusion [Fig. 2(g)] are normally preferred methods, at least if there exists a substantial degree of noise and if the structures of the image are characterized by severe discontinuities. These directional ﬁlters are able to close minor gaps in the structures along the principal ﬂow direction. Among those, the directional coherence enhancement ﬁlter has higher computational performance than coherence enhancing diffusion and it is also easier to adjust than inverse diffusion due to the reversed diffusion process in the latter. Therefore, the directional diffusion ﬁlter is our choice of ﬁltering method in the experimental part (Section III). The median ﬁlter [Fig. 2(c)] and the edge enhancing ﬁlter [Fig. 2(e)] are more edge preserving than the other ﬁlters, and are not well suited for ridge structures. However, the median ﬁlter or the edge enhancing ﬁlter are highly suitable for images of cytoplasmically stained cells, since the aim under these conditions would be to enhance the edges in the transition zone between cells and background (data not shown). B. Ridge Enhancement As a second preprocessing step, a ridge enhancement is recommended, especially for wide ﬁeld images since light from surrounding pixels is detected as well as light from the center pixel. The ridge enhancement enhances the contrast of ridges

compared to other structures, thus creating an image better suited for the cell segmentation and in particular for automated marker generation. 1) Hessian Ridge Enhancement: A convoluted Hessian matrix is given as (2) is the normalized and Gaussian convolved image and is an additional Gaussian convolution. The eigenvalues of the Hessian matrix are computed and every pixel is assigned a geometrical class according to the sign of the eigenvalues [34]. Across the cell boundary there is a large intensity variation, but the variation is small along the tangential plane of the plasma membrane. Therefore, the 3-D plasma membrane has the char, , , acteristic geometrical property of are the eigenvalues of the Hessian mawhere , , and trix in decreasing absolute values. To highlight the plasma membrane we choose among other possibilities the transfer function since it reduces the inﬂuence of and . This is important since the ridge is seldom perfect and often contains local peaks that exhibit relatively large , . From , the ridge enhanced image will take the largest values on the ridges compared to other geometrical classes, see an example of Hessian ridge enhancement in Fig. 3(b). 2) Ridge Enhancement by Curvature: The ridge enhancement by curvature is our extension to the Hessian ridge enhancement. Here, the ridge enhancement is given as the curvature in the principal direction of variation of the second derivative. Similar to the Hessian ridge enhancement, the eigenvalue decomposition of the Hessian matrix is computed. The purpose is with the largest modulus of eigento obtain the eigenvector values, pointing perpendicular to the ridge. A twice differentiable function can be expressed using the canonical parameter. Consider the vector formula for the ization curvature of a parametrized curve in 1-D [50] and deﬁne a local orientation along for every pixel in the image and compute the curvature (4) along where (3) where the derivatives are (4) and is the argument along . Thus, for any 2-D or 3-D image the problem is transformed into ﬁnding the local curvature of passing the image intensities along a 1-D line parallel to through . A three-point derivative was used to compute and along (5) and (6) for a stepsize approximately equal to half the width of the pixels was appropriate. ridge. For our data a value of A linear interpolation scheme was applied to extract the correct

724

IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 28, NO. 5, MAY 2009

Fig. 3. Ridge enhancement. The 3-D raw image in (a) was used to compute a 3-D Hessan ridge enhancement (b) and a ridge enhancement by curvature (c), which is better than (b). A combination of directional coherence enhancement ﬁlter with ridge enhancement by curvature was performed in (d), producing the best results. and  in Note that for simplicity only selected planes from the whole image stack is shown, and that all images were computed with equal settings for  the Gaussian convolution.

=9

=3

values from . The ﬁnal ridge enhanced image by curvature , an example is shown in Fig. 3(c). In is taken as and views Fig. 17, the ridge enhancement is shown from for a true 3-D stack of PC12 cells embedded in agarose. Clearly, both methods for ridge enhancement [Fig. 3(b) and (c)] produce strong and well characterized ridge patterns, but the ridge enhancement by curvature creates ridges that are more distinct. Moreover, the ﬁltering methods described in Section II-A improve the image quality, but they can not substitute the ridge enhancement. Preferably, the best results are obtained when combining the two steps, a ﬁltering followed by a ridge enhancement, see Fig. 3(d), where the best visual result is achieved. C. Segmentation and Cell Classiﬁcation In this section, three available methods for segmentation are presented, the watershed segmentation, level sets, and ridge following. First, the construction of markers is described, which is a method we have developed and which was shortly described in [42]. 1) Creating Markers: To avoid serious over-segmentation we have chosen the use of markers or initialization regions. Still, a fragment merging is often required after the segmentation to remove false borders within objects, but the complexity of the merging is signiﬁcantly reduced compared to a situation without the use of markers. The marker image is a binary image consisting of either single marker points or larger marker regions where each connected marker is placed inside an object of interest. For the watershed algorithm, each initial marker has a one-to-one relationship to the speciﬁc watershed region surrounded by the watershed surface. The level set can split into several regions or disappear around a marker. Both the watershed segmentation and the level sets are strongly inﬂuenced by the markers. This dependency is a consequence of both

the one-to-one relationship as well as the size and position of the markers. Region-markers generally create results of higher quality than point-markers since their boundaries are closer to the desired boundaries. After segmentation, the boundaries of the detected regions are ideally arranged on the ridges, thus separating each object from its neighbors. The markers can be manually or automatically constructed, but high-throughput experiments often depend upon automatically generated markers to save human time and resources. For the current project, the markers were automatically generated as described in [42]. The image in Fig. 4(a) was used as input to demonstrate the creation of markers. Adaptive thresholding [24], [51] was used to automatically create binary marker regions from the ﬁltered and ridge enhanced image [Fig. 4(b)]. Additionally, the image was scaled between [0, 1] to allow global thresholds for the adaptive thresholding. Speciﬁcally, the adaptive thresholding results in a binary image if else of the high intensity structures of the raw image. is a user-de0.2 and ﬁned scalar threshold with typical values of 0.01 is the ﬁlter dimension of the average ﬁlter of in a -neighborhood around . An adaptive thresholding has a much higher resistance against noise and inhomogeneous illumination compared to global thresholding for labeling of high intensity objects. Note that adaptive thresholding is not required due to the slightly varying background of the images, but rather because of inhomogeneous staining and endocytosis of the dye. Therefore, a correction of the background was not needed but adaptive thresholding was used to detect markers. The image in Fig. 4(c) is an example of adaptive thresholding applied to Fig. 4(b). Small objects were removed [Fig. 4(d)] and an iterative morphological closing was performed on the

HODNELAND et al.: A UNIFIED FRAMEWORK FOR AUTOMATED 3-D SEGMENTATION OF SURFACE-STAINED LIVING CELLS

725

where all pixels belonging to the same region have image is given as the same intensity value. Thus, every region in where is the number of markers. There are several choices of methods for segmentation, which are treated in more detail in Section II-D. 3) Fragment Merging: All three described segmentation methods, the watershed transform, the level sets and the ridge following can create an over-segmentation, which to a certain degree can be corrected by fragment merging. The underlying idea is to merge neighbor regions that fulﬁll given criteria resulting from [11]. Consider the piecewise constant image segmentation and deﬁne neighbor regions to be all pairs of regions with a common border. Label the set of pixels in the , and let , and border between region and as be user-deﬁned thresholds. We have in our simulations used three merging criteria. The ﬁrst requires the relative mean on the border to be above a certain threshold. intensity This is reasonable since a weak border is probably false. The relative mean intensity is computed as the mean intensity on the divided by the mean intensity of a bilateral structure border alongside, which is computed from dilation of the border and of different using two structural elements pixels and pixels. Thus, size, where where is the dilation and are represented as binary images operator. Both with “ones” on the given structure. Using a bilateral structure to obtain a control volume for intensities ensures local sensitivity, in contrary to a global measure. The mean image intensity in inside an object is given as the total intensity divided by the volume , which is used to compute of , the relative mean intensity
Fig. 4. Automated construction of markers. The image (a) was used for ridge enhancement (b) to improve the signal intensity of the ridges. An adaptive thresholding was applied to detect the ridges and convert them into binary structures (c). The smallest objects were removed due their size (d) and a morphological closing was performed to close gaps in the binary structure (e). The closing was repeated iteratively with increasing radius r of the circular structural element (se), r (se) < r (se). A binary ﬁlling was computed after the closing at each iterative step (f) and all binary objects of the size within a user-deﬁned interval were selected and used as marker regions. However, the objects were only selected if they had no intersection to previously selected objects. This enables larger marker regions with their boundaries closer to the true boundaries of the desired objects.

(7) If the border is not colocalizing with a true ridge, it probably imand the intensity criterion will facilitate merging. plies The second merging criterion restricts the allowed difference in size of the two merging candidates. This requirement is necessary to prevent cell regions to become merged with background in images with low contrast ridges. Thus, a merging requires where . The third merging criterion requires an increase or stationary surface convexity in the case of merging. This criterion efﬁciently promotes merging when an over-segmented region is within a concavity, partly surrounded by another region. We let denote the convex hull [24] of region . Again, is a binary image with “ones” on the given structure and “zeros” elsewhere. Then, the relative change of convexity after a possible merging of region and can be expressed as

remaining structures to close minor gaps in the binary structures [Fig. 4(e)]. For each iterative closing step, a larger structural element was applied to facilitate the closing of incrementally larger gaps. The holes in the closed objects were detected and assigned as markers if they had no intersection to previously labeled markers [Fig. 4(f)]. The closing was repeated iteratively with increasing radius of the circular structural element , which resulted in markers with bound(se), aries close to the desired cell boundaries. Finally, removal of the smallest markers was necessary, using a threshold speciﬁed by the user. This technique for marker construction is powerful in automated high-throughput experiments. It is fully automated, requireing a minimal use of human resources and the quality of the created markers is high in the experiments we have performed. 2) Segmentation: The segmentation is designed to process the raw image, ﬁltered image, ridge enhanced image or any combinations of these, and it returns a piecewise constant

(8) The merging procedure is executed by always picking the lowest intensity structure , and simultaneously checking whether the relative volume and the relative change of convexity . If this holds, a merging is performed. The lowest is then removed from the queue and

726

IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 28, NO. 5, MAY 2009

Fig. 5. Fragment merging. The ﬁltered and ridge enhanced image u in (a) is used for watershed segmentation (b). As an example, the border b (c) between region 2 and 3 is used to compute the bilateral structure bb (d). The computed parameters allow merging, thus the border between region 2 and 3 is removed (e).

Fig. 6. Classiﬁcation of segmented regions into cells and background. The watershed lines (a) deﬁned a set of regions numbered from 1 are correctly classiﬁed as background (black), the rest as cells (gray with white boundaries) in (b).

! 12. Region 1 and 8

the procedure is repeated. The merging stops when holds for every in the queue. As an example, Fig. 5(a) shows a small selection of plane 15 of the ﬁltered and ridge enhanced image stack in Fig. 8. In Fig. 8(b), a watershed segmentation is displayed for four regions, numbered from one to four. The and the bilateral structure for the pair common border of neighbor regions 2 and 3 are shown in Fig. 5(c) and (d), respectively. They are used to compute the relative intensity , relative volume and relative convexity that all facilitate merging according to empirically , and . These obtained thresholds of thresholds were found to be suitable when using the ridge enhanced image by curvature, . However, the merging can also be accomplished using the Hessian ridge enhanced image or the original image, which requires another value for . It is certainly possible to replace these merging criteria by others that are closely related to the image properties, and also accommodate new criteria on top of the existing. 4) Classiﬁcation: After segmentation and fragment merging, still remain to be classiﬁed as “background” or the regions “cells.” One approach for classiﬁcation is to design a neural network or a classiﬁcation tree. We tried this in an early stage but it was abandoned due to lack of ﬂexibility; some tasks require 2-D segmentation, others partly 3-D or even full 3-D. A neural network or a classiﬁcation tree has to be trained on a large set of data, and due to nonlinearity between the networks, those obtained from a 2-D training set can not automatically be extended into 3-D. Instead, a set of requirements characterizing a typical cell was implemented. Every requirement has to be fulto be classiﬁed as a cell. We deﬁlled in order for a region ﬁne reduced 3-D as the situation when the range of the original image is less than the range of a cell diameter. We use several requirements for classiﬁcation of rounded-up cells into “cells”

or “background,” with given user-deﬁned thresholds , , , , , and . 1) Minimum and maximum volume. The volume of a cell must where . stay within the interval 2) Mean intensity. It is expected that a cell has higher mean . intensities than background regions, 3) Mean intensity on the boundaries. The boundary of a cell is assumed to be brighter than background regions, , where is the boundary of region . 4) Convex volume. Cells are normally round-like and they are therefore expected to have a relatively high convexity. where is the convex hull of . 5) Convex perimeter. It is also assumed that a large portion of the boundary of the cells have a convex surface, therefore, . expecting that and are directly given from the lower and upper expected volume of a cell. and should be normalized to the expected background intensity. For seeded cells, the background intensity can usually be estimated from the mean intensity of the largest watershed region that is too large to be a cell. If the cells are too dense to expect any free background, the background intensity can be estimated from a blank image. Moreover, an accumulated and highly reliable background intensity can be estimated as the mean intensity of large watershed regions from the whole experand depend on the cell type [15], but iment. and have successfully been applied to PC12 cells (see Section II-F), also between different experiments. The same settings are suitable for 2-D images as well as 3-D stacks, which is convenient and practical. An example of a classiﬁcation is shown in Fig. 6 where the watershed lines in Fig. 6(a) delineate the boundaries of the segmented regions. The ﬁnal classiﬁcation is shown in Fig. 6(b) with background (black), cells (gray), and

HODNELAND et al.: A UNIFIED FRAMEWORK FOR AUTOMATED 3-D SEGMENTATION OF SURFACE-STAINED LIVING CELLS

727

Fig. 7. Watershed and level sets for cell segmentation. Raw image (a), the marker image (b) for watershed segmentation (c), and the marker image (d) for level set segmentation (e).

boundaries around cells (white). Region 1 and region 8 are correctly classiﬁed as background, and the others as cells. D. Comparing Methods for Segmentation 1) Watershed Segmentation: Watershed segmentation [18], [38]–[40], [52] is a method for segmentation belonging to the class of morphological operators. Among other applications, watershed has in the past been used for nuclei segmentation [14], [15]. In contrast to a surface staining, a nucleus staining provides an image which has more in common with a cytoplasmic staining in the way the objects are not necessarily local minima or maxima due to the continuous staining between cells or nuclei. To overcome this problem, the authors in [15] used a gradient-weighted distance transform to transform the original nucleus image into an image where each object was a regional minimum (or maximum). For the same task, a morphological gradient was used in [14] to create an image suitable for watershed segmentation. In contrast to the nucleus and cytoplasmic staining, the surface staining creates images which are directly suitable for watershed segmentation since the plasma membrane between the cells is already crest lines. Therefore, a transformation of the original image is not required and the watershed transform can be applied directly to the raw image. In this study, we have used the watershed transform by immersion [40] with a 26-connected neighborhood in 3-D as one of the comparative approaches for cell segmentation. As an example, the marker image in Fig. 4(f) was used for the watershed segmentation, but an additional marker representing the background was added. The watershed transform itself was carried out on the ﬁltered image, but the ridge enhanced image can also be used, especially for challenging images. Fig. 7(c) shows the watershed transform of the ﬁltered and ridge enhanced image Fig. 7(a) where the image in Fig. 7(b) was used as marker image. The watershed algorithm was also applied to a full 3-D data set to demonstrate the properties in 3-D. Fig. 8 shows every ﬁfth plane of the raw image (column 1), the ridge enhanced image (column 2), and the watershed segmentation (column 3) of a 3-D data set with 40 planes. 2) Level Set: The level set segmentation can also be used to detect cells. We have implemented a slightly different version of the method described in Solorzano [13]. In level sets, the interface is described implicitly by the zero level set of one or more higher-dimensional functions, the level set functions. By this method, one level set function is used for each marker. The marker image contains normally more than one marker, and one needs to take into consideration the conﬂict when interfaces of different level set functions meet since at most one level set function should be larger than zero in every point. To overcome this problem, the conﬂict measure as proposed in [13] was implemented. Fig. 7(d) shows the marker image used

for the level set segmentation of Fig. 7(a). It is equal to the marker image used in the watershed except from the background marker. Fig. 7(e) shows the resulting level set segmentation resulting from the interfaces of the level set functions. A full 3-D segmentation using level sets is shown in Fig. 8, column 4. 3) Ridge Following: Also ridge following methods enable a whole cell segmentation, relying on a tracing of high intensity structures to accomplish the segmentation. A fully automated 2-D ridge following is described in [36], [37]. High intensity structures with higher values than their surroundings are then locally traced along a local path until a stop criterion is fulﬁlled. An example of this method is shown in Fig. 9(a) and (b) for the image in Fig. 7(a). To the best of our knowledge, a local ridge following in 3-D has not been published, and we have therefore not evaluated the method of [36] and [37] in Section III. The study of Baggett et al. [21] represents a different ridge following, ﬁnding the globally optimal path between two points in a transformed coordinate system. At least one interior point and one boundary point is needed, and the path from the boundary point to itself is found in the polar transformation around the interior point, using a gray-weighted distance transform. This method was extended to 3-D in [22]. We have downloaded and tried the software, which is well-functioning. However, since the method is semi-automated due to the user-deﬁned input of the interior and boundary points, we have chosen to omit the method from the thorough segmentation evaluation in Section III. E. Method for Segmentation Evaluation Segmentation evaluation is a frequently debated and usually task-speciﬁc topic in computer vision and automated image analysis applications [43], [44]. The aim and purpose of segmentation differs signiﬁcantly and it is therefore a challenging task to construct methods for segmentation evaluation that comprise numerous criteria of success. The variation may include different requirements regarding accuracy of boundaries, the use of landmarks, penalization of under- and over-segmented regions (including penalization of false negative and false positive objects), fuzzy versus binary (nonprobabilistic versus probabilistic) ground-truth and single versus multiple experts for manual delineation. Furthermore, certain segmentation projects require assignments of various weights within each separate region, depending on the local importance. Due to such complicating factors and also because little has been accomplished in the ﬁeld of cell segmentation [6], a major focus in this work has been to further develop the region differencing method, a speciﬁc framework of the empirical discrepancy for segmentation evaluation in cell images. Our speciﬁc contribution is the combination of region differencing with a method to deal with over- and under-segmented regions. In Zhang [43], empirical discrepancy methods can be decomposed into different classes where the discrepancy is based on

728

IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 28, NO. 5, MAY 2009

Fig. 8. 3-D segmentation. From left to right, the original image, the ﬁltered and ridge enhanced image, the watershed segmentation, and the level set segmentation.

one or more of the following features: i) the number of missegmented pixels, ii) the position of missegmented pixels, iii) the number of false objects (false positive) in the image, and iv) feature values of segmented objects. Goumeidane et al. [53] proposed an empirical discrepancy method that relies on the position of missegmented pixels ii), but excluding the features i), iii), and iv). Still, they obtained a reasonable measure of discrepancy between a segmented region and a reference region by a spatial overlay of these. In [2], the discrepancy measure was deﬁned . is the volume by is the corresponding produced by manual segmentation and volume resulting from the automated segmentation. Our method is a related region differencing approach comparing all pairs of segmented regions, one taken from the “true” manual segmentation and the other from the automated segmentation

Fig. 9. Ridge following for cell segmentation. The ﬁlled circles in (a) are automatically generated starting points for the ridge following, which was applied to the image in Fig. 7(a). The solid lines in (a) represent the binary segmentation resulting from the ridge following. Clearly, some lines are not part of the true cell border, but these are removed by morphological closing of each connected component in the black regions, resulting in the ﬁnal segmentation (b).

HODNELAND et al.: A UNIFIED FRAMEWORK FOR AUTOMATED 3-D SEGMENTATION OF SURFACE-STAINED LIVING CELLS

729

Fig. 10. Measuring goodness of segmentation. Solid lines outline the reference regions, the dashed lines represent the automatically segmented regions. Based on human perception, (c) is the best segmentation of the four, which is consistent with the highest similarity measure A : that occurs in these examples. : ; (b) A : ; (c)A : ; (d) A : . (a) A

= 0 35

= 0 63

= 0 91

= 0 75

= 0 91

, closely related to the framework of segmentation evaluation described earlier (e.g., Udupa et al. [54]). Our method incorporates criteria i) and iii), using the number of missegmented pixels and penalizing false positive and negative objects. To be more speciﬁc, let be the whole image region and denote by the ground-truth segmented image obtained from manual consist of disjoint, constant valued redelineation. Let taking pixel values , gions and if , i.e., background is assigned the value zero. In contrast to a binary function, this graded assignment allows the human expert to express a global . Moreover, let degree of uncertainty into an identiﬁed object denote disjoint regions in obtained by the automated segmentation applied to the input image. Assume each is mapped to a value , allowing a pixel probabilistic automated segmentation. Again, the background if . Let is assigned zero, i.e., and denote the region and , respectively. Let of overlap and union between . We then deﬁne a similarity containing elements matrix

which is a measure of the relative volume of overlap between the manually and automatically segmented regions. and are jointly capable of distinguishing between under- and over-segmentation. In the case of over-segmenta, but tion, a situation that could imply will obtain a signiﬁcantly lower value. A similar argument repreholds for under-segmentation. Now, let sent our choice of similarity measure since it takes into account both under- and over-segmentation. An illustration of this approach is shown in Fig. 10. Each area (volume in 3-D) inside , and the corresolid lines represents the reference solution sponding area (volume in 3-D) inside dashed lines denotes the . Using (9), the segmentaautomatically segmented region compared tion in (c) attains the highest value of to (a), (b), and (d), in agreement with human perception. In the case of real cell images [Fig. 11(a)], automatically segmented regions (Fig. 11(b)–(f), white regions) and the ground-truth regions (Fig. 11(b)–(f), gray lines) are shown with their corresponding highest similarity measures. The similarity measure is calculated for all pairs of regions and in Fig. 11(b) and inserted into the 4 5 similarity matrix , each row corresponding to a single region from the ground truth image, and each column representing one region from the automatically segmented image (11)

(9) Note that . Each such element reﬂects the amount of agreement between a manual and an automated segmented region (see Fig. 10 for examples), where both degree of overlap and are taken into acand nonoverlap between region count, as well as the degree of uncertainties of manual and autois well represented by , mated segmentations. If , then , else . There are other possible alternatives to (9). The denominator can for instance be scaled or , to the total intensity value of either the two regions

(10) and are nonprobabilistic, binary functions Assume , i.e., and are characteristic taking values in functions of and , respectively. Then, (9) and (10) , , and reduce to

may consist of more than one Evidently, the matrix nonzero entry per row and column. This is a problem that is related to degeneracy [45]. Furthermore, empty columns and empty rows represent over- and under-segmentation, respectively. Such situations must also be taken care of properly. The values typeset in bold denote those elements with higher values along each row and column, chosen to represent the evaluation in this case. However, in the general case of a similarity matrix , the choice of such elements might not be unique. We propose a solution to this problem, which would be to establish a one-to-one map between maximal subsets and by creating a between matrix consisting of nonzero entries from providing the highest Frobenius norm (12)

730

IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 28, NO. 5, MAY 2009

Fig. 11. The image in (a) showing NRK cells has been segmented manually (gray lines R , b) and automatically (white regions R , b). The similarity measures reﬂect different quality of the segmentation. Note that the ﬁrst index i in A denotes a ground-truth region and the second index j denotes an automated segmented region. Maximum similarities are shown for R (c), A : , R (d), A : , R (e), A : and R (f), A : . The segmentation in (c) is poor, (d) fair, (e) good, and (f) fair.

= 0 007

= 0 663

= 0 861

= 0 678

The desired one-to-one map must conform to the requirements can have at most one nonzero entry per row and per that column, thus coping with the problem of degeneracy. False objects will give rise to columns with zeros in , accounting for criterion iii). The optimization in (12) is accomplished by , and then iterate through all elements in ﬁrst letting in decreasing order. For each iteration the element is removed if there exists a larger component in the same row or column. If not, the element remains unchanged. Then, by construcis obtained, tion, the largest possible Frobenius norm of satisfying the constraints. The optimization may create empty rows or columns in , corresponding to under-segmentation and over-segmentation, respectively. The overall similarity measure for the image is obtained by summing all elements in the derived matrix , after each of them has been scaled , i.e., the maximum to number of pixels of the automated or the manual solution. This scaling is performed in order to ensure that large regions more than small will inﬂuence our similarity measure is calculated as the regions. The ﬁnal similarity measure , scaled by the relative number of pixels in each sum of manually segmented region (13) where indicates a By this deﬁnition, denotes an excellent segmenpoor segmentation and , , and are tation. The relations between capable to distinguish between over- and under-segmentation, summarized in Table I. F. Preparation of the Microscopic Images The described automated cell segmentation method was tested on images of PC12 cells (rat pheochromocytoma cells,

TABLE I , SM AND UNDER- AND RELATIONS BETWEEN SM OVER-SEGMENTATION AND THE DIRECT CONNECTION BETWEEN SM AND OVERALL SEGMENTATION QUALITY

clone 251, Heumann et al. [55] and NRK cells (normal rat kidney cells, Mrs. M. Freshney, Glasgow, U.K.). PC12 cells were cultured as already described [56]. NRK cells were cultured in DMEM supplemented with 10% fetal calf serum. Transfection of NRK cells was accomplished by electroporation as described [56]. The PHD-YFP cDNA construct is described elsewhere [57]. For high-resolution ﬂuorescence microscopy, cells were plated in LabTek chambered coverglasses(Nalge Nunc International, Wiesbaden, Germany). For the experiments in which the effect of thymidine on cellular size and morphology was investigated, PC12 cell monolayers in LabTek chambers were maintained in growth medium containing 4 mM thymidine (Sigma) for 24 h (block of cell division), further incubated in medium without thymidine for 24 h (release of block) and ﬁnally imaged by wide ﬁeld ﬂuorescence microscopy (see below). In the control condition, fresh growth medium without thymidine was used for the blocking step. Cell monolayers were stained with wheat germ agglutinin (WGA) conjugated to Alexa Fluor dye. To obtain a 3-D matrix of cells, PC12 and NRK cells were embedded in agarose. Brieﬂy, low melt agarose (Carl Roth GmbH) was prepared in a . 2% (w/v) solution in DMEM 10% FCS and melted at 70 for 15 min. The solution was allowed to cool down to 45 or of PC12 or NRK cells, Pellets of approximately

HODNELAND et al.: A UNIFIED FRAMEWORK FOR AUTOMATED 3-D SEGMENTATION OF SURFACE-STAINED LIVING CELLS

731

TABLE II PARAMETERS FOR SEGMENTATION EXPERIMENTS. IN EACH CASE, THE CELL TYPE, THE FLUOROPHORE USED FOR PLASMA MEMBRANE LABELING AND THE MICROSCOPY METHOD IS INDICATED. ALL MANUAL AND AUTOMATED SEGMENTATION WAS PERFORMED IN 3-D, AS WELL AS THE SEGMENTATION EVALUATION

respectively, were loosely resuspended in 500 of growth medium supplemented with WGA-Alexa Fluor. In experiments in which transfected cells were analyzed, no WGA-Alexa Fluor was added to the cell suspension. 100 of the cell suspension of the molten agarose solution, the were mixed with 100 mixture was plated in a Labtek and incubated at 4 for 5 min to let the agarose solidify. Imaging was performed immediately thereafter. Confocal microscopy was performed either with a spinning-disc imaging setup (PerkinElmer Ultra View TMRS Live Cell Imager, PerkinElmer Life and Analytical Sciences, Boston, MA) or with a Leica TCS SP5 confocal microscope (Leica Microsystems, Mannheim, Germany). Imaging by wide ﬁeld ﬂuorescence microscopy is described in [58]. For both the wide ﬁeld and confocal imaging setups, the cells were analyzed in 3-D by acquiring single focal planes 300–500 nm apart from each other in the -direction spanning the whole cellular volume. III. RESULTS The watershed segmentation and level set segmentation have been compared to a manual ground-truth to evaluate the segmentation quality. Several experiments were performed on two different cell lines, two types of cell surface staining were used and imaging was performed with three different kinds of microscopy. The experimental parameters used in each case are summarized in Table II, showing the experiment name, the corresponding cell type, the ﬂuorescent marker and the microscope which was used (columns 1–4, respectively). As a common preprocessing step, the 3-D image stacks were ﬁltered using directional coherence enhancement ﬁlter (Section II-A). As a preprocessing step for the marker construction, the ridges of the ﬁltered image were enhanced using our own developed ridge enhancement by curvature (Section II-B-2). The markers were constructed using the method described in Section II-C-1. All automated segmentation was executed in full 3-D for the watershed segmentation (Section II-D-1) and the level sets (Section II-D-2) using the same set of markers as initialization regions. Both segmentation methods were subjected to the same cell classiﬁcation algorithm with equal set of parameters (Section II-C-4). A ground-truth was constructed for experiments (A-E) using manual segmentation (manual delineation) for comparison with the automated segmentation. Due to practical limitations for a manually conducted 3-D delineation, it was constructed plane wise using Adobe Photoshop and thereafter assembled into a 3-D representation. To limit the amount of

work required for the manual delineation, approximately up to 20 cells were randomly chosen to represent each experiment (A-E) in the ﬁnal segmentation evaluation. Every cell in the segmentation evaluation which had at least 10% of its border connected to the image border was removed from the analysis since those cells had a signiﬁcantly corrupt shape. Experiments A and C were evaluated with nonprobabilistic . Experiments characteristic functions B, D and E were evaluated using probabilistic functions because the images of these experiments included a certain amount of apoptotic and possibly dead cells responsible for an uncertainty in the manual segmentation. Each image produced a separate set of similarity measures, , and . To evaluate the whole experiment consisting of several images, each similarity measure was scaled by the relative number of manually detected cells in the image to which it belonged to, and then summed over all images in the experiment to obtain an overall similarity measure. Experiment F was performed to test whether the algorithm could detect small changes in cell size caused by a thymidine mediated block of the cell cycle [59]. No ground-truth was here constructed since this was a high-throughput experiment including as many as 1239 automatically segmented cells. All experiments were carried out on randomly chosen cells in order to be close to realistic experimental conditions. The program code used for segmentations was implemented in MATLAB, intensively vectorized to save computational time and executed on a Linux workstation. To avoid overoptimistic results, the method and parameter settings were developed on a separate data set not used for the ﬁnal evaluation. (The code could be available upon request by contacting the corresponding author.) A. Segmentation of WGA-Alexa Fluor Stained PC12 Cells Imaged by Wide Field Microscopy PC12 cells were surface-stained with WGA-Alexa Fluor and imaged in 3-D by wide ﬁeld microscopy. From most optical planes through the cell, images with sharp and distinct borders were obtained. Only those planes close to the top and the bottom of the spheroidal-shaped cells resulted in images with fuzzy cell boundaries. This is due to the fact that in these regions a large portion of the plasma membrane runs almost parallel to the optical plane [Fig. 12(a)]. The obtained cells exhibit challenging variations in shape and brightness and in some cases a discontinuous staining of the plasma membrane occurred. Furthermore, the displayed cells contain various amounts of punctuated, high intensity structures inside the cytoplasm as a result of endocytosed plasma membrane. These structures, known as endosomes, could be easily mistaken as cell border by the automated method (not shown). Representative images from one of the obtained 3-D-stacks at different -elevations are shown in Fig. 12(a)–(c) together with corresponding slices taken from the 3-D watershed segmentation (d)–(f), the level set segmentation (g)–(i), and the manual solution (j)–(l). The segmentation quality is high, indicating that plasma membrane-stained PC12 cells, due to their spheroidal shape, are suitable for automated 3-D segmentation. The comparative results from the statistical analysis of 24 cells used for assessment are summarized in Table III, row A. High success rates of up to 96% and 92%

732

IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 28, NO. 5, MAY 2009

Fig. 12. Segmentation of WGA-Alexa Fluor-stained PC12 cells imaged by wide ﬁeld microscopy. Raw data (a)–(c), watershed segmentation (d)–(f), level sets (g)–(i), and manual segmentation (j)–(l). The images are shown at z -elevations of 75%, 50%, and 25%.

TABLE III NUMERICAL RESULTS FROM 3-D AUTOMATED DETECTION OF NRK AND PC12 CELLS. THE WATERSHED ALGORITHM AND THE LEVEL SETS BOTH OBTAINED HIGH SUCCESS RATES AND ARE THUS COMPARABLE

were obtained for the watershed and the level sets, respectively. Thus, the two methods were comparable for this experiment. for both segmentation methods, arising from more over- than under-segmentation.

B. Segmentation of WGA-Alexa Fluor Stained NRK Cells Imaged by Confocal Spinning-Disc Microscopy In contrast to spheroidal PC12 cells, NRK cells possess a broad and ﬂat periphery surrounding the centered nucleus, which results in a protuberance of the plasma membrane (Fig. 13, drawing). Wide ﬁeld microscopy of such cells results in images displaying blurred cell borders (not shown), inappropriate for automated segmentation. To overcome this problem, confocal imaging techniques were applied. In this way only light from the respective focal planes is recorded during image acquisition. Images taken from one stack at different -elevations are shown in Figs. 13(a)–(c) together with corresponding slices from the watershed segmentation (d)–(f), the level set segmentation (g)–(i), and the manual segmentation (j)–(l). High success rates were achieved, up to 91% for the watershed and 93% for the level sets, see Table III,

row B. Thus the two methods had comparable performance for this data set. The numbers indicate a higher amount of . The over- than under-segmentation since major segmentation errors occurred in the lower planes due to the ﬂat morphology and weak signal of the NRK cells at this level, causing the automated methods to ﬂood further down in the stack compared to the manual ground-truth, thus creating over-segmentation. C. Segmentation of WGA-Alexa Fluor Stained NRK Cells Imaged by Confocal Point-Scanning Microscopy In this experiment, 3-D image stacks of WGA-Alexa Fluor stained NRK cells were acquired by confocal point-scanning microscopy. The respective images display cells with distinct cell borders [Fig. 14(a)–(c)] which are suitable for automated segmentation in 3-D. A 3-D segmentation revealed high success rates of up to 97% for watershed segmentation and 89% for level sets, shown in Table III, row C. In this experiment, the watershed segmentation had a higher success rate than the level set , resulting from approach. For both methods, under-segmentation. Most under-segmentation occurred in the lower planes where the NRK cells exhibit fuzzy borders. This

HODNELAND et al.: A UNIFIED FRAMEWORK FOR AUTOMATED 3-D SEGMENTATION OF SURFACE-STAINED LIVING CELLS

733

Fig. 13. Segmentation of WGA-Alexa Fluor stained NRK cells imaged by confocal spinning-disc microscopy. Each row displays a focal plane from a 3-D image stack (a)–(c) and its corresponding watershed segmentation (d)–(f), level set segmentation (g)–(i), and the manual ground-truth (j)–(l). The focal planes were acquired at z-elevations of 65%, 45%, and 25%, respectively. Note the sharp cell boundaries in (a)–(c), obtained by using confocal spinning-disc microscopy in preference to wide ﬁeld microscopy.

Fig. 14. Segmentation of WGA-Alexa Fluor stained NRK cells imaged by confocal point-scanning microscopy. Each row displays a focal plane from an image stack (a)–(c) and its corresponding segmentation (d)–(f) taken from the 3-D segmentation. Note the sharp cell boundaries in (a) and (b) and the fuzzy borders in (c) where the NRK cells are more ﬂat in than in the upper sections. The images are shown at z -elevations of 65%, 45%, and 25%.

complicated the segmentation [Fig. 14(c)] in a similar way as for the images taken by the confocal spinning disc microscopy. D. Segmentation of PHD-YFP-Expressing NRK Cells Imaged by Confocal Point-Scanning Microscopy Surface-staining of cells with WGA-Alexa Fluor is only applicable for automated segmentation if the dye molecules have access to the plasma membrane of the cell. This may be problematic for tissue due to the limited diffusion of molecules through the extracellular matrix. Therefore, the use of genetically encoded ﬂuorescent molecules would be advantageous. To address this issue, we expressed in NRK cells the pleckstrin-homology domain (PHD) of phospholipase C fused to the yellow ﬂuorescent protein (YFP) and imaged them by confocal point-scanning microscopy. PHD-YFP is speciﬁcally targeted to the cell periphery after expression in mammalian cells [57], [60] and does not lead to ﬂuorescent endocytic structures as in the case of WGA-Alexa Fluor. This revealed a prominent cell membrane labeling of PHD-YFP expressing

cells (Fig. 15(a)–(c), slices from a 3-D stack). However, not all cells were transfected (not shown), and the expression level varied from cell to cell. The latter resulted in cells exhibiting weak signals (Fig. 15(c), compare the cells in this plane). Cells with low signal intensity represent a great challenge for any automated segmentation. Therefore, one should keep in mind that due to the variable degree of protein expression and the restricted dynamic range of the imaging system not all positive cells can be adequately segmented from a 3-D stack. The automated watershed segmentation of the images in Fig. 15(a)–(c) is shown in Fig. 15(d)–(f) and the corresponding images from the level sets and the manual segmentation are shown in Fig. 15(g)–(i) and (j)–(l), respectively. A 3-D segmentation reveals success rates of up to for watershed approach and for the level and . The numersets using probabilistic functions ical results are shown in Table III, row D, revealing satisfying success rates and therefore indicating that the segmentation algorithms are also suitable for PHD-YFP expressing cells in addition to WGA-Alexa Fluor-stained cells and thus independent

734

IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 28, NO. 5, MAY 2009

Fig. 15. PHD-YFP-expressing NRK cells analyzed by confocal point-scanning microscopy. Raw data (a)–(c), watershed segmentation (d)–(f), level sets (g)–(i), and manual segmentation (j)–(l).

Fig. 17. Ridge enhancement for cells embedded in true 3-D. (a) Single focal plane and the xz (bottom) and yz (right) views along the dashed lines. (b) Contrast of the image stack has been improved by a ridge enhancement, which facilitates the automated generation of markers.

E. Segmentation of PHD-YFP-Expressing PC12 Cells Embedded in Agarose and Imaged by Confocal Point-Scanning Microscopy To create a tissue-like conﬁguration we plated cells in agarose and tested whether the segmentation was capable of a tissue-like segmentation of cells with surface staining. The images in the ﬁrst column of Fig. 16 show focal planes of z-heights 10%, 25%, and views 40%, 55%, 70%, and 85%. Fig. 17 shows the along the dashed lines in the original image (A) and the ridge enhanced image (B), respectively. Note how the ridge enhancement ﬁlter increases the contrast, even with a high degree of . anisotropy with pixel dimensions of The watershed transform, the level set, and the manual ground-truth are shown in the second, third, and last column, respectively. The results from the segmentation evaluation are displayed in Table III, row E. Three-dimensional views of the watershed and level set segmentation are depicted in Fig. 18. Note that only a fraction of the cells were transfected in the agarose matrix, thus leading to a relatively sparse density of ﬂuorescently labeled cells in 3-D. A higher density of ﬂuorescently labeled cells can be expected in tissue from transgenetic animals, along with a larger diversity of cells. Future experiments are therefore needed to explore the segmentation of real tissue.

Fig. 16. PHD-YFP-expressing PC12 cells grown in agarose and imaged by confocal point-scanning microscopy. The planes from bottom to top correspond to planes of the cell from bottom to top.

of the type of cell border labeling. The number of manually segmented cells (24) is larger than the number of automatically segmented cells (21 and 20), representing an under-segmentation. The current experiment had the lowest success rate in our work, probably due to a certain amount of weakly expressing cells.

HODNELAND et al.: A UNIFIED FRAMEWORK FOR AUTOMATED 3-D SEGMENTATION OF SURFACE-STAINED LIVING CELLS

735

Fig. 18. Three-dimensional view of PC12 cells imaged in agarose. Watershed (a) and level set segmentation (b).

TABLE IV STATISTICAL ANALYSIS OF THE INCREASE IN CELL SIZE UPON THYMIDINE TREATMENT. COLUMN 1 (LEFT) INDICATES THE THREE DIFFERENT EXPERIMENTS (+)) AND UNTREATED CELL POPULATION AND THE TOTAL. COLUMNS (2–3) SHOW THE NUMBER OF CELLS IN THE THYMIDINE-TREATED ( ( )). COLUMN 4 SHOWS THE P-VALUES ( ) FROM THE TWO-TAILED T-TEST APPLIED TO THE VOLUMES. COLUMNS (5–8) INDICATE THE MEAN ( ) FOR THE TWO CONDITIONS. THE RATIO OF THE MEAN VOLUMES BETWEEN THE TWO CELL VOLUME AND THE STANDARD ERROR OF THE MEAN ( POPULATIONS IS DISPLAYED IN COLUMN 9. ALL VOLUME ESTIMATES AND THE STANDARD ERRORS OF THE MEAN ARE GIVEN IN m

N

0

p

N





F. Biological Validation: Segmentation of WGA-Alexa Fluor Stained PC12 Cells Treated With Thymidine It is known that cells cultured in the presence of thymidine have an increased volume due to the inhibition of cell division [59]. To prove the usefulness and effectiveness of fully automated segmentation, the program was tested for its ability to detect a thymidine-dependent difference in cell size. We have chosen to use the watershed method for the segmentation in this experiment due to its high computational speed compared to the level set method. PC12 cells were grown in the presence and absence of thymidine, stained with WGA-Alexa Fluor and imaged by wide ﬁeld microscopy in 3-D, see Fig. 12 for an example of the obtained images. The binarized data sets obtained from the automated watershed segmentation were used to of the treated and calculate the volume cells. All planes were used in the untreated calculations of volume, covering the entire cell. This procedure revealed a signiﬁcant increase in mean cell volume of thymidine , , two tailed t-test) between treated cells ( 14% and 23% (Table IV). The statistical comparison of the increase in volume based on three experiments are shown in the bottom row of Table IV. Here, all cells belonging to the same group ( or ) in the three experiments were added and then subjected to a two-tailed t-test which resulted in a highly significant -value of . These results indicate that the automated segmentation method was able to experimentally conﬁrm the a priori expectation that treatment of cells with thymidine induce an increased cell volume. In general, a binarized segmentation permits estimation of a wide range of statistical parameters. As an example, the major and minor axis of the cells could be measured, indicating whether the cells have become

more elongated upon a certain treatment, or the mean cell intensity could be measured in a second image channel to obtain the concentration of a certain drug or protein. G. Comparing the Methods for 3-D Segmentation For the cell segmentation we have thoroughly compared two entirely different methods for segmentation of surface stained cells, the watershed transform and a level set model. Five experiments were conducted for comparison, including two different cell types, three different microscopes, and two unlike methods for cell surface markers (Sections III-A–III-F). All experiments reveal high success rates above 70% for both methods, except from (D) where the level set had the lowest success rate of . Comparing for all experiments, the watershed algorithm has a slightly higher performance than the level set. This difference was mostly due to breakthrough of the level set in regions of weakly stained plasma membrane, thus ﬂooding into the background. The amount of ﬂooding can be adjusted in the setup, however, this may result in poor convergence inside the cells around the high-signaled, endocytosed plasma membrane, thus preventing the zero level set from reaching the plasma membrane. The watershed algorithm is normally also signiﬁcantly faster than the level sets with a factor of 100. On the other hand, the level set model has a smoothing term, an important advantage compared to the standard watershed. Due to the preprocessing step of ﬁltering in this work, the watershed algorithm did not suffer signiﬁcantly from oscillating boundaries. It is also possible to combine the watershed algorithm and level sets by initializing the level set by the watershed regions, thus saving computational time and at the same time avoiding oscillating boundaries.

736

IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 28, NO. 5, MAY 2009

IV. DISCUSSION AND CONCLUSION Automated segmentation methods become increasingly important in cytometry and permit high-throughput analysis of cells. In this way statistically relevant information of biological processes occurring at the single cell level can be obtained. In the past, whole cell segmentation has mainly been performed in 2-D and was applied to ﬁxed cells [13], [21], [23]. Automated segmentation of living instead of ﬁxed cells has the capacity to provide information on cell dynamics. The present work describes a uniﬁed framework for 3-D segmentation of surfacestained, living cells. In addition, a comprehensive method for segmentation evaluation is presented, which demonstrates the performance and versatility of the compared segmentation algorithms. The usefulness and sensitivity of automated segmentation became most obvious in Experiment F, Section III, in which the program was able to detect a small but signiﬁcant increase in cell volume upon treatment with thymidine. These slight changes, ranging from 14% to 23%, were not evident from visual inspection of the images. This striking example demonstrates that the automated watershed segmentation is capable of revealing subtle but important changes in cell parameters as they may occur during the exposure of cells to environmental inﬂuences as drugs and toxins. For many applications the segmentation of surface-stained cells is superior to the segmentation of nuclei and cytoplasmically stained cells, because it is able to detect whole cells in closely packed arrangements like conﬂuent cell cultures or tissue [13], [21], [23]. A robust cell segmentation was obtained by ﬁrst performing a ﬁltering step. Several unlike approaches for ﬁltering were compared, linear and nonlinear spatial ﬁlters as well as PDE-based models. The results showed that typical edge-enhancing ﬁlters and linear smoothing ﬁlters were less suitable to smooth the ridges compared to coherence-enhancement ﬁlters [27], [47] and the nonlinear directional coherence enhancement ﬁlter [2]. After the ﬁltering, a ridge enhancement was applied to the ﬁltered image, which resulted in images showing pronounced ridges of which the majority are cell borders. Two methods for ridge enhancement were compared, the Hessian [34] and our related method, ridge enhancement by curvature. They showed comparable results, producing ridges of high contrast. The ridge enhancement in turn enables adaptive thresholding and morphological ﬁlling as a reliable and automated method to deﬁne marker regions for a marker-controlled watershed segmentation or a level set segmentation. Deﬁning the markers is the most crucial step in the segmentation procedure, since there should be exactly one marker inside each object of interest. In this respect further improvement of the success rate may be obtained by nucleus staining and subsequent use of this information for creating a high-quality marker image as it has been demonstrated for ﬁxed biopsy tissue [23]. The framework for segmentation was extensively tested on cell images from two cell lines with distinct morphologies, using two different types of plasma membrane labeling, and acquired by three types of microscopy. For simplicity, we decided to apply our ﬁrst choice for preprocessing of the images, the directional coherence enhancement ﬁlter and ridge enhancement,

for the extensive comparison of the watershed and the level set models in Section III. The segmentation method revealed high success rates when applied to the data sets of ﬂuorescence images displaying cells with distinct margins. In the case of PC12 cells displaying sharp cell boundaries, success rates up to was 96% were obtained compared to manual segmentation. For NRK cells a value up to 97% was obtained. However, segmenting NRK cells is more complicated than segmenting PC12 cells due to the ﬂat morphology. It follows that one of the most important prerequisites to obtain images displaying pronounced cell borders is that the optical plane of the imaging system is preferably perpendicular to the plasma membrane. This is easily achieved with a wide ﬁeld imaging setup for the spheroidal PC12 cells (Fig. 12), while for the ﬂat NRK cells, confocal microscopy techniques are necessary (Figs. 13–16). In the present study a comprehensive evaluation scheme based on a region differencing approach was developed and used to assess the performance of the automated cell segmentation. The obtained segmentation evaluation reﬂects both overand under-segmentation compared to a ground-truth, where the ground-truth, allowing an uncertainty factor, is acquired from manual segmentation performed by experts. In the past, segmentation evaluation of nuclei or cytoplasmically stained cells were performed using different methods, which makes a between-study comparison difﬁcult. To improve this situation, we aimed at the development of a standardized scheme for evaluation of cell segmentation. A crucial point for a high-quality segmentation of living cells is the type and quality of the cell border labeling. In the past, antibodies against cell surface proteins or Oregon green phalloidin labeling cortical F-actin were used to label cell borders of ﬁxed cells [13], [21], [23]. Our data show that under optimized experimental conditions both the vital stain WGA-Alexa Fluor and the expressed ﬂuorescent marker PHD-YFP revealed reproducible and high-quality data sets for segmentation of living cells. The advantage of WGA-Alexa Fluor is that it labels all cells and can be applied straightforward to the cell cultures shortly before the microscopic analysis. However, accurate analysis is only possible if the image acquisition takes place shortly after the cell labeling. Prolonged incubation times with WGA-Alexa Fluor lead to endocytoced plasma membrane resulting in numerous intracellular ﬂuorescent spots, which impose a severe problem to the automated segmentation. PHD-YFP on the other hand has to be introduced into cells by a more elaborated transfection method and usually results in only a certain percentage of transfected cells. This problem can be overcome by establishing stably transfected cell lines, or in the case of segmentation of cells in tissue and whole organisms, by establishing transgenetic animals. In the latter, cell surface staining by WGA-Alexa Fluor most likely fails due to the restricted diffusion of the dye through the dense extracellular matrix of tissue. In conclusion, the established approach for automated cell segmentation represents a robust and powerful tool for the statistical analysis of various cell parameters. The experience and the experimental results of this study demonstrate that good solutions can only be obtained if biological procedures and image processing techniques are combined in an optimal way.

HODNELAND et al.: A UNIFIED FRAMEWORK FOR AUTOMATED 3-D SEGMENTATION OF SURFACE-STAINED LIVING CELLS

737

ACKNOWLEDGMENT The authors would like to thank the Molecular Imaging Center (MIC) at the University of Bergen for providing the Perkin Elmer spinning-disc microscopy setup. The authors would like to thank V. Gerke (University of Muenster) and J. Barroso (University of Bergen) for providing the PHD-YFP construct and the images of PHD-YFP expressing NRK cells, respectively. The authors would also like to thank the anonymous reviewers for the very constructive feedback. REFERENCES
[1] A. Carpenter and D. Sabatini, “Systematic genome-wide screens of gene function,” Nature Reviews Genetics, vol. 5, pp. 11–22, 2004. [2] U. Adiga, R. Malladi, R. Fernandez-Gonzalez, and C. Ortiz de Solorzano, “High-throughput analysis of multispectral images of breast cancer tissue,” IEEE Trans. Image Process., vol. 15, no. 8, pp. 2259–2268, Aug. 2006. [3] C. Wählby, I.-M. Sintorn, F. Erlandsson, G. Borgefors, and E. Bengtsson, “Combining intensity, edge and shape information for 2-D and 3-D segmentation of cell nuclei in tissue sections,” J. Microscopy, vol. 215, pp. 67–76, 2004. [4] H. Bhaskar and S. Singh, “Live cell imaging: A computational perspective,” J. Real-Time Image Process., vol. 1, no. 3, pp. 195–212, 2007. [5] E. Bengtsson, “Computerized cell image analysis: Past, present, and future,” in Proc. SCIA03, 2003, pp. 395–407. [6] M. Tscherepanow, F. Zöllner, and F. Kummert, “Automatic segmentation of unstained living cells in bright-ﬁeld microscope images,” in Proc. Workshop Mass-Data Anal. Images Signals (MDA2006), 2006, pp. 86–95. [7] J. Geusebroek, A. Smeulders, and H. Geerts, “A minimum cost approach for segmenting networks of lines,” Int. J. Comput. Vis. vol. 43, no. 2, pp. 99–111, Jul. 2001. [8] K. Wu, D. Gauthier, and M. Levine, “Live cell image segmentation,” IEEE Trans. Biomed. Eng., vol. 42, no. 1, pp. 1–12, Jan. 1995. [9] D. Yu, T. D. Pham, H. Yan, B. Whang, and D. I. Crane, “Segmentation of cultured neurons using logical analysis of grey and distance differences,” J. Neurosci. Methods vol. 166, no. 1, pp. 125–137, 2007. [10] P. Adiga and B. Chaudhuri, “Efﬁcient cell segmentation tool for confocal microscopy tissue images and quantitative evaluation of FISH signals,” Microscopy Res. Technique, vol. 44, no. 1, pp. 49–68, 1999. [11] P. Adiga, “Integrated approach for segmentation of 3-D confocal images of a tissue specimen,” Microscopy Res. Technique, vol. 54, no. 4, pp. 260–270, 2003. [12] A. Dufour, V. Shinin, S. Tajbakhsh, N. Guillen-Aghion, J. C. OlivoMarin, and C. Zimmer, “Segmenting and tracking ﬂuorescent cells in dynamic 3-D microscopy with coupled active surfaces,” IEEE Trans. Image Process. vol. 14, no. 9, pp. 1396–1410, Sep. 2005. [13] C. D. Solorzano, R. Malladi, S. Lelièvre, and S. Lockett, “Segmentation of nuclei and cells using membrane related protein markers,” J. Microscopy, vol. 201, pp. 404–415, 2001. [14] N. Malpica, C. Ortiz de Solórzano, J. Vaquero, A. Santos, I. Vallcorba, J. Garcia-Sagredo, and P. Francisco del, “Applying watershed algorithms to the segmentation of clustered nuclei,” Cytometry, vol. 28, pp. 289–297, 1997. [15] U. Lin, G. A. , K. Olson, J. Guzowski, C. Barnes, and B. Roysam, “A hybrid 3-D watershed algorithm incorporating gradient cues and object models for automatic segmentation of nuclei in confocal image stacks,” Cytometry, Part A, vol. 56A, no. 1, pp. 23–26, 2003. [16] F. Zamani and R. Safabakhsh, “An unsupervised GVF snake approach for white blood cell segmentation based on nucleus,” in 8th Int. Conf. Signal Process., 2006, vol. 2. [17] E. Bengtsson, C. Wählby, and J. Lindblad, “Robust cell image segmentation methods,” Pattern Recognit. Image Anal., vol. 14, pp. 157–167, 2004. [18] J. Lindblad, “Development of Algorithms for Digital Image Cytometry,” Ph.D. dissertation, Acta Universitatis Upsaliensis, Uppsala, Sweden, 2002. [19] S. Peng, B. Urbanc, L. Cruz, B. T. Hyman, and H. E. Stanley, “Neuron recognition by parallel Potts segmentation,” Proc. Nat. Acad. Sci. vol. 100, no. 7, pp. 3847–3852, 2003. [20] A. Dima, M. Scholz, and K. Obermayer, “Automatic segmentation and skeletonization of neurons from confocal microscopy images based on the 3-D wavelet transform,” IEEE Trans. Image Process. vol. 11, no. 7, pp. 790–801, Jul. 2002.

[21] D. Baggett, M.-A. Nakaya, M. McAuliffe, T. P. Yamaguchi, and S. Lockett, “Whole cell segmentation in solid tissue sections,” Cytometry Part A, vol. 67A, pp. 137–143, 2005. [22] D. McCullough, P. Gudla, B. Harris, J. Collins, K. Meaburn, M.-A. Nakaya, T. Yamaguchi, T. Misteli, and S. Lockett, “Segmentation of whole cells and cell nuclei from 3-D optical microscope images using dynamic programming,” IEEE Trans. Med. Imag., vol. 27, no. 5, pp. 723–734, May 2008. [23] A. I. Dow, S. A. Shafer, J. M. Kirkwood, R. A. Mascari, and A. S. Waggoner, “Automatic multiparameter ﬂuorescence imaging for determining lymphocyte phenotype and activation status in melanoma tissue sections,” Cytometry, vol. 25, pp. 71–81, 1996. [24] R. Gonzalez and R. Woods, Digital Image Processing. Reading, MA: Addison-Wesley, 1992. [25] T. F. Chan and J. Shen, Image Processing and Analysis: Variational, PDE, Wavelet, and Stochastic Methods. Philadelphia, PA, USA: SIAM, 2005. [26] J. Weickert, “Theoretical foundations of anisotropic diffusion in image processing,” in Theoretical Foundations of Computer Vision. New York: Springer, 1994, pp. 221–236. [27] J. Weichert, “A review of nonlinear diffusion ﬁltering,” in Scale-Space Theory in Computer Vision. New York: Springer, 1997, vol. 1252, Lecture Notes in Computer Science, pp. 1–28. [28] M. Lysaker, S. Osher, and X.-C. Tai, “Noise removal using smoothed normals and surface ﬁtting,” IEEE Trans. Image Process., vol. 13, no. 10, pp. 1345–1357, Oct. 2004. [29] T. F. Chan, S. Osher, and J. Shen, “The digital TV ﬁlter and non-linear denoising,” IEEE Trans. Image Process. vol. 10, no. 2, pp. 231–241, Feb. 2001. [30] A. Ross, A. Jain, and J. Reisman, “A hybrid ﬁngerprint matcher,” in Proc. 16th Int. Conf. Pattern Recognit., Washington, DC, 2002, vol. 3, pp. 795–798. [31] A. Frangi, W. Niessen, K. Vincken, and M. Viergever, “Multiscale vessel enhancement ﬁlterering,” in Medical Image Computing and Computer-Assisted Interventation—MICCAI’98. Berlin: Springer, 1998, vol. 1496, pp. 130–137. [32] D. Eberly, R. Gardner, B. Morse, S. Pizer, and C. Scharlach, “Ridges for image analysis,” J. Math. Imag. Vis., vol. 4, no. 4, pp. 353–373, 1994. [33] J. Stoeckel, F. Vos, P. Vos, and A. Vossepoel, “An evaluation of ridge extraction methods for portal imaging,” in Proc. Int. Conf. Pattern Recognit., Washington, DC, 2000, vol. 3, pp. 429–432. [34] S. Gautama, W. Goeman, and D. J. , “Robust detection of road junctions in VHR images using an improved ridge detector,” in Proc. Int. Soc. Photogrammetry Remote Sens. (ISPRS), 2004, vol. 35, pp. 815–819. [35] T. Lindeberg, “Edge detection and ridge detection with automatic scale selection,” Int. J. Comput. Vis. vol. 30, no. 2, pp. 117–154, 1998. [36] K. A. Al-Kofahi, A. Can, S. Lasek, D. H. Szarowski, N. Dowell-Mesﬁn, W. Shain, J. N. Turner, and B. Roysam, “Median-based robust algorithms for tracing neurons from noisy confocal microscope images,” IEEE Trans. Inf. Technol. Biomed., vol. 7, no. 4, pp. 302–317, Dec. 2003. [37] A. Can, H. Shen, J. N. Turner, H. L. Tanenbaum, and B. Roysam, “Rapid automated tracing and feature extraction from retinal fundus images using direct exploratory algorithms,” IEEE Trans. Inf. Technol. Biomed., vol. 3, no. 2, pp. 125–138, Jun. 1999. [38] H. Nguyen, M. Worring, and R. van den Boomgaard, “Watersnakes: Energy-driven watershed segmentation,” IEEE Trans. Pattern Anal. Mach. Intell. vol. 25, no. 3, pp. 330–342, Mar. 2003. [39] V. Grau, A. J. U. Mewes, M. A. Raya, R. Kikinis, and S. K. Warﬁeld, “Improved watershed transform for medical image segmentation using prior information,” IEEE Trans. Med. Imag. vol. 23, no. 4, pp. 447–458, Apr. 2004. [40] L. Vincent and P. Soille, “Watersheds in digital spaces: An efﬁcient algorithm based on immersion simulations,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 13, no. 6, pp. 583–598, Jun. 1991. [41] C. Wählby, J. Lindblad, M. Vondrus, E. Bengtsson, and L. Björkesten, “Algorithms for cytoplasm segmentation of ﬂuorescence labelled cells,” Analytical Cellular Pathol., vol. 24, pp. 101–111, 2002. [42] X.-C. Tai, E. Hodneland, J. Weickert, N. V. Bukoreshtliev, A. Lundervold, and H.-H. Gerdes, “Level set methods for watershed image segmentation,” in Scale Space and Variational Methods in Computer Vision. Berlin: Springer, 2007, vol. 4485/2008, pp. 178–190. [43] Y. Zhang, “A survey on evaluation methods for image segmentation,” Pattern Recognit., vol. 29, pp. 1335–1346, 1996. [44] Y. Zhang, “Evaluation and comparison of different segmentation algorithms,” Pattern Recognit. Lett., vol. 18, no. 10, pp. 963–974, 1997.

738

IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 28, NO. 5, MAY 2009

[45] R. Unnikrishnan, C. Pantofaru, and M. Hebert, “A measure for objective evaluation of image segmentation algorithms,” in Proc. 2005 IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR ’05), Workshop Empirical Evaluation Methods Comput. Vis., Jun. 2005, vol. 3, pp. 34–41. [46] R. van den Boomgaard, Algorithms for non-linear diffusion [Online]. Available: http://staff.science.uva.nl/ rein/nldiffusionweb/nldiffusioncode.pdf [47] J. Weickert, “Multiscale texture enhancement,” in Computer Analysis of Images and Patterns. Berlin, Germany: Springer, 1995, vol. 970/ 1995, pp. 230–237. [48] R. Kimmel, R. Malladi, and N. Sochen, “Images as embedded maps and minimal surfaces: Movies, color, texture, and volumetric medical images,” Int. J. Comput. Vis., vol. 39, no. 2, pp. 111–129, 2000. [49] G. Gilboa, N. A. Sochen, and Y. Y. Zeevi, “Forward-and-backward diffusion processes for adaptive image enhancement and denoising,” IEEE Trans. Image Process., vol. 11, no. 7, pp. 689–703, Jul. 2002. [50] L. Finney and G. Thomas, Jr., Calculus. Reading, MA: AddisonWesley, 1994. [51] S. G. Chang, B. Yu, and M. Vetterli, “Spatially adaptive wavelet thresholding with context modeling for image denoising,” IEEE Trans. Image Process., vol. 9, no. 9, pp. 1522–1531, Sep. 2000. [52] J. B. T. M. Roerdink and A. Meijster, “The watershed transform: Definitions, algorithms and parallelization strategies,” Fundamenta Informaticae, vol. 41, no. 1–2, pp. 187–228, Jan. 2000. [53] A. Goumeidane, M. Khamadja, B. Belaroussi, H. Benoit-Cattin, and C. Odet, “New discrepancy measures for segmentation evaluation,” Pattern Recognit. Lett., vol. 2, no. 10, pp. 411–414, 2003.

[54] J. Udupa, V. Leblanc, Y. Zhuge, C. Imielinska, H. Schmidt, L. Currie, B. Hirsch, and J. Woodburn, “A framework for evaluating image segmentation algorithms,” Computerized Med. Imag. Graphics vol. 30, no. 2, pp. 75–87, Mar. 2006. [55] T. Block, C. Kin, and B. Breckenridge, “Mutants of PC12 cells with altered cyclic AMP responses,” Molecular Cellular Biol. vol. 4, no. 10, pp. 2091–2097, 1984. [56] R. Rudolf, T. Salm, A. Rustom, and H.-H. Gerdes, “Dynamics of immature secretory granules: Role of cytoskeletal elements during transport, cortical restriction, and F-actin-dependent tethering,” Molecular Biol. Cell, vol. 12, pp. 1353–1365, 2001. [57] U. Rescher, D. Ruhe, C. Ludwig, N. Zobiack, and V. Gerke, “Annexin 2 is a phosphatidylinositol (4,5)-bisphosphate binding protein recruited to actin assembly sites at cellular membranes,” J. Cell Sci., vol. 117, pp. 3473–3480, 2004. [58] E. Hodneland, A. Lundervold, S. Gurke, X.-C. Tai, A. Rustom, and H.-H. Gerdes, “Automated detection of tunneling nanotubes in 3-D images,” Cytometry Part A, vol. 69A, pp. 961–972, 2006. [59] J. Bergeron, “Different effects of thymidine and 5-ﬂuorouracil 2 -deoxyriboside on biosynthetic events in cultured p 815y mast cells,” Biochem. J., vol. 123, pp. 385–390, 1971. [60] S. A. Watt, G. Kular, I. Fleming, P. Downes, and J. M. Lucocq, “Subcellular localization of phosphatidylinositol 4,5-bisphosphate using the pleckstrin homology domain of phospholipase c d1,” Biochem. J, vol. 363, pp. 657–666, 2002.

